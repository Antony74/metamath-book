%Book: Metamath
%Author:  Norman D. Megill nm@alum.mit.edu

% macropackage = LaTeX
% fonts = AMS (American Mathematical Society)
% 3 passes are necessary to get correct page numbers in cross-references
%
% AMSFonts are available from:
%   American Mathematical Society
%   P.O. Box 6248
%   Providence, RI 02940
%   Phone:  800-321-4AMS or 401-455-4080
% These fonts are also available on the Internet via anonymous ftp to
% e-MATH.AMS.COM in the directory /ams.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentstyle[leqno]{book}
%\usepackage{amssymb}
\raggedbottom
\makeindex

\begin{document}

%%%%%%% load in AMS fonts %%%%%%%
%\input{amssym.def}
%\input{amssym.tex}
\input{c:/texmf/tex/plain/amsfonts/amssym.def}
\input{c:/texmf/tex/plain/amsfonts/amssym.tex}

\bibliographystyle{plain}
\pagenumbering{roman}
\pagestyle{headings}

\thispagestyle{empty}

\hfill
\vfill

\begin{center}
{\LARGE\bf Metamath} \\
\vspace{1ex}
{\large A Computer Language for Pure Mathematics} \\
\vspace{7ex}
{\large Norman D. Megill}
\end{center}

\vfill
\hfill

\newpage
\thispagestyle{empty}

\hfill
\vfill

\begin{center}

Copyright (C) 1997, 1999 by Norman D. Megill

Permission is granted to make and distribute verbatim copies of this
manual
provided the copyright notice and this
permission notice are preserved on all copies.

Permission is granted to copy and distribute modified versions of this
manual under the conditions for verbatim copying, provided that the
entire
resulting derived work is distributed under the terms of a permission
notice
identical to this one.

Permission is granted to copy and distribute translations of this
manual into another language, under the above conditions for modified
versions,
except that this permission notice may be stated in a translation
approved by the
author.            \\
\ \\
\ \\
Norman D. Megill\\ 19 Locke Lane, Lexington Ma 02173 \\
E-mail address: {\tt nm@alum.mit.edu} \\
This book was last revised July 26, 1997 \\
Preface was revised on March 17, 1999 \\
For current information on the Metamath software see \\
{\tt ftp://ftp.shore.net/members/ndm/Readme.txt} \\
\verb$http://www.shore.net/~ndm/java/mm.html$
\end{center}

\newpage
\thispagestyle{empty}

\hfill
\vfill

\begin{center}
{\it In loving memory of my wife Deborah Nickerson Megill, who inspired
and encouraged all of this}\\
\ \\
{\it To my 8-year-old son Robin Dwight Megill, who misses his mommy}
\end{center}

\vfill
\hfill

\newpage

\tableofcontents
%\listoftables

\chapter*{Preface}
\markboth{PREFACE}{PREFACE}

\subsubsection{Overview}

Metamath\index{Metamath} is a computer language and an associated computer
program for archiving, verifying, and studying mathematical proofs at a very
detailed level.  The Metamath language incorporates no mathematics per se but
treats all mathematical statements as mere sequences of symbols.  You provide
Metamath with certain special sequences (axioms) that tell it what rules
of inference are allowed.  Metamath is not limited to any specific field of
mathematics.  The Metamath language is simple and robust, with an
almost total absence of hard-wired syntax, and I believe that it
provides about the simplest possible framework that allows essentially all of
mathematics to be expressed with absolute rigor.

% index test
%\newcommand{\nn}[1]{#1n}
%\index{aaa@bbb}
%\index{abc!def}
%\index{abd|see{qqq}}
%\index{abe|nn}
%\index{abf|emph}
%\index{abg|(}
%\index{abg|)}

Using the Metamath language, you can build formal or mathematical
systems\index{formal system}\footnote{A formal or mathematical system consists
of a collection of symbols (such as $2$, $4$, $+$ and $=$), syntax rules that
describe how symbols may be combined to form a legal expression (called a
well-formed formula or {\em wff}, pronounced ``whiff''), some starting wffs
called axioms, and inference rules that describe how theorems may be derived
(proved) from the axioms.  A theorem is a mathematical fact such as $2+2=4$.
Strictly speaking, even an obvious fact such as this must be proved from
axioms to be formally acceptable to a mathematician.}\index{theorem}
\index{axiom}\index{rule}\index{well-formed formula (wff)} that involve
inferences from axioms.  Although a database is provided
that includes a recommended set of axioms for standard mathematics, if you
wish you can supply your own symbols, syntax, axioms, rules, and definitions.

The name ``Metamath'' was chosen to suggest that the language provides a means
for {\em describing} mathematics rather than being the mathematics itself.
Actually in some sense any mathematical language is metamathematical.
Symbols written on paper, or stored in a computer, are not mathematics itself
but rather a way of expressing mathematics.  For example ``7'' and ``VII'' are
symbols for denoting the number seven in Arabic and Roman numerals;  neither
{\em is} the number seven.

If you are able to understand and write computer programs, you should be able
to follow abstract mathematics with the aid of Metamath.  Used in conjunction
with standard textbooks, Metamath can guide you step-by-step towards an
understanding of abstract mathematics from a very rigorous viewpoint, even if
you have no formal abstract mathematics background.  By using a single,
consistent notation to express proofs, once you grasp its basic concepts
Metamath provides you with the ability to immediately follow and dissect
proofs even in totally unfamiliar areas.

Of course, just being able follow a proof will not necessarily give you an
intuitive familiarity with mathematics.  Memorizing the rules of chess does not
give you the ability to appreciate the game of a master, and knowing how the
notes on a musical score map to piano keys does not give you the ability to
hear in your head how it would sound.  But each of these can be a first step.

Metamath allows you to explore proofs in the sense that you can see the
theorem referenced at any step expanded in as much detail as you want, right
down to the underlying axioms of logic and set theory (in the case of the set
theory database provided).  While Metamath will not replace the higher-level
understanding that can only be acquired through exercises and hard work, being
able to see how gaps in a proof are filled in can give you increased
confidence that can speed up the learning process and save you time when you
get stuck.

The Metamath language breaks down a mathematical proof into its tiniest
possible parts.  These can be pieced together, like interlocking
pieces in a puzzle, only in a way that produces correct and absolutely rigorous
mathematics.

The nature of Metamath\index{Metamath} enforces very precise mathematical
thinking, similar to that involved in writing a computer program.  A crucial
difference, though, is that once a proof is verified (by the Metamath program)
to be correct, it is definitely correct; it can never have a hidden
``bug.''\index{computer program bugs}  After getting used to the kind of rigor
and accuracy provided by Metamath, you might even be tempted to
adopt the attitude that a proof should never be considered correct until it
has been verified by a computer, just as you would not completely trust a
manual calculation until you have verified it on a
calculator.

My goal for Metamath was a system for describing and verifying
mathematics that is completely universal yet conceptually as simple as
possible.  In approaching mathematics from an axiomatic, formal viewpoint, I
wanted Metamath to be able to handle almost any mathematical system, not
necessarily with ease, but at least in principle and hopefully in practice. I
wanted it to verify proofs with absolute rigor, and for this reason Metamath
is what might be thought of as a ``compile-only'' language rather than an
algorithmic or Turing-machine language (Pascal, C, Prolog, Mathematica,
etc.).  In other words, a ``program'' (database) written in the Metamath
language doesn't ``do'' anything; it merely exhibits mathematical knowledge
and permits this knowledge to be verified as being correct.  A program in an
algorithmic language can potentially have hidden bugs\index{computer program
bugs} as well as possibly being hard to understand.  But each token in a
Metamath database must be consistent with the database's earlier
contents according to simple, fixed rules, and if a database is syntactically
correct,\footnote{Here the notion of verifying correctness of syntax includes
verification that a sequential list of proof steps results in the specified
theorem.} then the mathematical content is correct with absolute certainty (or
at least to the certainty of the verification program, which is relatively
simple).  The only ``bugs'' that can exist are in the statement of the axioms,
for example if the axioms are inconsistent (a famous problem shown to be
unsolvable by G\"{o}del's incompleteness theorem\index{G\"{o}del's
incompleteness theorem}).

Metamath doesn't prove theorems automatically but is designed to verify proofs
that you supply to it.  Metamath is completely general and has no built-in,
preconceived notions about your formal system\index{formal system}, its logic
or its syntax, but the price for its generality is that it does not lend
itself well to automated proofs in its most general form.  (In principle it
could accept translated proofs from other, more specific theorem proving
programs, although nothing along those lines has been done so far.)  For
constructing proofs, the Metamath program has a Proof Assistant\index{Proof
Assistant} which helps you fill in some of a proof step's details, shows you
what choices you have at any step, and verifies the proof as you build it; but
you are still expected to provide the proof.

Like most computer languages, the Metamath\index{Metamath} language uses the
standard ({\sc ascii}) characters on a computer keyboard, so it cannot
directly represent many of the special symbols that mathematicians use.  A
useful feature of the Metamath program is its ability to convert its notation
into the \LaTeX\ typesetting language.\index{latex@{\LaTeX}}  This feature
lets you convert the {\sc ascii} tokens you've defined into standard
mathematical symbols, so you end up with symbols and formulas you are familiar
with instead of somewhat cryptic {\sc ascii} representations of them.

Metamath is probably conceptually different from anything you've seen
before and some aspects may take some getting used to.  This book will
help you decide whether Metamath suits your specific needs.

\subsubsection{Setting Your Expectations}
It is important for you to understand what Metamath\index{Metamath} is and is
not.  As mentioned, Metamath is {\em not} an automated theorem prover but
rather a proof verifier.  Developing a database can be tedious, hard work,
especially if you want to make the proofs as short as possible, but it becomes
easier as you build up a collection of useful theorems.  The purpose of
Metamath is simply to document existing mathematics in an absolutely rigorous,
computer-verifiable way, not to aid directly in the creation of new
mathematics.  It also is not a magic solution for learning abstract
mathematics, although it may be helpful to be able to actually see the implied
rigor behind what you are learning from textbooks, as well as providing hints
to work out proofs that you are stumped on.

As of this writing, a sizable set theory database has been developed to
provide a foundation for many fields of mathematics, but much more work would
be required to develop useful databases for specific fields.

Metamath\index{Metamath} ``knows no math;'' it just provides a framework in
which to express mathematics.  Its language is very small.  You can define two
kinds of symbols, constants\index{constant} and variables\index{variable}.
The only thing Metamath knows how to do is to substitute strings of symbols
for the variables\index{substitution!variable}\index{variable substitution} in
an expression based on instructions you provide it in a proof, subject to
certain constraints you specify for the variables.  Even the decimal
representation of a number is merely a string of certain constants (digits)
which together, in a specific context, correspond to whatever mathematical
object you choose to define for it; unlike other computer languages, there is
no actual number stored inside the computer.  In a proof, you in effect
instruct Metamath what symbol substitutions to make in previous axioms or
theorems and join a sequence of them together to result in the desired
theorem.  This kind of symbol manipulation captures the essence of mathematics
at a preaxiomatic level.

\subsubsection{Metamath and Mathematical Literature}

In advanced mathematical literature, proofs are usually presented in the form
of short outlines that often only an expert can follow.  This is partly out of
a desire for brevity, but it would also be unwise (even if it were practical)
to present proofs in complete formal detail, since the overall picture would
be lost.\index{formal proof}

A solution I envision\label{envision} that would allow mathematics to remain
acceptable to the expert, yet increase its accessibility to non-specialists,
consists of a combination of the traditional short, informal proof in print
accompanied by a complete formal proof stored in a computer database.  In an
analogy with a computer program, the informal proof is like a set of comments
that describe the overall reasoning and content of the proof, whereas the
computer database is like the actual program and provides a means for anyone,
even a non-expert, to follow the proof in as much detail as desired, exploring
it back through layers of theorems (like subroutines that call other
subroutines) all the way back to the axioms of the theory.  In addition, the
computer database would have the advantage of providing absolute assurance
that the proof is correct, since each step can be verified automatically.

There are several other approaches besides Metamath to a project such
as this.  Section~\ref{proofverifiers} discusses some of these.

To me, a noble goal would be a {\sc cd rom} with hundreds of thousands of
theorems and their computer-verifiable proofs, encompassing a significant
fraction of known mathematics and available for instant access.  Whether or
not Metamath is an appropriate choice remains to be seen, but in
principle I believe it is sufficient.

\subsubsection{Formalism}

Over the past fifty years, a group of French mathematicians working
collectively under the pseudonym of Bourbaki\index{Bourbaki, Nicholaus} have
co-authored a series of monographs that attempt to rigorously and
consistently formalize large bodies of mathematics from foundations.  On the
one hand, certainly such an effort has its merits; on the other hand, the
Bourbaki project has been criticized for its ``scholasticism'' and
``hyperaxiomatics'' that hide the intuitive steps that lead to the results
\cite[p.~191]{Barrow}\index{Barrow, John D.}.

Metamath unabashedly carries this philosophy to its extreme and no doubt is
subject to the same kind of criticism.  Nonetheless I think that in
conjunction with conventional approaches to mathematics Metamath can serve a
useful purpose.  The Bourbaki approach is essentially pedagogic, requiring the
reader to become intimately familiar with each detail in a very large
hierarchy before he or she can proceed to the next step.  The difference with
Metamath is that the ``reader'' (user) knows that all details are contained in
its computer database, available as needed; it does not demand that the user
to know everything but conveniently makes available those portions that are of
interest.  As the body of all mathematical knowledge grows larger and larger,
no one individual can have a thorough grasp of its entirety.  Metamath
can finalize and put to rest any questions about the validity of any part of it
and can make any part of it accessible, in principle, to a non-specialist.

\subsubsection{A Personal Note}
Why did I develop Metamath\index{Metamath}?  I enjoy abstract mathematics, but
I sometimes get lost in a barrage of definitions and start to lose confidence
that my proofs are correct.  Or I reach a point where I lose sight of how
anything I'm doing relates to the axioms that a theory is based on and am
sometimes suspicious that there may be some overlooked implicit axiom
accidentally introduced along the way (as happened historically with Euclidean
geometry\index{Euclidean geometry}, whose omission of Pasch's
axiom\index{Pasch's axiom} went unnoticed for 2000 years
\cite[p.~160]{Davis}!). I'm also somewhat lazy and wish to avoid the effort
involved in re-verifying the gaps in informal proofs ``left to the reader;'' I
prefer to figure them out just once and not have to go through the same
frustration a year from now when I've forgotten what I did.  Metamath provides
better recovery of my efforts than scraps of paper that I can't
decipher anymore.  But mostly I find very appealing the idea of rigorously
archiving mathematical knowledge in a computer database, providing precision,
certainty, and elimination of human error.

\subsubsection{Note on Bibliography and Index}

The Bibliography usually includes the Library of Congress classification
for a work to make it easier for you to find it in on a university
library shelf.  The Index has author references to pages where their works
are cited, even though the authors' names may not appear on those pages.

\subsubsection{Acknowledgments}

Acknowledgments are first due to my wife, Deborah, for critiquing the
manuscript but most of all for her patience and support.  I also wish to thank
Joe Wright, Richard Becker, Clarke Evans, Buddha Buck, and Jeremy Henty for
helpful comments.  Any errors, omissions, and other shortcomings are of course
my responsibility.

(Added March, 1999) I wish to thank Fredrick Paul Eisele,
Sr.\footnote{\verb$phreed@ameritech.net$}\ for preparing the Debian Linux
package for Metamath.

\chapter{Introduction}
\pagenumbering{arabic}

\begin{quotation}
  {\em {\em I.M.:}  No, no.  There's nothing subjective about it!  Everybody
knows what a proof is.  Just read some books, take courses from a competent
mathematician, and you'll catch on.

{\em Student:}  Are you sure?

{\em I.M.:}  Well---it is possible that you won't, if you don't have any
aptitude for it.  That can happen, too.

{\em Student:}  Then {\em you} decide what a proof is, and if I don't learn
to decide in the same way, you decide I don't have any aptitude.

{\em I.M.:}  If not me, then who?}
    \flushright\sc  ``The Ideal Mathematician''
    \index{Davis, Phillip J.}
    \footnote{\cite{Davis}, p.~40}\\
\end{quotation}

In the past century, brilliant mathematicians have discovered almost
unimaginably profound results that rank among the crowning intellectual
achievements of mankind.  However, there is a sense in which modern abstract
mathematics is behind the times, stuck in an era before computers existed.
While no one disputes the remarkable results that have been achieved,
communicating these results in a precise way to the uninitiated is virtually
impossible.  To describe these results, a terse informal language is used which
despite its elegance is very difficult to learn.  This informal language is not
imprecise, far from it, but rather it often has omitted detail
and symbols with hidden context that are
implicitly understood by an expert but few others.  Extremely complex technical
meanings are associated with innocent-sounding English words such as
``compact'' and ``measurable'' that barely hint at what is actually being
said.  Anyone who does not keep the precise technical meaning constantly in
mind is bound to fail, and acquiring the ability to do this can be achieved
only through much practice and hard work.  Only the few who complete the
painful learning experience can join the small in-group of pure
mathematicians.  The informal language effectively cuts off the true nature of
their knowledge from most everyone else.

Metamath\index{Metamath} makes abstract mathematics more concrete.  It allows
a computer to keep track of the complexity associated with each word or symbol
with absolute rigor.  You can explore this complexity at your leisure, to
whatever degree you desire.  Whether or not you believe that concepts such as
infinity actually ``exist'' outside of the mind, Metamath lets you get to the
foundation for what's really being said.  Its language is simple enough so that you
don't have to rely on the authority of experts but can verify the results
yourself, step by step.  If you want to attempt to derive your own results,
Metamath will not let you make a mistake in reasoning.

``Metamath''\index{Metamath} is the name of a mathematical computer language
that describes formal\index{formal system} mathematical
systems and expresses proofs of theorems in those systems.  Such a language
is called a metalanguage\index{metalanguage} by mathematicians.  ``Metamath''
is also the name of a computer program that verifies
proofs expressed in the language.  The Metamath program does not have built-in
ability to make logical inferences; it just makes a series of symbol
substitutions according to instructions given to it in a proof
and verifies that the result matches the expected theorem.  It makes logical
inferences based only on rules of logic that are contained in a set of
axioms\index{axiom}, or first principles, that you provide to it as the
starting point for proofs.

The complete specification of the Metamath language is only four pages long
(Section~\ref{spec}, p.~\pageref{spec}).  Its simplicity may at first make you
may wonder how it can do much of anything at all.  But in fact the kinds of
symbol manipulations it performs are the ones that are implicitly done in all
mathematical systems at the lowest level.  You can learn it relatively quickly
and have complete confidence in any mathematical proof that it verifies.  On
the other hand, it is powerful and general enough so that virtually any
mathematical theory, from the most basic to the deeply abstract, can be
described with it.

Although in principle Metamath can be used with any
kind of mathematics, it is best suited for abstract or ``pure'' mathematics
that is mostly concerned with theorems and their proofs, as opposed to the
kind of mathematics that deals with the practical manipulation of numbers.
Examples of branches of pure mathematics are logic\index{logic},\footnote{Logic
is the study of statements that are universally true regardless of the objects
being described by the statements.  An example is the statement, ``if $P$
implies $Q$, then either $P$ is false or $Q$ is true.''} set theory\index{set
theory},\footnote{Set theory is the study of general-purpose mathematical objects called
``sets,'' and from it essentially all of mathematics can be derived.  For
example, numbers can be defined as specific sets, and their properties
can be explored using the tools of set theory.} number theory\index{number
theory},\footnote{Number theory deals with the properties of positive and
negative integers (whole numbers).} group theory\index{group
theory},\footnote{Group theory studies the properties of mathematical objects
called groups that obey a simple set of axioms and have properties of symmetry
that make them useful in many other fields.} abstract algebra\index{abstract
algebra},\footnote{Abstract algebra includes group theory and also studies
groups with additional properties that qualify them as ``rings'' and
``fields.''  The set of real numbers is a familiar example of a field.},
analysis\index{analysis} \index{real and complex numbers}\footnote{Analysis is
the study of real and complex numbers.} and
topology\index{topology}.\footnote{One area studied by topology are properties
that remain unchanged when geometrical objects undergo stretching
deformations; for example a doughnut and a coffee cup each have one hole (the
cup's hole is in its handle) and are thus considered topologically
equivalent.  In general, though, topology is the study of abstract
mathematical objects that obey a certain (surprisingly simple) set of axioms.
See, for example, Munkres \cite{Munkres}\index{Munkres, James R.}.} Even in
physics, Metamath could be applied to certain branches that make use of
abstract mathematics, such as quantum logic\index{quantum logic} (used to study
aspects of quantum mechanics\index{quantum mechanics}).

On the other hand, Metamath\index{Metamath} is less suited to applications
that deal primarily with intensive numeric computations.  Metamath does not
have any built-in representation of numbers\index{Metamath!representation of
numbers}; instead, a specific string of symbols (digits) must be syntactically
constructed as part of any proof in which an ordinary number is used.  For
this reason, numbers in Metamath are best limited to specific constants that
arise during the course of a theorem or its proof.  Numbers are only a tiny
part of the world of abstract mathematics.  The exclusion of built-in numbers
was a conscious decision to help achieve Metamath's simplicity, and there are
other software tools such as the computer algebra
programs\index{computer algebra system} {\sc
macsyma}\index{macsyma@{\sc macsyma}}, Mathematica\index{Mathematica}, and
Maple\index{Maple} specifically suited to handling numbers efficiently.

After learning Metamath's basic statement types, any
tech\-ni\-cal\-ly ori\-ent\-ed person, mathematician or not, can
immediately trace
any theorem proved in the language as far back as he or she wants, all the way
to the axioms on which the theorem is based.  This ability suggests a
non-traditional way of learning about pure mathematics.  Used in conjunction
with traditional methods, Metamath could make pure mathematics accessible to
people who are not sufficiently skilled to figure out the implicit detail in
ordinary textbook proofs.  Once you learn the axioms of a theory, you can have
complete confidence that everything you need to understand a proof you are
studying is all there, at your beck and call, allowing you to focus in on any
proof step you don't understand in as much depth as you need, without worrying
about getting stuck on a step you can't figure out.\footnote{On the other
hand, writing proofs in the Metamath language is challenging, requiring
a degree of rigor far in excess of that normally taught to students.  In a
classroom setting, I doubt that writing Metamath proofs would ever replace
traditional homework exercises involving informal proofs, because the time
needed to work out the details would not allow a course to
cover much material.  For students who have trouble grasping the implied rigor
in traditional material, writing a few simple proofs in the Metamath language
might help clarify fuzzy thought processes.  Although somewhat difficult at
first, it eventually becomes fun to do, like solving a puzzle, because of the
instant feedback provided by the computer.}

Metamath\index{Metamath} is probably unlike anything you have
encountered before.  In this first chapter we will look at the philosophy and
use of computers in mathematics in order to better understand the motivation
behind Metamath.  The material in this chapter is not required in order to use
Metamath.  You may skip it if you are impatient, but I hope you will find it
educational and enjoyable.  If you want to start experimenting with the
Metamath program right away, proceed directly to Chapter~\ref{using}
(p.~\pageref{using}).  To
learn the Metamath language, skim Chapter~\ref{using} then proceed to
Chapter~\ref{languagespec} (p.~\pageref{languagespec}).

\section{Mathematics as a Computer Language}

\begin{quote}
  {\em The study of mathematics is apt to commence in
dis\-ap\-point\-ment.\ldots We are told that by its aid the stars are weighted
and the billions of molecules in a drop of water are counted.  Yet, like the
ghost of Hamlet's father, this great science eludes the efforts of our mental
weapons to grasp it.}
  \flushright\sc  Alfred North Whitehead\footnote{\cite{Whitehead}, ch.\ 1}\\
\end{quote}\index{Whitehead, Alfred North}

\subsection{Is Mathematics ``User-Friendly''?}

Suppose you have no formal training in abstract mathematics.  But popular
books you've read offer tempting glimpses of this world filled with profound
ideas that have stirred the human spirit.  You are not satisfied with the
informal, watered-down descriptions you've read but feel it is important to
grasp the underlying mathematics itself to understand its true meaning. It's
not practical to go back to school to learn it, though; you don't want to
dedicate years of your life to it.  There are many important things in life,
and you have to set priorities for what's important to you.  What would happen
if you tried to pursue it on your own, in your spare time?

After all, you were able to learn a computer programming language such as
Pascal on your own without too much difficulty, even though you had no formal
training in computers.  You don't claim to be an expert in software design,
but you can write a passable program when necessary to suit your needs.  Even
more important, you know that you can look at anyone else's Pascal program, no
matter how complex, and with enough patience figure out exactly how it works,
even though you are not a specialist.  Pascal allows you do anything that a
computer can do, at least in principle.  Thus you know you have the ability,
in principle, to follow anything that a computer program can do:  you just
have to break it down into small enough pieces.

Here's an imaginary scenario of what might happen if you na\-ive\-ly a\-dopted
this same view of abstract mathematics and tried to pick it up on your own, in
a period of time comparable to, saying, learning a computer programming
language.

\subsubsection{A Non-Mathematician's Quest for Truth}

\begin{quote}
  {\em \ldots my daughters have been studying (chemistry) for several
se\-mes\-ters, think they have learned differential and integral calculus in
school, and yet even today don't know why $x\cdot y=y\cdot x$ is true.}
  \flushright\sc  Edmund Landau\footnote{\cite{Landau}, p.~vi}\\
\end{quote}\index{Landau, Edmund}

\begin{quote}
  {\em Minus times minus is plus,\\
The reason for this we need not discuss.}
  \flushright\sc W.\ H.\ Auden\footnote{As quoted in \cite{Guillen}, p.~64}\\
\end{quote}\index{Auden, W.\ H.}\index{Guillen, Michael}

We'll suppose you are technically oriented professional, perhaps an engineer, a
computer programmer, or a physicist, but probably not a mathematician.  You
consider yourself reasonably intelligent.  You did well in school, learning a
variety of methods and techniques in practical mathematics such as calculus and
differential equations.  But rarely did your courses get into anything
resembling modern abstract mathematics, and proofs were something that appeared
only occasionally in your textbooks, a kind of necessary evil that was
supposed to convince you of a certain key result.  Most of your
homework consisted of exercises that gave you practice in the techniques, and
you were hardly ever asked to come up with a proof of your own.

You find yourself curious about advanced, abstract mathematics.  You are
driven by an inner conviction that it is important to understand and
appreciate some of the most profound knowledge discovered by mankind.  But it
seems very hard to learn, something that only certain gifted longhairs can
access and understand.  You are frustrated that it seems forever cut off from
you.

Eventually your curiosity drives you to do something about it.
You set for yourself a goal of ``really'' understanding mathematics:  not just
how to manipulate equations in algebra or calculus according to cookbook
rules, but rather to gain a deep understanding of where those rules come from.
In fact, you're not thinking about this kind of ordinary mathematics at all,
but about a much more abstract, ethereal realm of pure mathematics, where
famous results such as G\"{o}del's incompleteness theorem\index{G\"{o}del's
incompleteness theorem} and Cantor's different kinds of infinities
reside.

You have probably read a number of popular books, with titles like {\em
Infinity and the Mind} \cite{Rucker}\index{Rucker, Rudy}, on topics such as
these.  You found them inspiring but at the same time somewhat
unsatisfactory.  They gave you a general idea of what these results are about,
but if someone asked you to prove them, you wouldn't have the faintest idea of
where to begin.   Sure, you could give the same overall outline that you
learned from the popular books; and in a general sort of way, you do have an
understanding.  But deep down inside, you know that there is a rigor that is
missing, that probably there are many subtle steps and pitfalls along the way,
and ultimately it seems you have to place your trust in the experts in the
field.  You don't like this; you want to be able to verify these results for
yourself.

So where do you go next?  As a first step, you decide to look up some of the
original papers on the theorems you are curious about, or better, obtain some
standard textbooks in the field.  You look up a theorem you want to
understand.  Sure enough, it's there, but it's expressed with strange
terms and odd symbols that mean absolutely nothing to you.  It might as well be written in
a foreign language you've never seen before, whose symbols are totally alien.
You look at the proof, and you haven't the foggiest notion what each step
means, much less how one step follows from another.  Well, obviously you have
a lot to learn if you want to understand this stuff.

You feel that you could probably understand it by
going back to college for another three to six years and getting a math
degree.  But that does not fit in with your career and the other things in
your life and would serve no practical purpose.  You decide to seek a quicker
path.  You figure you'll just trace your way back to the beginning, step by
step, as you would do with a computer program, until you understand it.  But
you quickly find that this is not possible, since you can't even understand
enough to know what you have to trace back to.

Maybe a different approach is in order---maybe you should start at the
beginning and work your way up.  First, you read the introduction to the book
to find out what the prerequisites are.  In a similar fashion, you trace your
way back through two or three more books, finally arriving at one that seems
to start at a beginning:  it lists the axioms of arithmetic.  ``Aha!'' you
naively think, ``This must be the starting point, the source of all mathematical
knowledge.'' Or at least the starting point for mathematics dealing with
numbers; you have to start somewhere and have no idea what the starting point
for other mathematics would be.  But the word ``axioms'' looks promising.  So
you eagerly read along and work through some elementary exercises at the
beginning of the book.  You feel vaguely bothered:  these
don't seem like axioms at all, at least not in the sense that you want to
think of axioms.  Axioms imply a starting point from which everything else can
be built up, according to precise rules specified in the axiom system.  Even
though you can understand first few proofs in an informal way,
and are able to do some of the
exercises, it's hard to pin down precisely what the
rules are.   Sure, each step seems to follow logically from the others, but
exactly what does that mean?  Is the ``logic'' just a matter of common sense,
something vague that we all understand but can never quite state precisely?

You've spent a number of years, off and on, programming computers, and you
know that in the case of computer languages there is no question of what the
rules are---they are precise and crystal clear.  If you follow them, your
program will work, and if you don't, it won't.  No matter how complex a
program, it can always be broken down into simpler and simpler pieces, until
you can ultimately identify the bits that are moved around to perform a
specific function.  Some programs might require a lot of perseverance to
accomplish this, but if you focus on a specific portion of it, you don't even
necessarily have to know how the rest of it works. Shouldn't there be an
analogy in mathematics?

You decide to apply the ultimate test:  you ask yourself how a computer could
verify or ensure that the steps in these proofs follow from one another.
Certainly mathematics must be at least as precisely defined as a computer
language, if not more so; after all, computer science itself is based on it.
If you can get a computer to verify these proofs, then you should also be
able, in principle, to understand them yourself in a very crystal clear,
precise way.

You're in for a surprise:  you can conceive of no way to convert the
proofs, which are in English, to a form that the computer can understand.
The proofs are filled with phrases such as ``assume there exists a unique
$x$\ldots'' and ``given any $y$, let $z$ be the number such that\ldots''  This
isn't the kind of logic you are used to in computer programming, where
everything, even arithmetic, reduces to Boolean ones and zeroes if you care to
break it down sufficiently.  Even though you think you understand the proofs,
there seems to be some kind of higher reasoning involved rather than precise
rules that define how you manipulate the symbols in the axioms.  Whatever it
is, it just isn't obvious how you would express it to a computer, and the more
you think about it, the more puzzled and confused you get, to the point where
you even wonder whether {\em you} really understand it.  There's a lot more to
these axioms of arithmetic than meets the eye.

Nobody ever talked about this in school in your applied math and engineering
courses.  You just learned the rules they gave you, not quite understanding
how or why they worked, sometimes vaguely suspicious or uncertain of them, and
through homework problems and osmosis learned how to present solutions that
satisfied the instructor and earned you an ``A.''  Rarely did you actually
``prove'' anything in a rigorous way, and the math majors who did do stuff
like that seemed to be in a different world.

Of course, there are computer algebra programs that can do mathematics, and
rather impressively.  They can instantly solve the integrals that you
struggled with in freshman calculus, and do much, much more.  But when you
look at these programs, what you see is a big collection of algorithms and
techniques that evolved and were added to over time, along with some basic
software that manipulates symbols.  Each algorithm that is built in is the
result of someone's theorem whose proof is omitted; you just have to trust the
person who proved it and the person who programmed it in and hope there are no
bugs.\index{computer program bugs}  Somehow this doesn't seem to be the
essence of mathematics.  Although computer algebra systems can generate
theorems with amazing speed, they can't actually prove a single one of them.

After some puzzlement, you revisit some popular books on what mathematics is
all about.  Somewhere you read that all of mathematics is actually derived
from something called ``set theory.''  This is a little confusing, because no
where in the book that presented the axioms of arithmetic was there any
mention of set theory, or if there was, it seemed to be just a tool that helps
you describe things better---the set of even numbers, that sort of thing.  If
set theory is the basis for all mathematics, then why are additional axioms
needed for arithmetic?

Something is wrong but you're not sure what.  One of your friends is a pure
mathematician.  He knows he is unable to communicate to you what he does for a
living and seems to have little interest in trying.  You do know that for him,
proofs are what mathematics is all about. You ask him what a proof is, and he
essentially tells you that, while of course it's based on logic, really it's
something you learn by doing it over and over until you pick it up.  He refers
you to a book, {\em How to Read and Do Proofs} \cite{Solow}.\index{Solow,
Daniel}  Although this book helps you understand traditional informal proofs,
there is still something missing you can't seem to pin down yet.

You ask your friend how you would go about having a computer verify a proof.
At first he seems puzzled by the question; why would you want to do that?
Then he says it's not something that would make any sense to do, but he's
heard that you'd have to break the proof down into thousands or even millions
of individual steps to do such a thing, because the reasoning involved is at
such a high level of abstraction.  He says that maybe it's something you could
do up to a point, but the computer would be completely impractical once you
get into any meaningful mathematics.  There, the only way you can verify a
proof is by hand, and you can only acquire the ability to do this by
specializing in the field for a couple of years in grad school.  Anyway, he
thinks it all has to do with set theory, although he has never taken a formal
course in set theory but just learned what he needed as he went along.

You are intrigued and amazed.  Apparently a mathematician can grasp as a
single concept something that would take a computer a thousand or a million
steps to verify, and have complete confidence in it.  Each one of these
thousand or million steps must be absolutely correct, or else the whole proof
is meaningless.  If you added a million numbers by hand, would you trust the
result?  How do you really know that all these steps are correct, that there
isn't some subtle pitfall in one of these million steps, like a bug in a
computer program?\index{computer program bugs}  After all, you've read that
famous mathematicians have occasionally made mistakes, and you certainly know
you've made your share on your math homework problems in school.

You recall the analogy with a computer program.  Sure, you can understand what
a large computer program such as a word processor does, as a single high-level
concept or a small set of such concepts, but your ability to understand it in
no way ensures that the program is correct and doesn't have hidden bugs.  Even
if you wrote the program yourself you can't really know this; most large
programs that you've written have had bugs that crop up at some later date, no
matter how careful you tried to be while writing them.

OK, so now it seems the reason you can't figure out how to make a
computer verify proofs is because each step really corresponds to a
million small steps.  Well, you say, a computer can do a million
calculations in a second, so maybe it's still practical to do.  Now the
puzzle becomes how to figure out what the million steps are that each
English-language step corresponds to.  Your mathematician friend hasn't
a clue, but suggests that maybe you would find the answer by studying
set theory.  Actually, your friend thinks you're a little off the wall
for even wondering such a thing.  For him, this is not what mathematics
is all about.

The subject of set theory keeps popping up, so you decide it's
time to look it up.

You decide to start off on a careful footing, so you start reading a couple of
very elementary books on set theory.  A lot of it seems pretty obvious, like
intersections, subsets, and Venn diagrams.  You thumb through one of the
books; nowhere is anything about axioms mentioned. The other book relegates to
an appendix a brief discussion that mentions a set of axioms called
``Zermelo-Fraenkel set theory''\index{Zermelo-Fraenkel set theory} and states
them in English.  You look at them and have no idea what they really mean or
what you can do with them.  The comments in this appendix say that the purpose
of mentioning them is to expose you to the idea, but imply that they are not
necessary for basic understanding and that they are really the subject matter
of advanced treatments where fine points such as a certain paradox (Russell's
paradox\index{Russell's paradox}\footnote{Russell's paradox assumes that there
exists a set $S$ that is a collection of all sets that don't contain
themselves.  Now, either $S$ contains itself or it doesn't.  If it contains
itself, it contradicts its definition.  But if it doesn't contain itself, it
also contradicts its definition.  Russell's paradox is resolved in ZF set
theory by denying that such a set $S$ exists.}) are resolved.  Wait a
minute---shouldn't the axioms be a starting point, not an ending point?  If
there are paradoxes that arise without the axioms, how do you know you won't
stumble across one accidentally when using the informal approach?

And nowhere do these books describe how ``all of mathematics can be
derived from set theory'' which by now you've heard a few times.

You find a more advanced book on set theory.  This one actually lists the
axioms of ZF set theory in plain English on page one.  {\em Now} you think
your quest has ended and you've finally found the source of all mathematical
knowledge; you just have to understand what it means.  Here, in one place, is
the basis for all of mathematics!  You stare at the axioms in awe, puzzle over
them, memorize them, hoping that if you just meditate on them long enough they
will become clear.  Of course, you haven't the slightest idea how the rest of
mathematics is ``derived'' from them; in particular, if these are the axioms
of mathematics, then why do arithmetic, group theory, and so on need their own
axioms?

You start reading this advanced book carefully, pondering the meaning of every
word, because by now you're really determined to get to the bottom of this.
The first thing the book does is explain how the axioms came about, which was
to resolve Russell's paradox.\index{Russell's paradox}  In fact that seems to
be the main purpose of their existence; that they supposedly can be used to
derive all of mathematics seems irrelevant and is not even mentioned.  Well,
you go on.  You hope the book will explain to you clearly, step by step, how
to derive things from the axioms.  After all, this is the starting point of
mathematics, like a book that explains the basics of a computer programming
language.  But something is missing.  You find you can't even understand the
first proof or do the first exercise.  Symbols such as $\exists$ and $\forall$
permeate the page without any mention of where they came from or how to
manipulate them; the author assumes you are totally familiar with them and
doesn't even tell you what they mean.  By now you know that $\exists$ means
``there exists'' and $\forall$ means ``for all,'' but shouldn't the rules for
manipulating these symbols be part of the axioms?  You still have no idea
how you could even describe the axioms to a computer.

Certainly there is something much different here from the technical
literature you're used to reading.  A computer language manual almost
always explains very clearly what all the symbols mean, precisely what
they do, and the rules used for combining them, and you work your way up
from there.

After glancing at four or five other such books, you come to the realization
that there is another whole field of study that you need just to get to the
point at which you can understand the axioms of set theory.  The field is
called ``logic.''  In fact, some of the books did recommend it as a
prerequisite, but it just didn't sink in.  You assumed logic was, well, just
logic, something that a person with common sense intuitively understood.  Why
waste your time reading boring treatises on symbolic logic, the manipulation
of 1's and 0's that computers do, when you already know that?  But this is a
different kind of logic, quite alien to you.  The subject of {\sc nand} and
{\sc nor} gates is not even touched upon or in any case has to do with only a
very small part of this field.

So your quest continues.  Skimming through the first couple of introductory
books, you get a general idea of what logic is about and what quantifiers
(``for all,'' ``there exists'') mean, but you find their examples somewhat
trivial and mildly annoying (``all dogs are animals,'' ``some animals are
dogs,'' and such).  But all you want to know is what the rules are for
manipulating the symbols so you can apply them to set theory.  Some formulas
describing the relationships among quantifiers ($\exists$ and $\forall$) are
listed in tables, along with some verbal reasoning to justify them.
Presumably, if you want to find out if a formula is correct, you go through
this same kind of mental reasoning process, possibly using images of dogs and
animals. Intuitively, the formulas seem to make sense.  But when you ask
yourself, ``What are the rules I need to get a computer to figure out whether
this formula is correct?'', you still don't know.  Certainly you don't ask the
computer to imagine dogs and animals.

You look at some more advanced logic books.  Many of them have an introductory
chapter summarizing set theory, which turns out to be a prerequisite.  You
need logic to understand set theory, but it seems you also need set theory to
understand logic!  These books jump right into proving rather advanced
theorems about logic, without offering the faintest clue about where the logic
came from that allows them to prove these theorems.

Luckily, you come across an elementary book of logic that, halfway through,
after the usual truth tables and metaphors, presents in a clear, precise way
what you've been looking for all along: the axioms!  They're divided into
propositional calculus (also called sentential logic) and predicate calculus
(also called first-order logic),\index{first-order logic} with rules so simple
and crystal clear that now you can finally program a computer to understand
them.  Indeed, they're no harder than learning how to play a game of chess.
As far as what you seem to need is concerned, the whole book could have been
written in five pages!

{\em Now} you think you've found the ultimate source of mathematical
truth.  So---the axioms of mathematics consist of these axioms of logic,
together with the axioms of ZF set theory. (By now you've also been able to
figure out how to translate the ZF axioms from English into the
actual symbols of logic which you can now manipulate according to
precise, easy-to-understand rules.)

Of course, you still don't understand how ``all of mathematics can be
derived from set theory,'' but maybe this will reveal itself in due
course.

You eagerly set out to program the axioms and rules into a computer and start
to look at the theorems you will have to prove as the logic is developed.  All
sorts of important theorems start popping up:  the deduction
theorem,\index{deduction theorem} the substitution theorem,\index{substitution
theorem} the completeness theorem of propositional calculus,\index{first-order
logic!completeness} the completeness theorem of predicate calculus.  Uh-oh,
there seems to be trouble.  They all get harder and harder, and not one of
them can be derived with the axioms and rules of logic you've just been
handed.  Instead, they all require ``metalogic'' for their proofs, a kind of
mixture of logic and set theory that allows you to prove things {\em about}
the axioms and theorems of logic rather than {\em with} them.

You plow ahead anyway.  A month later, you've spent much of your
free time getting the computer to verify proofs in propositional calculus.
You've programmed in the axioms, but you've also had to program in the
deduction theorem, the substitution theorem, and the completeness theorem of
propositional calculus, which by now you've resigned yourself to treating as
rather complex additional axioms, since they can't be proved from the axioms
you were given.  You can now get the computer to verify and even generate
complete, rigorous, formal proofs\index{formal proof}.  Never mind that they
may have 100,000 steps---at least now you can have complete, absolute
confidence in them.  Unfortunately, the only theorems you have proved are
pretty trivial and you can easily verify them in a few minutes with truth
tables, if not by inspection.

It looks like your mathematician friend was right.  Getting the computer to do
serious mathematics with this kind of rigor seems almost hopeless.  Even
worse, it seems that the further along you get, the more ``axioms'' you have
to add, as each new theorem seems to involve additional ``metamathematical''
reasoning that hasn't been formalized, and none of it can be derived from the
axioms of logic.  Not only do the proofs keep growing exponentially as you get
further along, but the program to verify them keeps getting bigger and bigger
as you program in more ``metatheorems.''\index{metatheorem}\footnote{A
metatheorem is usually a statement that is too general to be directly provable
in a theory.  For example, ``if $n_1$, $n_2$, and $n_3$ are integers, then
$n_1+n_2+n_3$ is an integer'' is a theorem of number theory.  But ``for any
integer $k > 1$, if $n_1, \ldots, n_k$ are integers, then $n_1+\ldots +n_k$ is
an integer'' is a metatheorem, in other words a family of theorems, one for
every $k$.  The reason it is not a theorem is that the general sum $n_1+\ldots
+n_k$ (as a function of $k$) is not an operation that can be defined directly
in number theory.} The bugs\index{computer program bugs} that have cropped up
so far have already made you start to lose faith in the rigor you seem to have
achieved, and you know its just going to get worse as your program gets larger.

\begin{center}
***
\end{center}

\subsection{Mathematics and the Non-Specialist}

\begin{quote}
  {\em A real proof is not checkable by a machine, or even by any mathematician
not privy to the gestalt, the mode of thought of the particular field of
mathematics in which the proof is located.}
  \flushright\sc  Davis and Hersh\index{Davis, Phillip J.}
  \footnote{\cite{Davis}, p.~354}\\
\end{quote}

The bulk of abstract or theoretical mathematics is ordinarily outside
the reach of anyone but a few specialists in each field who have completed
the necessary difficult internship in order to enter its coterie.  The
typical intelligent layperson has no reasonable hope of understanding much of
it, nor even the specialist mathematician of understanding other fields.  It
is like a foreign language that has no dictionary to look up the translation;
the only way you can learn it is by living in the country for a few years.  It
is argued that the effort involved in learning a specialty is a necessary
process for acquiring a deep understanding.  Of course, this is almost certainly
true if one is to make significant contributions to a field; in particular,
``doing'' proofs is probably the most important part of a mathematician's
training.  But is it also necessary to deny outsiders access to it?  Is it
necessary that abstract mathematics be so hard for a layperson to grasp?

A computer normally is of no help whatsoever.  Most published proofs are
actually just series of hints written in an informal style that requires
considerable knowledge of the field to understand.  These are the ``real
proofs'' referred to by Davis and Hersh.\index{informal proof}  There is an
implicit understanding that, in principle, such a proof could be converted to
a complete formal proof\index{formal proof}.  However, it is said that no one
would ever attempt such a conversion, even if they could, because that would
presumably require millions of steps (Section~\ref{dream}).  Unfortunately the
informal style automatically excludes the understanding of the proof
by anyone who hasn't gone through the necessary apprenticeship. The
best that the intelligent layperson can do is to read popular books about deep
and famous results; while this can be helpful, it can also be misleading, and
the lack of detail usually leaves the reader with no ability whatsoever to
explore any aspect of the field being described.

The statements of theorems often use sophisticated notation that makes them
inaccessible to the non-specialist.  For a non-specialist who wants to achieve
a deeper understanding of a proof, the process of tracing definitions and
lemmas back through their hierarchy\index{hierarchy} quickly becomes confusing
and discouraging.  Textbooks are usually written to train mathematicians or to
communicate to people who are already mathematicians, and large gaps in proofs
are often left as exercises to the reader who is left at an impasse if he or
she becomes stuck.

I believe that eventually computers will enable non-specialists and even
intelligent laypersons to follow almost any mathematical proof in any field.
Metamath is an attempt in that direction.  If all of mathematics were as
easily accessible as say a computer programming language, I could envision
computer programmers and hobbyists who otherwise lack mathematical
sophistication exploring and being amazed by the world of theorems and proofs
in obscure specialties, perhaps even coming up with results of their own.  A
tremendous advantage would be that anyone could experiment with conjectures in
any field---the computer would offer instant feedback as to whether
an inference step was correct.

Mathematicians sometimes have to put up with the annoyance of
cranks\index{cranks} who lack a fundamental understanding of mathematics but
insist that their ``proofs'' of, say, Fermat's Last Theorem\index{Fermat's
Last Theorem} be taken seriously.  I think part of the problem is that these
people are mislead by informal mathematical language, treating it as if they
were reading ordinary expository English and failing to appreciate the
implicit underlying rigor.  Such cranks are rare in the field of computers,
because computer languages are much more explicit, and ultimately the proof is
in whether a computer program works or not.  With easily accessible
computer-based abstract mathematics, a mathematician could say to a crank,
``don't bother me until you've demonstrated your claim on the computer!''

\subsection{An Impossible Dream?}\label{dream}

\begin{quote}
  {\em Even quite basic theorems would demand almost unbelievably vast
  books to display their proofs.}
    \flushright\sc  Robert E. Edwards\footnote{\cite{Edwards}, p.~68}\\
\end{quote}\index{Edwards, Robert E.}

\begin{quote}
  {\em Oh, of course no one ever really {\em does} it.  It would take
  forever!  You just show that you could do it, that's sufficient.}
    \flushright\sc  ``The Ideal Mathematician''
    \index{Davis, Phillip J.}\footnote{\cite{Davis},
p.~40}\\
\end{quote}

\begin{quote}
  {\em There is a theorem in the primitive notation of set theory that
  corresponds to the arithmetic theorem `$1000+2000=3000$'.  The formula
  would be forbiddingly long\ldots even if [one] knows the definitions
  and is asked to simplify the long formula according to them, chances are
  he will make errors and arrive at some incorrect result.}
    \flushright\sc  Hao Wang\footnote{\cite{Wang}, p.~140}\\
\end{quote}\index{Wang, Hao}

\begin{quote}
  {\em The {\em Principia Mathematica} was the crowing achievement of the
  formalists.  It was also the deathblow of the formalist view.\ldots\\
  {[Rus\-sell]} failed, in three enormous volumes, to get beyond the elementary
  facts of arithmetic.  He showed what can be done in principle and what
  cannot be done in practice.  If the mathematical process were really
  one of strict, logical progression, we would still be counting our
  fingers.\ldots\\
  One theoretician estimates, for instance, that a demonstration of one of
  Ramanujan's conjectures assuming set theory and elementary analysis would
  take about two thousand pages; the length of a deduction from first principles
  is nearly in\-con\-ceiv\-a\-ble\ldots The probabilists argue that\ldots any
  very long proof can at best be viewed as only probably correct\ldots}
  \flushright\sc Richard de Millo et. al.\footnote{\cite{deMillo}, pp.~269,
  271}\\
\end{quote}\index{de Millo, Richard}

A number of writers have conveyed the impression that the kind of absolute
rigor provided by Metamath\index{Metamath} is an impossible dream, suggesting
that a complete, formal verification\index{formal proof} of a typical theorem
would take millions of steps in untold volumes of books.  Even if it could be
done, the thinking sometimes goes, all meaning would be lost in such a
monstrous, tedious verification.\index{informal proof}\index{proof length}

These writers assume, however, that in order to achieve the kind of complete
formal verification they desire one must break down a proof into individual
primitive steps that make direct reference to the axioms.  This is
not necessary.  There is no reason not to make use of previously proved
theorems rather than proving them over and over.

Just as important, definitions\index{definition} can be introduced along the
way, allowing very complex formulas to be represented with few symbols.  Not
doing this can lead to absurdly long formulas.  For example, G\"{o}del's
incompleteness theorem\index{G\"{o}del's incompleteness theorem}, which can be
expressed with a small number of defined symbols, would require about 20,000
primitive symbols to express it.\index{Boolos, George S.}\footnote{George S.\
Boolos, lecture at Massachusetts Institute of Technology, spring 1990}  An
extreme example is Bourbaki's language for set theory, which requires tens of
thousands of symbols in a two-dimensional notation to express the number
``one'' \cite[p.~17]{Manin}.\index{Manin, Yu I.}\index{Bourbaki, Nicholaus}

A hierarchy\index{hierarchy} of theorems and definitions permits an
exponential growth in the formula sizes and primitive proof steps to be
described with only a linear growth in the number of symbols used.  Of course,
this is how ordinary informal mathematics is normally done anyway, but with
Metamath\index{Metamath} it can be done with absolute rigor and precision.

\subsection{Beauty}


\begin{quote}
  {\em No one shall be able to drive us from the paradise that Cantor has
created for us.}
   \flushright\sc  David Hilbert\footnote{As quoted in \cite{Moore}, p.~131}\\
\end{quote}\index{Hilbert, David}

\begin{quote}
  {\em Mathematics possesses not only truth, but some supreme beauty ---a
  beauty cold and austere, like that of a sculpture.}
    \flushright\sc  Bertrand
    Russell\footnote{\cite{Russell}}\\
\end{quote}\index{Russell, Bertrand}

\begin{quote}
  {\em Euclid alone has looked on Beauty bare.}
  \flushright\sc Edna Millay\footnote{As quoted in \cite{Davis}, p.~150}\\
\end{quote}\index{Millay, Edna}

For most people, abstract mathematics is distant, strange, and
incomprehensible.  Many popular books have tried to convey some of the sense
of beauty in famous theorems.  But even an intelligent layperson is left with
only a general idea of what a theorem is about and is hardly given the tools
needed to make use of it.  Traditionally, it is only after years of arduous
study that one can grasp the concepts needed for deep understanding.
Metamath\index{Metamath} allows you to approach the proof of the theorem from
a quite different perspective, peeling apart the formulas and definitions
layer by layer until an entirely different kind of understanding is achieved.
Every step of the proof is there, pieced together with absolute precision and
instantly available for inspection through a microscope with a magnification
as powerful as you desire.

A proof is itself can be considered an object of beauty.  Constructing an
elegant proof is an art.  Once a famous theorem has been proved, often
considerable effort is made to find simpler and more easily understood
proofs.  Creating and communicating elegant proofs is a major concern of
mathematicians.  Metamath is one way of providing a common language for
archiving and preserving this information.

The length of a proof can, to a certain extent, be considered an objective
measure of its ``beauty,'' since shorter proofs are usually considered more
elegant.  In the set theory database {\tt set.mm} provided with Metamath, one
goal was to make all proofs as short as possible.

\subsection{Simplicity}

\begin{quote}
  {\em God made man simple; man's complex problems are of his own
  devising.}
    \flushright\sc Eccles. 7:29\footnote{Jerusalem Bible}\\
\end{quote}\index{Bible}

\begin{quote}
  {\em God made integers, all else is the work of man.}
    \flushright\sc Leopold Kronecker\footnote{{\em Jahresberichte der
Deutschen Mathematicker Vereinigung}, bk. 2}\\
\end{quote}\index{Kronecker, Leopold}

\begin{quote}
  {\em For what is clear and easily comprehended attracts; the
  complicated repels.}
    \flushright\sc David Hilbert\footnote{As quoted in \cite{deMillo},
p.~273}\\
\end{quote}\index{Hilbert, David}

The Metamath\index{Metamath} language is simple and Spartan.  Metamath treats
all mathematical expressions as simple sequences of symbols, devoid of meaning.
The higher-level or ``metamathematical'' notions underlying Metamath are about
as simple as they could possibly be.  Each individual step in a proof involves
a single basic concept, the substitution of an expression for a variable, so
that in principle almost anyone, whether mathematician or not, can
completely understand how it was arrived at.

In one of its most basic applications, Metamath\index{Metamath} can be used to
develop the foundations of mathematics\index{foundations of mathematics} from
the very beginning.  This is done in the set theory database that is provided
with the Metamath package and is the subject matter
of Chapter~\ref{fol}. Any language (a metalanguage\index{metalanguage})
used to describe mathematics (an object language\index{object language}) must
have a mathematical content of its own, but it is desirable to keep this
content down to a bare minimum, namely that needed to make use of the
inference rules specified by the axioms.  With any metalanguage there is a
``chicken and egg'' problem somewhat like circular reasoning:  you must assume
the validity of the mathematics of the metalanguage in order to prove the
validity of the mathematics of the object language.  The mathematical content
of Metamath itself is quite limited.  Like the rules of a game of chess, the
essential concepts are simple enough so that virtually anyone should be able to
understand them (although that in itself will not let you play like
a master).  The symbols that Metamath manipulates do not in themselves
have any intrinsic meaning.  Your interpretation of the axioms that you supply
to Metamath is what gives them meaning.  Metamath is an attempt to strip down
mathematical thought to its bare essence and show you exactly how the symbols
are manipulated.

Philosophers and logicians, with various motivations, have often thought it
important to study ``weak'' fragments of logic\index{weak logic}
\cite{Anderson}\index{Anderson, Alan Ross} \cite{MegillBunder}\index{Megill,
Norman}\index{Bunder, Martin}, other unconventional systems of logic (such as
``modal'' logic\index{modal logic} \cite[ch.\ 27]{Boolos}\index{Boolos, George
S.}), and quantum logic\index{quantum logic} in physics
\cite{Pavicic}\index{Pavi{\v{c}}i{\'{c}}, M.}.  Metamath\index{Metamath}
provides a framework in which such systems can be expressed, with an absolute
precision that makes all underlying metamathematical assumptions rigorous and
crystal clear.

Some schools of philosophical thought, for example
intuitionism\index{intuitionism} and constructivism\index{constructivism},
demand that the notions underlying any mathematical system be as simple and
concrete as possible.  Metamath should meet the requirements of these
philosophies.  Metamath must be taught the symbols, axioms\index{axiom}, and
rules\index{rule} for a specific theory, from the skeptical (such as
intuitionism\index{intuitionism}\footnote{Intuitionism does not accept the law
of excluded middle (``either something is true or it is not true'').  See
\cite[p.~xi]{Tymoczko}\index{Tymoczko, Thomas} for discussion and references
on this topic.  Consider the theorem, ``There exist irrational numbers $a$ and
$b$ such that $a^b$ is rational.''  An intuitionist would reject the following
proof:  If $\sqrt{2}^{\sqrt{2}}$ is rational, we are done.  Otherwise, let
$a=\sqrt{2}^{\sqrt{2}}$ and $b=\sqrt{2}$. Then $a^b=2$, which is rational.})
to the bold (such as the axiom of choice in set theory\footnote{The axiom of
choice\index{Axiom of Choice} asserts that given any collection of pairwise
disjoint nonempty sets, there exists a set that has exactly one element in
common with each set of the collection.  It is used to prove many important
theorems in standard mathematics.  Some philosophers object to it because it
asserts the existence of a set without specifying what the set contains
\cite[p.~154]{Enderton}\index{Enderton, Herbert B.}.  In one foundation for
mathematics due to Quine\index{Quine, Willard Van Orman}, that has not been
otherwise shown to be inconsistent, the axiom of choice turns out to be false
\cite[p.~23]{Curry}\index{Curry, Haskell B.}.  The {\tt show
trace{\char`\_}back} command of the Metamath program allows you to find out
whether the axiom of choice, or any other axiom, was assumed by a
proof.}\index{{\tt show trace{\char`\_}back} command}).

The simplicity of the Metamath language lets the algorithm (computer program)
that verifies the validity of a Metamath proof to be straightforward and
robust.  You can have confidence that the theorems it verifies really can be
derived from your axioms.

\subsection{Rigor}

\begin{quote}
  {\em Rigor became a goal with the Greeks\ldots But the efforts to
  pursue rigor to the utmost have led to an impasse in which there is
  no longer any agreement on what it really means.  Mathematics remains
  alive and vital, but only on a pragmatic basis.}
    \flushright\sc  Morris Kline\footnote{\cite{Kline}, p.~1209}\\
\end{quote}\index{Kline, Morris}

Kline refers to a much deeper kind of rigor than that which we will discuss in
this section.  G\"{o}del's incompleteness theorem\index{G\"{o}del's
incompleteness theorem} showed that it is impossible to achieve absolute rigor
in standard mathematics because we can never prove that mathematics is
consistent (free from contradictions).\index{consistent theory}  If
mathematics is consistent, we will never know it, but must rely on faith.  If
mathematics is inconsistent, the best we can hope for is that some clever
future mathematician will discover the inconsistency.  In this case, the
axioms would probably be revised slightly to eliminate the inconsistency, as
was done in the case of Russell's paradox,\index{Russell's paradox} but the
bulk of mathematics would probably not be affected by such a discovery.
Russell's paradox, for example, did not affect most of the remarkable results
achieved by 19th-century and earlier mathematicians.  It mainly invalidated
some of Gottlob Frege's\index{Frege, Gottlob} work on the foundations of
mathematics in the late 1800's; in fact Frege's work inspired Russell's
discovery.  Despite the paradox, Frege's work contains important concepts that
have significantly influenced modern logic.  Kline's {\em Mathematics, The
Loss of Certainty} \cite{Klinel}\index{Kline, Morris} has an interesting
discussion of this topic.

What {\em can} be achieved with absolute certainty\index{certainty} is the
knowledge that if we assume the axioms are consistent and true, then the
results derived from them are true.  Part of the beauty of mathematics is that
it is the one area of human endeavor where absolute certainty can be achieved
in this sense.  A mathematical truth will remain such for eternity.  However,
our actual knowledge of whether a particular statement is a mathematical truth
is only as certain as the correctness of the proof that establishes it.  If
the proof of a statement is questionable or vague, we can't have absolute
confidence in the truth that the statement claims.

Let us look at some traditional ways of expressing proofs.

Except in the field of formal logic\index{formal logic}, almost all
traditional proofs in mathematics are really not proofs at all, but rather
proof outlines or hints as to how to go about constructing the proof.  Many
gaps\index{gaps in proofs} are left for the reader to fill in. There are
several reasons for this.  First, it is usually assumed in mathematical
literature that the person reading the proof is a mathematician familiar with
the specialty being described, and that the missing steps are obvious to such
a reader or at least that the reader is capable of filling them in.  This
attitude is fine for professional mathematicians in the specialty, but
unfortunately it often has the drawback of cutting off the rest of the world,
including mathematicians in other specialties, from understanding the proof.
We discussed one possible resolution to this on p.~\pageref{envision}.
Second, it is often assumed that a complete formal proof\index{formal proof}
would require countless millions of symbols (Section~\ref{dream}). This might
be true if the proof were to be expressed directly in terms of the axioms of
logic and set theory,\index{set theory} but it is usually not true if we allow
ourselves a hierarchy\index{hierarchy} of definitions and theorems to build
upon, using a notation that allows us to introduce new symbols, definitions,
and theorems in a precisely specified way.

Even in formal logic,\index{formal logic} formal proofs\index{formal proof}
that are considered complete still contain hidden or implicit information.
For example, a ``proof'' is usually defined as a sequence of
wffs,\index{well-formed formula (wff)}\footnote{A {\em wff} or well-formed
formula is a mathematical expression (string of symbols) constructed according
to some precise rules.  A formal mathematical system\index{formal system}
contains (1) the rules for constructing syntactically correct
wffs,\index{syntax rules} (2) a list of starting wffs called
axioms,\index{axiom} and (3) one or more rules prescribing how to derive new
wffs, called theorems\index{theorem}, from the axioms or previously derived
theorems.  An example of such a system is contained in
Metamath's\index{Metamath} set theory database, which defines a formal
system\index{formal system} from which all of standard mathematics can be
derived.  Section~\ref{startf} steps you through a complete example of a formal
system, and you may want to skim it now if you are unfamiliar with the
concept.} each of which is an axiom or follows from a rule applied to previous
wffs in the sequence.  The implicit part of the proof is the algorithm by
which a sequence of symbols is verified to be a valid wff, given the
definition of a wff.  The algorithm in this case is rather simple, but for a
computer to verify the proof,\index{automated proof verification} it must have
the algorithm built into its verification program.\footnote{It is possible, of
course, to specify wff construction syntax outside of the program itself
with a suitable input language (the Metamath language being an example), but
some proof-verification or theorem-proving programs lack the ability extend
wff syntax in such a fashion.} If one deals exclusively with axioms and
elementary wffs, it is straightforward to implement such an algorithm.  But as
more and more definitions are added to the theory in order to make the
expression of wffs more compact, the algorithm becomes more and more
complicated.  A computer program that implements the algorithm becomes larger
and harder to understand as each definition is introduced, and thus more prone
to bugs.\index{computer program bugs}  The larger the program, the
more suspicious the mathematician may be about
the validity of its algorithms.  This is especially true because
computer programs are inherently hard to follow to begin with, and few people
enjoy verifying them manually in detail.

Metamath\index{Metamath} takes a different approach.  Metamath's ``knowledge''
is limited to the ability to substitute variables for expressions, subject to
some simple constraints.  Once the basic algorithm of Metamath is assumed to
be debugged, and perhaps independently confirmed, it
can be trusted once and for all.  The information that Metamath needs to
``understand'' mathematics is contained entirely in the body of knowledge
presented to Metamath.  Any errors in reasoning can only be errors in the
axioms or definitions contained in this body of knowledge.  As a
``constructive'' language\index{constructive language} Metamath has no
conditional branches or loops like the ones that make computer programs hard
to decipher; instead, the language can only build new sequences of symbols
from earlier sequences  of symbols.

The simplicity of the rules that underlie Metamath not only makes Metamath
easy to learn but also gives Metamath a great deal of flexibility. For
example, Metamath is not limited to describing standard first-order
logic\index{first-order logic}; higher-order logics\index{higher-order logic}
and fragments of logic\index{weak logic} can be described just as easily.
Metamath gives you the freedom to define whatever wff notation you prefer; it
has no built-in conception of the syntax of a wff.\index{well-formed formula
(wff)}  With suitable axioms and definitions, Metamath can even describe and
prove things about itself.\index{Metamath!self-description}  (John
Harrison\index{Harrison, John} discusses the ``reflection''
principle\index{reflection principle} involved in self-descriptive systems in
\cite{Harrison}.)

The flexibility of Metamath requires that its proofs specify a lot of detail,
much more than in an ordinary ``formal'' proof.\index{formal proof}  For
example, in an ordinary formal proof, a single step consists of displaying the
wff that constitutes that step.  In order for a computer program to verify
that the step is acceptable, it first must verify that the symbol sequence
being displayed is an acceptable wff.\index{automated proof verification} Most
proof verifiers have at least basic wff syntax built into their programs.
Metamath has no hard-wired knowledge of what constitutes a wff built into it;
instead every wff must be explicitly constructed based on rules defining wffs
that are present in a database.  Thus a single step in an ordinary formal
proof may be correspond to many steps in a Metamath proof. Despite the larger
number of steps, though, this does not mean that a Metamath proof must be
significantly larger than an ordinary formal proof. The reason is that since
we have constructed the wff from scratch, we know what the wff is, so there is
no reason to display it.  We only need to refer to a sequence of statements
that construct it.  In a sense, the display of the wff in an ordinary formal
proof is an implicit proof of its own validity as a wff; Metamath just makes
the proof explicit. (Section~\ref{proof} describes Metamath's proof notation.)

\section{Computers and Mathematicians}

\begin{quote}
  {\em The computer is important, but not to mathematics.}
    \flushright\sc  Paul Halmos\footnote{As quoted in \cite{Albers}, p.~121}\\
\end{quote}\index{Halmos, Paul}

Pure mathematicians have traditionally been indifferent to computers, even to
the point of disdain.\index{computers and pure mathematics}  Computer science
itself is sometimes considered to fall in the mundane realm of ``applied''
mathematics, perhaps essential for the real world but intellectually unexciting
to those who seek the deepest truths in mathematics.  Perhaps a reason for this
attitude towards computers is that there is little or no computer software that
meets their needs, and there may be a general feeling that such software could
not even exist.  On the one hand, there are the practical computer algebra
systems, which can perform amazing symbolic manipulations in algebra and
calculus,\index{computer algebra system} yet can't prove the simplest
existence theorem, if the idea of a proof is present at all.  On the other
hand, there are specialized automated theorem provers that technically speaking
may generate correct proofs.\index{automated theorem proving}  But sometimes
their specialized input notation may be cryptic and their output perceived to
be long, inelegant, incomprehensible proofs.    The output
may be viewed with suspicion, since the program that generates it tends to be
very large, and its size increases the potential for bugs\index{computer
program bugs}.  Such a proof may be considered trustworthy only if
independently verified and ``understood'' by a human, but no one wants to
waste their time on such a boring, unrewarding chore.



\subsection{Trusting the Computer}

\begin{quote}
  {\em \ldots I continue to find the quasi-empirical interpretation of
  computer proofs to be the more plausible.\ldots Since not
  everything that claims to be a computer proof can be
  accepted as valid, what are the mathematical criteria for acceptable
  computer proofs?}
    \flushright\sc  Thomas Tymoczko\footnote{\cite{Tymoczko}, p.~245}\\
\end{quote}\index{Tymoczko, Thomas}

In some cases, computers have been essential tools for proving famous
theorems.  But if a proof is so long and obscure that it can be verified in a
practical way only with a computer, it is vaguely felt to be suspicious.  For
example, proving the famous four-color theorem\index{four-color
theorem}\index{proof length} (``a map needs no more than four colors to
prevent any two adjacent countries from having the same color'') can presently
only be done with the aid of a very complex computer program which originally
required 1200 hours of computer time. There has been considerable debate about
whether such a proof can be trusted and whether such a proof is ``real''
mathematics \cite{Swart}\index{Swart, E. R.}.\index{trusting computers}

However, under normal circumstances even a skeptical mathematician would a have
a great deal of confidence in the result of multiplying two numbers on a pocket
calculator, even though the precise details of what goes on are hidden from its
user.  Even the verification on a supercomputer that a huge number is prime is
trusted, especially if there is independent verification; no one bothers to
debate the philosophical significance of its ``proof,'' even though the actual
proof would be so large that it would be completely impractical to ever write
it down on paper.  It seems that if the algorithm used by the computer is
simple enough to be readily understood, then the computer can be trusted.

Metamath\index{Metamath} adopts this philosophy.  The simplicity of its
language makes it easy to learn, and because of its simplicity one can have
essentially absolute confidence that a proof is correct. All axioms, rules, and
definitions are available for inspection at any time because they are defined
by the user; there are no hidden or built-in rules that may be prone to subtle
bugs\index{computer program bugs}.  The basic algorithm at the heart of
Metamath is simple and fixed, and it can be assumed to be bug-free and robust
with a degree of confidence approaching certainty.  (An independently written
implementation of Metamath could pretty much eliminate any residual doubt on
the part of a skeptic.)

\subsection{Trusting the Mathematician}

\begin{quote}
  {\em There is no Algebraist nor Mathematician so expert in his science, as
  to place entire confidence in any truth immediately upon his discovery of it,
  or regard it an any thing, but a mere probability.  Every time he runs over
  his proofs, his confidence encreases; but still more by the approbation of
  his friends; and is rais'd to its utmost perfection by the universal assent
  and applauses of the learned world.}
  \flushright\sc David Hume\footnote{{\em A Treatise of Human Nature}, as
  quoted in \cite{deMillo}, p.~267}\\
\end{quote}\index{Hume, David}

\begin{quote}
  {\em Stanislaw Ulam estimates that mathematicians publish 200,000 theorems
  every year.  A number of these are subsequently contradicted or otherwise
  disallowed, others are thrown into doubt, and most are ignored.}
  \flushright\sc Richard de Millo et. al.\footnote{\cite{deMillo}, p.~269}\\
\end{quote}\index{Ulam, Stanislaw}

Whether or not the computer can be trusted, humans  of course will occasionally
err. Only the most memorable proofs get independently verified, and of these
only a handful of truly great ones achieve the status of being ``known''
mathematical truths that are used without giving a second thought to their
correctness.

There are many famous examples of incorrect theorems and proofs in
mathematical literature.\index{errors in proofs}

\begin{itemize}
\item There have been thousands of purported proofs of Fermat's Last
Theorem\index{Fermat's Last Theorem} (``no integer solutions exist to $x^n +
y^n = z^n$ for $n > 2$''), by amateurs, cranks, and well-regarded
mathematicians \cite[p.~5]{Stark}\index{Stark, Harold M}.  Fermat wrote a note
in his copy of Bachet's {\em Diophantus} that he found ``a truly marvelous
proof of this theorem but this margin is too narrow to contain it''
\cite[p.~507]{Kramer}.  A recent, much publicized proof by Yoichi
Miyaoka\index{Miyaoka, Yoichi} was shown to be incorrect ({\em Science News},
April 9, 1988, p.~230).  The theorem was finally proved by Andrew
Wiles\index{Wiles, Andrew} ({\em Science News}, July 3, 1993, p.~5), but it
initially had some gaps and took over a year after its announcement to be
checked thoroughly by experts.  On Oct. 25, 1994, Wiles announced that the last
gap found in his proof had been filled in.
  \item In 1882, M. Pasch discovered that an axiom was omitted from Euclid's
formulation of geometry\index{Euclidean geometry}; without it, the proofs of
important theorems of Euclid are not valid.  Pasch's axiom\index{Pasch's
axiom} states that a line that intersects one side of a triangle must also
intersect another side, provided that it does not touch any of the triangle's
vertices.  The omission of Pasch's axiom went unnoticed for 2000
years \cite[p.~160]{Davis}, in spite of (one presumes) the thousands of
students, instructors, and mathematicians who studied Euclid.
  \item The first published proof of the famous Schr\"{o}der-Berstein
theorem\index{Schr\"{o}der-Berstein theorem} in set theory was incorrect
\cite[p.~148]{Enderton}\index{Enderton, Herbert B.}.  This theorem states
that if there exists a function\footnote{A {\em set}\index{set} is any
collection of objects. A {\em function}\index{function} or {\em
mapping}\index{mapping} is a rule that assigns to each element of one set
(called the function's {\em domain}\index{domain}) an element from another
set.} from set $A$ onto set $B$ and vice-versa, then sets $A$ and $B$ can be
put into one-to-one correspondence.  Although it sounds simple and obvious,
the standard proof is quite long and complex.
  \item In the early 1900's, Hilbert\index{Hilbert, David} published a
purported proof of the continuum hypothesis\index{continuum hypothesis}, which
was eventually established as unprovable by Cohen\index{Cohen, Paul} in 1963
\cite[p.~166]{Enderton}.  The continuum hypothesis states that no
infinity\index{infinity} (``transfinite cardinal number'')\index{cardinal,
transfinite} exists whose size (or ``cardinality''\index{cardinality}) is
between the size of the set of integers and the size of the set of real
numbers.  This hypothesis originated with German mathematician Georg
Cantor\index{Cantor, Georg} in the late 1800's, and his inability to prove it
is said to have contributed to mental illness that afflicted him in his later
years.
  \item An incorrect proof of the four-color theorem\index{four-color theorem}
was published by Kempe\index{Kempe, A. B.} in 1879
\cite[p.~582]{Courant}\index{Courant, Richard}; it stood for 11 years before
its flaw was discovered.  This theorem states that any map can be colored
using only four colors, so that no two adjacent countries have the same
color.  In 1976 the theorem was finally proved by the famous computer-assisted
proof of Haken, Appel, and Koch \cite{Swart}\index{Appel, K.}\index{Haken,
W.}\index{Koch, K.}.  Or at least it seems that way.  Mathematician
H.~S.~M.~Coxeter\index{Coxeter, H. S. M.} has doubts \cite[p.~58]{Davis}:  ``I
have a feeling that is an untidy kind of use of the computers, and the more
you correspond with Haken and Appel, the more shaky you seem to be.''
  \item Many false ``proofs'' of the Poincar\'{e}
conjecture\index{Poincar\'{e} conjecture} have been proposed over the years.
This conjecture states that any object that mathematically behaves like a
three-dimensional sphere is a three-dimensional sphere topologically,
regardless of how it is distorted.  In March 1986, mathematicians Colin
Rourke\index{Rourke, Colin} and Eduardo R\^{e}go\index{R\^{e}go, Eduardo}
caused  a stir in the mathematical community by announcing that they had found
a proof; in November of that year the proof was found to be false \cite[p.
218]{PetersonI}.  The conjecture remains unproven.
 \end{itemize}

Some other counterexamples to ``theorems'' in current mathematical
literature are given on the Web page
\begin{verbatim}
      http://www.math.hut.fi/~lounesto/counterexamples.htm
\end{verbatim}

One of the purposes of Metamath\index{Metamath} is to allow proofs to be
expressed with absolute precision.  Developing a proof in the Metamath
language can be challenging, because Metamath will not permit even the
tiniest mistake.\index{errors in proofs}  But once the proof is created, its
correctness can be trusted immediately, without having to depend on the
process of peer review for confirmation.

\section{The Use of Computers in Mathematics}

\subsection{Computer Algebra Systems}

For the most part, you will find that Metamath\index{Metamath} is not a
practical tool for manipulating numbers.  (Even proving that $2 + 2 = 4$, if
you start with set theory, can be quite complex!)  Several commercial
mathematics packages are quite good at arithmetic, algebra, and calculus, and
as practical tools they are invaluable.\index{computer algebra system} But
they have no notion of proof, and cannot understand statements starting with
``there exists such and such...''.

Software packages such as Mathematica \cite{Wolfram}\index{Mathematica} do not
concern themselves with proofs but instead work directly with known results.
These packages primarily emphasize heuristic rules such as the substitution of
equals for equals to achieve simpler expressions or expressions in a different
form.  Starting with a rich collection of built-in rules and algorithms, users
can add to the collection by means of a powerful programming language.
However, results such as, say, the existence of a certain abstract object
without displaying the actual object cannot be expressed (directly) in their
languages.  The idea of a proof from a small set of axioms is absent.  Instead
this software simply assumes that each fact or rule you add to the built-in
collection of algorithms is valid.  One way to view the software is as a large
collection of axioms from which the software, with certain goals, attempts to
derive new theorems, for example equating a complex expression with a simpler
equivalent. But the terms ``theorem''\index{theorem} and
``proof,''\index{proof} for example, are not even mentioned in the index of
the user's manual for Mathematica.\index{Mathematica and proofs}  What is also
unsatisfactory from a philosophical point of view is that there is no way to
ensure the validity of the results other than by trusting the writer of each
application module or tediously checking each module by hand, similar to
checking a computer program for bugs.\index{computer program
bugs}\footnote{Two examples illustrate why the knowledge database of computer
algebra systems should sometimes be regarded with a certain caution.  If you
ask Mathematica (version 3.0) to {\tt Solve[x\^{ }n + y\^{ }n == z\^{ }n , n]}
it will respond with {\tt \{\{n-\char`\>-2\}, \{n-\char`\>-1\},
\{n-\char`\>1\}, \{n-\char`\>2\}\}}. In other words, Mathematica seems to
``know'' that Fermat's Last Theorem\index{Fermat's Last Theorem} is true!  (At
the time this version of Mathematica was released this fact was unknown.)  If
you ask Maple\index{Maple} to {\tt solve(x\^{ }2 = 2\^{ }x)} then {\tt
simplify(\{"\})}, it returns the solution set {\tt \{2, 4\}}, apparently
unaware that 0.7666647\ldots is also a solution.} While of course extremely
valuable in applied mathematics, computer algebra systems tend to be of little
interest to the theoretical mathematician except as aids for exploring certain
specific problems.

Because of possible bugs, trusting the output of a computer algebra system for
use as theorems in a proof-verifier would defeat the latter's goal of rigor.
On the other hand, a fact such that a certain relatively large number is
prime, while easy for a computer algebra system to derive, might have a long,
tedious proof that could overwhelm a proof-verifier. One approach for linking
computer algebra systems to a proof-verifier while retaining the advantages of
both is to add a hypothesis to each such theorem indicating its source.  For
example, a constant {\sc maple} could indicate the theorem came from the Maple
package, and would mean ``assuming Maple is consistent, then\ldots''  This and
many other topics concerning the formalization of mathematics are discussed in
John Harrison's\index{Harrison, John} very interesting
PhD thesis~\cite{Harrison-thesis}, available
on the Web.

\subsection{Automated Theorem Provers}\label{theoremprovers}

A mathematical theory is ``decidable''\index{decidable theory} if a mechanical
method or algorithm exists that is guaranteed to determine whether or not a
particular formula is a theorem.  Among the few theories that are decidable is
elementary geometry,\index{Euclidean geometry} as was shown by a classic
result of logician Alfred Tarski\index{Tarski, Alfred} in 1948
\cite{Tarski}.\footnote{Tarski's result actually applies to a subset of the
geometry discussed in elementary textbooks.  This subset includes most of what
would be considered elementary geometry but it is not powerful enough to
express, among other things, the notions of the circumference and area of a
circle.  Extending the theory in a way that includes notions such as these
makes the theory undecidable, as was also shown by Tarski.  Tarski's algorithm
is far too inefficient to implement practically on a computer.  A practical
algorithm for proving a smaller subset of geometry theorems (those not
involving concepts of ``order'' or ``continuity'') was discovered by Chinese
mathematician Wu Wen-ts\"{u}n in 1977 \cite{Chou}\index{Chou,
Shang-Ching}.}\index{Wen-ts{\"{u}}n, Wu}  But most theories, including
elementary arithmetic, are undecidable.  This fact contributes to keeping
mathematics alive and well, since mathematicians know that they will never be
replaced by computers (providing one believes Roger Penrose's argument that a
computer can never replace the brain \cite{Penrose}\index{Penrose, Roger}). In
fact,  elementary geometry is often considered a ``dead'' field for the simple
reason that it is decidable.

On the other hand, the undecidability of a theory does not mean that one cannot
use a computer to search for proofs, providing one is willing to give up if a
proof is not found after a reasonable amount of time.  The field of automated
theorem proving\index{automated theorem proving} specializes in pursuing such
computer searches.  Among the more successful results to date are those based
on an algorithm known as Robinson's resolution principle
\cite{Robinson}\index{Robinson's resolution principle}.

Automated theorem provers can be excellent tools for those willing to learn
how to use them.  But they are not widely used in mainstream pure
mathematics, even though they could probably be useful in many areas.  There
are several reasons for this.  Probably most important, the main goal in pure
mathematics is to arrive at results that are considered to be deep or
important; proving them is essential but secondary.  Usually, an automated
theorem prover cannot assist in this main goal, and by the time the main goal
is achieved, the mathematician may have already figured out the proof as a
by-product.  There is also a notational problem.  Mathematicians are used to
using very compact syntax where one or two symbols (heavily dependent on
context) can represent very complex concepts; this is part of the
hierarchy\index{hierarchy} they have built up to tackle difficult problems.  A
theorem prover on the other hand might require that a theorem be expressed in
``first-order logic,''\index{first-order logic} which is the logic on which
most of mathematics is ultimately based but which is not ordinarily used
directly because expressions can become very long.  Some automated theorem
provers are experimental programs, limited in their use to very specialized
areas, and the goal of many is simply research into the nature of automated
theorem proving itself.  Finally, much research remains to be done to enable
them to prove very deep theorems.  One significant recent result was a
computer proof by Larry Wos\index{Wos, Larry} and colleagues that every Robbins
algebra\index{Robbins algebra} is a Boolean  algebra\index{Boolean algebra}
({\em New York Times}, Dec. 10, 1996).\footnote{In 1933, E.~V.\
Huntington\index{Huntington, E. V.}
presented the following axiom system for
Boolean algebra with a unary operation $n$ and a binary operation $+$:
\begin{center}
    $x + y = y + x$ \\
    $(x + y) + z = x + (y + z)$ \\
    $n(n(x) + y) + n(n(x) + n(y)) = x$
\end{center}
Herbert Robbins\index{Robbins, Herbert}, a student of Huntington, conjectured
that the last equation can be replaced with a simpler one:
\begin{center}
    $n(n(x + y) + n(x + n(y))) = x$
\end{center}
Robbins and Huntington could not find a proof.  The problem was
later studied unsucessfully by Tarski\index{Tarski, Alfred} and his
students, and it remained an unsolved problem until a
computer found the proof in 1996.  For more information on
the Robbins algebra problem see \cite{Wos}.}

How does Metamath\index{Metamath} relate to automated theorem provers?  A
theorem prover is primary concerned with one theorem at a time (perhaps
tapping into a small database of known theorems) whereas Metamath is more like
a theorem archiving system, storing both the theorem and its proof in a
database for access and verification.  Metamath is one answer to ``what do you
do with the output of a theorem prover?''  and could be viewed as the
next step in the process.  Automated theorem provers could be useful tools for
helping develop its database, although as of this writing there are no
software translation tools that do this.  Note that very long, automatically
generated proofs can make your database fat and ugly and cause Metamath's proof
verification to take a long time to run.  Unless you have a particularly good
program that generates very concise proofs, it might be best to consider the
use of automatically generated proofs as a quick-and-dirty approach, to be
manually rewritten at some later date.

If you are interested in automatic theorem provers, two well-regarded programs
are Isabelle\footnote{Isabelle is available on the Internet via anonymous ftp
to {\tt ftp.cl.cam.ac.uk} in the directory {\tt ml}. Read the instructions in
the file {\tt isabelle.txt}.}\index{Isabelle} and {\sc otter}.

{\sc otter}\index{otter@{\sc otter}} is available on a disk included with the
book {\em Automated Reasoning:  Introduction and Applications}
\cite{Wos}\index{Wos, Larry}.  This program not only is able to generate
relatively efficient proofs, it can even be instructed to search for shorter
proofs.  The effective use of {\sc otter} does require a certain amount of
experience, skill, and patience.  The axiom system used in the {\tt
set.mm}\index{set theory database ({\tt set.mm})} set theory database can be
expressed to {\sc otter} using a method described in
\cite{Megill}.\index{Megill, Norman}\footnote{To use those axioms with {\sc
otter}, they must be restated in a way that eliminates the need for ``dummy
variables.''\index{dummy variable!eliminating} See the Comment on
p.~\pageref{nodd}.} When successful, this method tends to generate short and
clever proofs, but my experiments with it indicate that the method will find
proofs within a reasonable time only for relatively easy theorems.  It is
still fun to experiment with.

Reference \cite{Bledsoe}\index{Bledsoe, W. W.} surveys a number of approaches
people have explored in the field of automated theorem proving\index{automated
theorem proving}.


\subsection{Proof Verifiers}\label{proofverifiers}

A proof verifier is a program that doesn't generate proofs but instead
verifies proofs that you give it.  Many proof verifiers have limited built-in
automated proof capabilities, such as figuring out simple logical inferences
(while still being guided by a person who provides the overall proof).  Metamath
has no built-in automated proof capability other than the limited
capability of its Proof Assisitant.

Proof-verification languages are not used as frequently as they might be.
Pure mathematicians are more concerned with producing new results, and such
detail and rigor would interfere with that goal.  The use of computers in pure
mathematics is primarily focused on automated theorem provers (not verifiers),
again with the ultimate goal of aiding the creation of new mathematics.
Automated theorem provers are usually concerned with attacking one theorem at
time rather than making a large, organized database easily available to the
user.  Metamath is one way to help close this gap.

Besides Metamath, there are several other on-going projects with the goal of
formalizing mathematics into computer-verifiable databases. One such project
is {\sc qed},\index{qed project@{\sc qed} project} and several mathematicians
are currently working to agree on a the requirements for a universal language.
Information on this project is available via anonymous ftp to
{\tt info.mcs.anl.gov}; discussions reside in {\tt /pub/qed/archives}, and the
goals of the project are described in the file {\tt /pub/qed/manifesto}.  One
specific proof-verification language is Mizar,\index{Mizar} which can display
its proofs in the informal language that mathematicians are accustomed to.
Information on the Mizar language is available via anonymous ftp to {\tt
ftp.cs.ualberta.ca} in the directory {\tt pub/Mizar}.

Other higher-level proof verification languages are {\sc lcf}\index{lcf@{\sc
lcf}} and {\sc hol};\index{hol@{\sc hol}} a good overview of these and others
is given in \cite{Harrison}.  All of these languages are fundamentally
different from Metamath in that much of the mathematical foundational
knowledge is embedded in the underlying proof-verification program, rather
than placed directly in the database that is being verified.  For the working
mathematician these languages are often more practical to use than Metamath,
but they can have a steep learning curve for those without a mathematical
background.  For example, one usually must have a fair understanding of
mathematical logic in order to follow their proofs.

For the working mathematician, Mizar is an excellent tool for rigorously
documenting proofs. Mizar typesets its proofs in the informal English used by
mathematicians (and, while fine for them, are just as inscrutable by
laypersons!). A price paid for Mizar is a relatively steep learning curve of a
couple of weeks.  Several mathematicians are actively formalizing different
areas of mathematics using Mizar and publishing the proofs in a dedicated
journal. Unfortunately the task of formalizing mathematics is still looked
down upon to a certain extent since it doesn't involve the creation of new
mathematics.

To summarize our discussions of computers and mathematics, computer algebra
systems can be viewed as theorem generators focusing on a narrow realm of
mathematics (numbers and their properties), automated theorem provers as proof
generators for specific theorems in a much broader realm covered by a built-in
formal system such as first-order logic, proof verifiers in general as proof
documentors usually restricted to first-order logic, and Metamath in
particular as a proof documentor whose realm is essentially unlimited.


\section{Mathematics and Metamath}

\subsection{Standard Mathematics}

There are a number of ways that Metamath\index{Metamath} can be used with
standard mathematics.  The most satisfying way philosophically is the start at
the very beginning, and develop the desired mathematics from the axioms of
logic and set theory.\index{set theory}  This is the approach taken in the
{\tt set.mm}\index{set theory database ({\tt set.mm})} module provided with
the Metamath software.  Among other things, this module builds up to the
axioms of real and complex numbers\index{analysis}\index{real and complex
numbers} (see Section~\ref{real}), and a standard development of analysis, for
example, could start at that point, using it as a basis.   Besides this
philosophical advantage, there are practical advantages to having all of the
tools of set theory available in the supporting infrastructure.

On the other hand, you may wish to start with the standard axioms of a
mathematical theory without going through the set theoretical proofs of those
axioms.  You will need mathematical logic to make inferences, but if you wish
you can simply introduce theorems\index{theorem} of logic as
``axioms''\index{axiom} wherever you need them, with the implicit assumption
that in principle they can be proved, if they are obvious to you.  If you
choose this approach, you will probably want to review the notation used in
{\tt set.mm}\index{set theory database ({\tt set.mm})} so that your own
notation will be consistent with it.

\subsection{Other Formal Systems}
\index{formal system}

Unlike some programs, Metamath\index{Metamath} is not limited to any specific
area of mathematics, nor committed to any particular mathematical philosophy
such as classical logic versus intuitionism, nor limited, say, to expressions
in first-order logic.  Although the database {\tt set.mm} included with the
Metamath software package describes standard logic and set theory, Meta\-math
is actually a general-purpose language for describing a wide variety of formal
systems.\index{formal system}  Non-standard systems such as modal
logic,\index{modal logic} intuitionist logic\index{intuitionism}, higher-order
logic\index{higher-order logic}, quantum logic\index{quantum logic}, and
category theory\index{category theory} can all be described with the Metamath
language.  You define the symbols you prefer and tell Metamath the axioms and
rules you want to start from, and Metamath will verify any inferences you make
from those axioms and rules.  A simple example of a non-standard formal system
is Hofstadter's\index{Hofstadter, Douglas R.} MIU system,\index{MIU-system}
whose Metamath description is presented in Appendix~\ref{MIU}.

Since the days of David Hilbert,\index{Hilbert, David} mathematicians have
been concerned with the fact the metalanguage\index{metalanguage} used to
describe mathematics may be stronger than the mathematics being described.
Metamath\index{Metamath}'s underlying finitary\index{finitary proof},
constructive nature provides a good philosophical basis for studying even the
weakest logics.\index{weak logic}

Actually, the usual treatment of many non-standard formal systems\index{formal
system} uses model theory\index{model theory} or proof theory\index{proof
theory} to describe these systems; these theories, in turn, are based on
standard set theory.  In other words, a non-standard formal system is defined
as a set with certain properties, and standard set theory is used to derive
additional properties of this set.  The standard set theory database provided
with Metamath can be used for this purpose, and the development of a special
axiom system for the non-standard formal system becomes unnecessary.  The
model- or proof-theoretic approach often allows you to prove much deeper
results with less effort.

%\section{Additional Remarks}


\subsection{Metamath and Its Philosophy}

Closely related to Metamath\index{Metamath} is a philosophy or way of looking
at mathematics. This philosophy is related to the formalist
philosophy\index{formalism} of Hilbert\index{Hilbert, David} and his followers
\cite[pp.~1203--1208]{Kline}\index{Kline, Morris}
\cite[p.~6]{Behnke}\index{Behnke, H.}. In this philosophy, mathematics is
viewed as nothing more than a set of rules that manipulate symbols, together
with the consequences of those rules.  While the mathematics being described
may be complex, the rules used to describe it (the
``metamathematics''\index{metamathematics}) should be as simple as possible.
In particular, proofs should be restricted to dealing with concrete objects
(the symbols we write on paper rather than the abstract concepts they
represent) in a constructive manner; these are called ``finitary''
proofs\index{finitary proof} \cite[pp.~2--3]{Shoenfield}\index{Shoenfield,
Joseph R.}.

Whether or not you find Metamath interesting or useful will in part depend on
the appeal you find in its philosophy, and this appeal will probably depend on
your particular goals with respect to mathematics.  For example, if you are a
pure mathematician at the forefront of discovering new mathematical knowledge,
you will probably find that the rigid formality of Metamath stifles your
creativity.  On the other hand, we would argue that once this knowledge is
discovered, there are advantages to documenting it in a standard format that
will make it accessible to others.  In 60 years from now, your field may be
dormant, and as Davis and Hersh put it, your ``writings would become less
translatable than those of the Maya'' \cite[p.~37]{Davis}\index{Davis, Phillip
J.}.


\subsection{A History of the Approach Behind Metamath}

Probably the one work that has had the most motivating influence on
Metamath\index{Metamath} is Whitehead and Russell's monumental {\em Principia
Mathematica} \cite{PM}\index{Whitehead, Alfred North}\index{Russell,
Bertrand}\index{principia mathematica@{\em Principia Mathematica}}, whose aim
was to deduce all of mathematics from a small number of primitive ideas, in a
very explicit way that in principle anyone could understand and follow.  While
this work was tremendously influential in its time, from a modern perspective
it suffers from several drawbacks.  Both its notation and its underlying
axioms are now considered dated and are no longer used.  From our point of
view, its development is not really as accessible as we would like to see; for
practical reasons, proofs become more and more sketchy as its mathematics
progresses, and working them out in fine detail requires a degree of
mathematical skill and patience that many people don't have.  There are
numerous small errors, which is understandable given the tedious, technical
nature of the proofs and the lack of a computer to verify the details.
However, even today {\em Principia Mathematica} stands out as the work closest
in spirit to Metamath.  It remains a mind-boggling work, and one can't help
but be amazed at seeing ``$1+1=2$'' finally appear on page 83 of Volume II
(Theorem *110.643).

The origin of the proof notation used by Metamath dates back to the 1950's,
when the logician C.~A.~Meredith expressed his proofs in a compact notation
called ``condensed detachment''\index{condensed detachment}
\cite{Hindley}\index{Hindley, J. Roger} \cite{Kalman}\index{Kalman, J. A.}
\cite{Meredith}\index{Meredith, C. A.} \cite{Peterson}\index{Peterson, Jeremy
George}.  This notation allows proofs to be communicated unambiguously by
merely referencing the axiom\index{axiom}, rule\index{rule}, or
theorem\index{theorem} used at each step, without explicitly indicating the
substitutions\index{substitution!variable}\index{variable substitution} that
have to be made to the variables in that axiom, rule, or theorem.  Ordinarily,
condensed detachment is more or less limited to propositional
calculus\index{propositional calculus}.  The concept has been extended to
first-order logic\index{first-order logic} in \cite{Megill}\index{Megill,
Norman}, making it is easy to write a small computer program to verify proofs
of simple first-order logic theorems.\index{condensed detachment!and
first-order logic}

A key concept behind the notation of condensed detachment is called
``unification,''\index{unification} which is an algorithm for determining what
substitutions\index{substitution!variable}\index{variable substitution} to
variables have to be made to make two expressions match each other.
Unification was first precisely defined by the logician J.~A.~Robinson, who
used it in the development of a powerful
theorem-proving technique called the ``resolution principle''
\cite{Robinson}\index{Robinson's resolution principle}. Metamath does not make
use of the resolution principle, which is intended for systems of first-order
logic.\index{first-order logic}  Metamath's use is not restricted to
first-order logic, and as we have mentioned it does not automatically discover
proofs.  However, unification is a key idea behind Metamath's proof
notation, and Metamath makes use of a very simple version of it
(Section~\ref{unify}).

\subsection{Metamath and First-Order Logic}

First-order logic\index{first-order logic} is the
supporting structure for standard mathematics.  On top of it is set theory,
which contains the axioms from which virtually all of mathematics can be
derived---a remarkable fact.\index{Russell's paradox}\index{category
theory}\index{cardinal, inaccessible}\index{proper
class}\index{class!proper}\footnote{An exception seems to be category theory.
There are several schools of thought on whether category theory is derivable
from set theory.  At a minimum, it appears that an additional axiom is needed
that asserts the existence of an ``inaccessible cardinal'' (a type of infinity
so large that standard set theory can't prove or deny that it exists).  But it
is also argued that not just one but a ``proper class'' of them is needed, and
the existence of proper classes is impossible in standard set theory.  (A
proper class is a collection of sets so huge that no set can contain it as an
element.  Proper classes can lead to inconsistencies such as ``Russell's
paradox.''  The axioms of standard set theory are devised so as to deny the
existence of proper classes.)  For more information, see
\cite[pp.~328--331]{Herrlich}\index{Herrlich, Horst} and
\cite{Blass}\index{Blass, Andrea}.}

One of the things that makes Metamath\index{Metamath} more practical for
first-order theories is a set of axioms for first-order logic designed
specifically with Metamath's approach in mind.  These are included in a
standard database called {\tt set.mm}\index{set theory database ({\tt set.mm})}
which comes with the Metamath software.  See Chapter~\ref{fol} for a detailed
description; the axioms are shown in Section~\ref{metaaxioms}.  While
logically equivalent to standard axiom systems, our axiom system breaks
up the standard axioms into smaller pieces such that from them, you can
directly derive what in other systems can only be derived as higher-level
``metatheorems.''\index{metatheorem}  In other words, it is more powerful than
the standard axioms from a metalogical point of view.  A rigorous
justification for this system and its ``metalogical
completeness''\index{metalogical completeness} is found in
\cite{Megill}\index{Megill, Norman}.  The system is closely related to a
system developed by Monk\index{Monk, J. Donald} and Tarski\index{Tarski,
Alfred} in 1965 \cite{Monks}.

For example, the formula $\exists x \, x = y $ (given $y$, there exists some
$x$ equal to it) is a theorem of logic,\footnote{Specifically, it is a theorem
of those systems of logic that assume non-empty domains.  It is not a theorem
of more general systems that include the empty domain\index{empty domain}, in
which nothing exists, period!  Such systems are called ``free
logics.''\index{free logic} For a discussion of these systems, see
\cite{Leblanc}\index{Leblanc, Hugues}.  Since our use for logic is as a basis
for set theory, which has a non-empty domain, it is more convenient (and more
traditional) to use a less general system.  An interesting curiosity is that,
using a free logic as a basis for Zermelo-Fraenkel set
theory\index{Zermelo-Fraenkel set theory} (with the redundant Axiom of the
Null Set omitted),\index{Axiom of the Null Set} we cannot even prove the
existence of a single set without assuming the axiom of infinity!\index{Axiom
of Infinity}} whether or not $x$ and $y$ are distinct variables\index{distinct
variables}.  In many systems of logic, we would have to prove two theorems to
arrive at this result.  First we would prove ``$\exists x \, x = x $,'' then
we would separately prove ``$\exists x \, x = y $, where $x$ and $y$ are
distinct variables.''  We would then combine these two special cases ``outside
of the system'' (i.e.\ in our heads) to be able to claim, ``$\exists x \, x =
y $, regardless of whether $x$ and $y$ are distinct.''  In other words, in the
combination of the two special cases is a
metatheorem.  In the system of logic
used in Metamath's set theory\index{set theory database ({\tt set.mm})}
database, the axioms of logic are broken down into small pieces that allow
them to reassembled in such a way that theorems such as these can be proved
directly.

Breaking down the axioms in this way makes them look peculiar and not very
intuitive at first, but rest assured that they are correct and complete.  Their
correctness is ensured because they are theorem schemes of standard first-order
logic (which you can easily verify if you are a logician).  Their completeness
follows from the fact that we explicitly derive the standard axioms of
first-order logic as theorems.  Deriving the standard axioms is somewhat
tricky, but once we're there, we have at our disposal a system that is less
awkward to work with in formal proofs\index{formal proof}.  In technical terms
that logicians understand, we eliminate the cumbersome concepts of ``free
variable,''\index{free variable} ``bound variable,''\index{bound variable} and
``proper substitution''\index{proper substitution}\index{substitution!proper}
as primitive notions.  These concepts are present in our system but are
defined in terms of concepts expressed by the axioms and can be eliminated in
principle.  In standard systems, these concepts are really like additional,
implicit axioms\index{implicit axiom} that are somewhat complex and cannot be
eliminated.

The traditional approach to logic, wherein free variables and proper
substitution is defined, is also possible to do directly in the Metamath
language.  However the notation tends to become awkward and there are
disadvantages; for example, extending the definition of wffs becomes more
complex when definitions are added because the free variable and proper
substitution concepts have to have their definitions extended for each new wff
introduced by a definition.  Our choice of axioms for {\tt set.mm} is to a
certain extent a matter of style, in an attempt to achieve overall simplicity,
but you should also be aware that the traditional approach is possible as well
if you should choose it.

\chapter{Using the Metamath Program}
\label{using}

\section{Installation}

The way that you install Metamath\index{Metamath!installation} on your
computer system is different for different computers.  A separate set of
installation instructions for your specific computer is provided with the
Metamath software.  In general, the installation is simple.  There is one file
containing the Metamath program itself.  This file is usually called {\tt
metamath} or {\tt metamath.}{\em xxx} where {\em xxx} is the convention (such
as {\tt exe}) for an executable program on your operating system.  There are
several additional files containing samples of the Metamath language, all
ending with {\tt .mm}.  The file {\tt set.mm}\index{set theory database ({\tt
set.mm})} contains logic and set theory and can be used as a starting point
for other areas of mathematics.

You will also need a text editor\index{text editor} capable of editing plain
{\sc ascii}\footnote{American Standard for Coded Information Interchange} text
in order to prepare your input files.\index{ascii@{\sc ascii}}  Most computers
have this capability built in.  Note that plain text is not necessarily the
default for some word processing programs\index{word processor}, especially if
they can handle different fonts; for example, with Microsoft Word\index{Word
(Microsoft)}, you must save the file in the format ``Text Only With Line
Breaks'' to get a plain text\index{plain text} file.\footnote{It is
recommended that all lines in a Metamath source file be 79 characters or less
in length for compatibility among different computer terminals.  When creating
a source file on an editor such as Word, select a monospaced
font\index{monospaced font} such as Courier\index{Courier font} or
Monaco\index{Monaco font} to make this easier to achieve.}

On some computer systems, Metamath does not have the capability to print its
output directly; instead, you send its output to a file (using the
{\tt open} commands described later).  The way you
print this file depends on your computer.\index{printers}  Some computers have
a print command, whereas with others, you may have to read the file into an
editor and print it from there.

If you want to print your Metamath source files with typeset formulas
containing standard mathematical symbols, you will need the \LaTeX\
typesetting program.\index{latex@{\LaTeX}}  Otherwise you will have to
be content with the {\sc ascii} representations of the symbols, which
may seem a little cryptic until you get used to them.

If you choose \LaTeX , you will need AMSFonts.  These fonts are available
from the American Mathematical Society
for a modest price.\index{AMSFonts}

Sources for all of the software that we have mentioned are listed in
Appendix~\ref{swsources}.

\section{Your First Formal System}\label{start}
\subsection{From Nothing to Zero}\label{startf}

To give you a feel for what the Metamath\index{Metamath} language looks like,
we will take a look at a very simple example from formal number
theory\index{number theory}.  This example is taken from
Mendelson\index{Mendelson, Elliot} \cite[p. 123]{Mendelson}.\footnote{To keep
the example simple, we have changed the formalism slightly, and what we call
axioms\index{axiom} are strictly speaking theorems\index{theorem} in
\cite{Mendelson}.}  We will look at a small subset of this theory, namely that
part needed for the first number theory theorem proved in \cite{Mendelson}.

First we will look at a standard formal proof\index{formal proof} for the
example we have picked, then we will look at the Metamath version.  If you
have never been exposed to formal proofs, the notation may seem to be such
overkill to express such simple notions that you may wonder if you are missing
something.  You aren't.  The concepts involved are in fact very simple, and a
detailed breakdown in this fashion is necessary to express the proof in a way
that can be verified mechanically.  And as you will see, Metamath breaks the
proof down into even finer pieces so that the mechanical verification process
can be about as simple as possible.

Before we can introduce the axioms\index{axiom} of the theory, we must define
the syntax rules for forming legal expressions\index{syntax rules}
(combinations of symbols) with which those axioms can be used. The number 0 is
a {\bf term}\index{term}; and if $ t$ and $r$ are terms, so is $(t+r)$. Here,
$ t$ and $r$ are ``metavariables''\index{metavariable} ranging over terms; they
themselves do not appear as symbols in an actual term.  Some examples of
actual terms are $(0 + 0)$ and $((0+0)+0)$.  (Note that our theory describes
only the number zero and sums of zeroes.  Of course, not much can be done with
such a trivial theory, but remember that we have picked a very small subset of
complete number theory for our example.  The important thing for you to focus
on is our definitions that describe how symbols are combined to form valid
expressions, and not on the content or meaning of those expressions.) If $ t$
and $r$ are terms, an expression of the form $ t=r$ is a {\bf wff}
(well-formed formula)\index{well-formed formula (wff)}; and if $P$ and $Q$ are
wffs, so is $(P\rightarrow Q)$ (which means ``$P$ implies
$Q$''\index{implication ($\rightarrow$)} or ``if $P$ then $Q$'').
Here $P$ then $Q$ are metavariables ranging over wffs.  Examples of actual
wffs are $0=0$, $(0+0)=0$, $(0=0 \rightarrow (0+0)=0)$, and $(0=0\rightarrow
(0=0\rightarrow 0=(0+0)))$.  (Our notation makes use of more parentheses than
are customary, but the elimination of ambiguity this way simplifies our
example by avoiding the need to define operator precedence\index{operator
precedence}.)

The {\bf axioms}\index{axiom} of our theory are all wffs of the following
form, where $ t$, $r$, and $s$ are any terms:

%Latex p. 92
\renewcommand{\theequation}{A\arabic{equation}}

\begin{equation}
(t=r\rightarrow (t=s\rightarrow r=s))
\end{equation}
\begin{equation}
(t+0)=t
\end{equation}

Note that there are an infinite number of axioms since there are an infinite
number of possible terms.  A1 and A2 are properly called ``axiom
schemes,''\index{axiom scheme} but we will refer to them as ``axioms'' for
brevity.

An axiom is a {\bf theorem}; and if $P$ and $(P\rightarrow Q)$ are theorems
(where $P$ and $Q$ are wffs), then $Q$ is also a theorem.\index{theorem}  The
second part of this definition is called the modus ponens (MP) rule of
inference\index{inference rule}\index{modus ponens}.  It allows us to obtain
new theorems from old ones.

The {\bf proof}\index{proof} of a theorem is a sequence of one or more
theorems, each of which is either an axiom or the result of modus ponens
applied to two previous theorems in the sequence, and the last of which is the
theorem being proved.

The theorem we will prove for our example is very simple:  $ t=t$.  The proof of
our theorem follows.  Study it carefully until you feel sure you
understand it.\label{zeroproof}
\\[\baselineskip]
\begin{tabular}{lll}
1.&$(t+0)=t$&(by axiom A2)\\
2.&$(t+0)=t$&(by axiom A2)\\
3.&$((t+0)=t\rightarrow ((t+0)=t\rightarrow t=t))$&(by axiom A1)\\
4.&$((t+0)=t\rightarrow t=t)$&(by MP applied to\\
{}&{}&steps 2 and 3)\\
5.&$ t=t$&(by MP applied to\\
{}&{}&steps 1 and 4)
\end{tabular}
\\[\baselineskip]
(You may wonder why step 1 is repeated twice.  This is not necessary in the
formal language we have defined, but in Metamath's ``reverse Polish
notation''\index{reverse Polish notation (RPN)} for proofs, a previous step
can be referred to only once.  The repetition of step 1 here will enable you
to see more clearly the correspondence of this proof with the
Metamath\index{Metamath} version on p.~\pageref{demoproof}.)

Our theorem is more properly called a ``theorem scheme,''\index{theorem
scheme} for it represents an infinite number of theorems, one for each
possible term $ t$.  Two examples of actual theorems would be $0=0$ and
$(0+0)=(0+0)$.  Rarely do we prove actual theorems, since by proving schemes
we can prove an infinite number of theorems in one fell swoop.  Similarly, our
proof should really be called a ``proof scheme.''\index{proof scheme}  To
obtain an actual proof, pick an actual term to use in place of $ t$, and
substitute it for $ t$ throughout the proof.

Let's discuss what we have done here.  The axioms\index{axiom} of our theory,
A1 and A2, are trivial and obvious.  Everyone knows that adding zero to
something doesn't change it, and also that if two things are equal to a third,
then they are equal to each other. In fact, stating the trivial and obvious is
a goal to strive for in any axiomatic system.  From trivial and obvious truths
that everyone agrees upon, we can prove results that are not so obvious yet
have absolute faith in them.  If we trust the axioms and the rules, we must,
by definition, trust the consequences of those axioms and rules, if logic is
to mean anything at all.

Our rule of inference\index{rule}, modus ponens\index{modus ponens}, is also
pretty obvious once you understand what it means.  If we prove a fact $P$, and
we also prove that $P$ implies $Q$, then $Q$ necessarily follows as a new
fact.  The rule provides us with a means for obtaining new facts (i.e.\
theorems\index{theorem}) from old ones.

The theorem that we have proved, $ t=t$, is so fundamental that you may wonder
why it isn't one of the axioms\index{axiom}.  In some axiom systems of
arithmetic, it {\em is} an axiom.  The choice of axioms in a theory is to some
extent arbitrary and even an art form, constrained only by the requirement
that any two equivalent axiom systems be able to derive each other as
theorems.  We could imagine that the inventor of our axiom system originally
included $ t=t$ as an axiom, then discovered that it could be derived as a
theorem from the other axioms.  Because of this, it was not necessary to
keep it as an axiom.  By eliminating it, the final set of axioms became
that much simpler.

Unless you have worked with formal proofs\index{formal proof} before, it
probably wasn't apparent to you that $ t=t$ could be derived from our two
axioms until you saw the proof. While you certainly believe that $ t=t$ is
true, you might not be able to convince an imaginary skeptic who believes only
in our two axioms until you produce the proof.  Formal proofs such as this are
hard to come up with when you first start working with them, but after you get
used to them they can become interesting and fun.  Once you understand the
idea behind formal proofs you will have grasped the fundamental principle that
underlies all of mathematics.  As the mathematics becomes more sophisticated,
its proofs become more challenging, but ultimately they all can be broken down
into individual steps as simple as the ones in our proof above.

Mendelson's\index{Mendelson, Elliot} book, from which our example was taken,
contains a number of detailed formal proofs such as these, and you may be
interested in looking it up.  The book is intended for mathematicians,
however, and most of it is rather advanced.  Popular literature describing
formal proofs\index{formal proof} include \cite[p.~296]{Rucker}\index{Rucker,
Rudy} and \cite[pp.~204--230]{Hofstadter}\index{Hofstadter, Douglas R.}.

\subsection{Converting It to Metamath}\label{convert}

Formal proofs\index{formal proof} such as the one in our example break down
logical reasoning into small, precise steps that leave little doubt that the
results follow from the axioms\index{axiom}.  You might think that this would
be the finest breakdown we can achieve in mathematics.  However, there is more
to the proof than meets the eye. Although our axioms were rather simple, a lot
of verbiage was needed before we could even state them:  we needed to define
``term,'' ``wff,'' and so on.  In addition, there are a number of implied
rules that we haven't even mentioned. For example, how do we know that step 3
of our proof follows from axiom A1? There is some hidden reasoning involved in
determining this.  Axiom A1 has two occurrences of the letter $ t$.  One of
the implied rules states that whatever we substitute for $ t$ must be a legal
term\index{term}.\footnote{Some authors make this implied rule explicit by
stating, ``only expressions of the above form are terms,'' after defining
``term.''}  The expression $ t+0$ is pretty obviously a legal term whenever $
t$ is, but suppose we wanted to substitute a huge term with thousands of
symbols?  Certainly a lot of work would be involved in determining that it
really is a term, but in ordinary formal proofs all of this work would be
considered a single ``step.''

To express our axiom system in the Metamath\index{Metamath} language, we must
describe this auxiliary information in addition to the axioms themselves.
Metamath does not know what a ``term'' or a ``wff''\index{well-formed formula
(wff)} is.  In Metamath, the specification of the ways in which we can combine
symbols to obtain terms and wffs are like little axioms in themselves.  These
auxiliary axioms are expressed in the same notation as the ``real''
axioms\index{axiom}, and Metamath does not distinguish between the two.  The
distinction is made by you, i.e.\ by the way in which you interpret the
notation you have chosen to express these two kinds of axioms.

The Metamath language breaks down mathematical proofs into tiny pieces, much
more so than in ordinary formal proofs\index{formal proof}.  If a single
step\index{proof step} involves the
substitution\index{substitution!variable}\index{variable substitution} of a
complex term for one of its variables, Metamath must see this single step
broken down into many small steps.  This fine-grained breakdown is what gives
Metamath generality and flexibility as it lets it not be limited to any
particular mathematical notation.

Metamath's proof notation is not, in itself, intended to be read by humans but
rather is in a compact format intended for a machine.  The Metamath program
will convert this notation to a form you can understand, using the {\tt show
proof}\index{{\tt show proof} command} command.  You can tell the program what
level of detail of the proof you want to look at.  You may want to look at
just the logical inference steps that correspond
to ordinary formal proof steps,
or you may want to see the fine-grained steps that prove that an expression is
a term.

Here, without further ado, is our example converted to the
Metamath\index{Metamath} language:\index{metavariable}\label{demo0}

\begin{verbatim}

        $( Declare the constant symbols we will use $)
            $c 0 + = -> ( ) term wff |- $.
        $( Declare the metavariables we will use $)
            $v t r s P Q $.
        $( Specify properties of the metavariables $)
            tt $f term t $.
            tr $f term r $.
            ts $f term s $.
            wp $f wff P $.
            wq $f wff Q $.
        $( Define "term" and "wff" $)
            tze $a term 0 $.
            tpl $a term ( t + r ) $.
            weq $a wff t = r $.
            wim $a wff ( P -> Q ) $.
        $( State the axioms $)
            a1 $a |- ( t = r -> ( t = s -> r = s ) ) $.
            a2 $a |- ( t + 0 ) = t $.
        $( Define the modus ponens inference rule $)
            ${
               min $e |- P $.
               maj $e |- ( P -> Q ) $.
               mp  $a |- Q $.
            $}
        $( Prove a theorem $)
            th1 $p |- t = t $=
          $( Here is its proof: $)
               tt tze tpl tt weq tt tt weq tt a2 tt tze tpl
               tt weq tt tze tpl tt weq tt tt weq wim tt a2
               tt tze tpl tt tt a1 mp mp
             $.
\end{verbatim}\index{metavariable}

A ``database''\index{database} is a set of one or more {\sc ascii} source
files.  Here's a brief description of this Metamath\index{Metamath} database
(which consists of this single source file), so that you can understand in
general terms what is going on.  To understand the source file in detail, you
should read Chapter~\ref{languagespec}.

The database is a sequence of ``tokens,''\index{token} which are normally
separated by spaces or carriage returns.  The only tokens that are built into
the Metamath language are those beginning with {\tt \$}.  These tokens
are called ``keywords.''\index{keyword}  All other tokens are
user-defined, and their names are arbitrary.

As you might have guessed, the Metamath token {\tt \$(}\index{{\tt \$(} and
{\tt \$)} auxiliary keywords} starts a comment and {\tt \$)} ends a comment.

The Metamath tokens {\tt \$c}\index{{\tt \$c} statement}, {\tt \$v}\index{{\tt
\$v} statement}, {\tt \$e}\index{{\tt \$e} statement}, {\tt \$f}\index{{\tt
\$f} statement}, {\tt \$a}\index{{\tt \$a} statement}, and {\tt
\$p}\index{{\tt \$p} statement} specify ``statements'' that end with {\tt
\$.}\,.\index{{\tt \$.}\ keyword}

The Metamath tokens {\tt \$c} and {\tt \$v} each declare\index{constant
declaration}\index{variable declaration} a list of user-defined tokens, called
``math symbols,''\index{math symbol} that the database will reference later
on.  All of the math symbols they define you have seen earlier except the
turnstile symbol {\tt |-} ($\vdash$)\index{turnstile ({$\,\vdash$})}, which is
commonly used by logicians to mean ``a proof exists for.''  For us
the turnstile is just a
convenient symbol that distinguishes expressions that are axioms\index{axiom}
or theorems\index{theorem} from expressions that are terms or wffs.

The {\tt \$c} statement declares ``constants''\index{constant} and the {\tt
\$v} statement declares ``variables''\index{variable}\index{constant
declaration}\index{variable declaration} (or more precisely,
metavariables\index{metavariable}).  A variable may be
substituted\index{substitution!variable}\index{variable substitution} with
sequences of math symbols whereas a constant may not be substituted with
anything.

It may seem redundant to require both {\tt \$c}\index{{\tt \$c} statement} and
{\tt \$v}\index{{\tt \$v} statement} statements (since any math
symbol\index{math symbol} not specified with a {\tt \$c} statement could be
presumed to be a variable), but this provides for better error checking and
also allows math symbols to be redeclared\index{redeclaration of symbols}
(Section~\ref{scoping}).

The token {\tt \$f}\index{{\tt \$f} statement} specifies a statement called a
``variable-type hypothesis'' (also called a ``floating hypothesis'') and {\tt
\$e}\index{{\tt \$e} statement} specifies a ``logical hypothesis'' (also
called an ``essential hypothesis'').\index{hypothesis}\index{variable-type
hypothesis}\index{logical hypothesis}\index{floating
hypothesis}\index{essential hypothesis}  The token {\tt \$a}\index{{\tt \$a}
statement} specifies an ``axiomatic assertion,''\index{axiomatic assertion}
and {\tt \$p}\index{{\tt \$p} statement} specifies a ``provable
assertion.''\index{provable assertion}  To the left of each occurrence of
these four tokens is a ``label''\index{label} that identifies the hypothesis
or assertion for later reference.  For example, the label of the first
axiomatic assertion is {\tt tze}.  A {\tt \$f} statement must contain
exactly two math symbols, a constant followed by a variable.  The {\tt \$e},
{\tt \$a}, and {\tt \$p} statements each start with a constant followed by, in
general, an arbitrary sequence of math symbols.

Associated with each assertion\index{assertion} is a set of hypotheses that
must be satisfied in order for the assertion to be used in a proof.  These are
called the ``mandatory hypotheses''\index{mandatory hypothesis} of the
assertion.  Among those hypotheses whose ``scope'' (described below) includes
the assertion, {\tt \$e} hypotheses are always mandatory and {\tt
\$f}\index{{\tt \$f} statement} hypotheses are mandatory when they share their
variable with the assertion or its {\tt \$e} hypotheses.  The exact rules for
determining which hypotheses are mandatory are described in detail in
Sections~\ref{frames} and \ref{scoping}. For example, the mandatory hypotheses
of assertion {\tt tpl} are {\tt tt} and {\tt tr}, whereas assertion {\tt tze}
has no mandatory hypotheses because it contains no variables and has no {\tt
\$e}\index{{\tt \$e} statement} hypothesis.  Metamath's {\tt show statement}
command\index{{\tt show statement} command}, described in the next section,
will show you a statement's mandatory hypotheses.

Sometimes we need to make a hypothesis relevant to only certain assertions.
The set of statements to which a hypothesis is relevant is called its
``scope.'' The Metamath brackets, {\tt \$\char`\{}\index{{\tt \$\char`\{} and {\tt \$\char`\}}
keywords} and {\tt \$\char`\}}, define a ``block''\index{block} that delimits
the scope of any hypothesis contained between them.  The assertion {\tt mp} has
mandatory hypotheses {\tt wp}, {\tt wq}, {\tt min}, and {\tt maj}.  The only
mandatory hypothesis of {\tt th1}, on the other hand, is {\tt tt}, since {\tt
th1} occurs outside of the block containing {\tt min} and {\tt maj}.

Note that {\tt \$\char`\{} and {\tt \$\char`\}} do not affect the
scope of assertions ({\tt \$a} and {\tt \$p}).  Assertions are always
available to be referenced by any later proof in the source file.

Each provable assertion ({\tt \$p}\index{{\tt \$p} statement} statement) has
two parts.  The first part is the assertion\index{assertion} itself, which is
a sequence of math symbol\index{math symbol} tokens placed between the {\tt
\$p} token and a {\tt \$=}\index{{\tt \$=} keyword} token.  The second part is
a ``proof,'' which is a list of label tokens placed between the {\tt \$=}
token and the {\tt \$.}\index{{\tt \$.}\ keyword}\ token that ends the
statement.\footnote{If you've looked at the {\tt set.mm} database, you may
have noticed another notation used for proofs. The other notation is called
``compressed.''\index{compressed proof}\index{proof!compressed}  It reduces
the amount of space needed to store a proof in the database and is described in
Appendix~\ref{compressed}.  In the example above, we use
``normal''\index{normal proof}\index{proof!normal} notation.} The proof acts
as a series of instructions to the Metamath program, telling it how to build
up the sequence of math symbols contained in assertion part of the {\tt \$p}
statement, making use of the hypotheses of the {\tt \$p} statement and
previous assertions.  The construction takes place according to precise rules.
If the list of labels in the proof causes these rules to be violated, or if
the final sequence that results does not match the assertion, the Metamath
program will notify you with an error message.

If you are familiar with reverse Polish notation (RPN), which is sometimes used
on pocket calculators, here in a nutshell is how a proof works.  Each
hypothesis label\index{hypothesis label} in the proof is pushed\index{push}
onto the RPN stack\index{stack}\index{RPN stack} as it is encountered. Each
assertion label\index{assertion label} pops\index{pop} off the stack as many
entries as the referenced assertion has mandatory hypotheses.  Variable
substitutions\index{substitution!variable}\index{variable substitution} are
computed which, when made to the referenced assertion's mandatory hypotheses,
cause these hypotheses to match the stack entries. These same substitutions
are then made to the variables in the referenced assertion itself, which is
then pushed onto the stack.  At the end of the proof, there should be one
stack entry, namely the assertion being proved.  This process is explained in
detail in Section~\ref{proof}.

Metamath's proof notation is not very readable for humans, but it allows the
proof to be stored compactly in a file.  The Metamath\index{Metamath} program
has proof display features that let you see what's going on in a more
readable way, as you will see in the next section.

The rules used in verifying a proof are not based on any built-in syntax of the
symbol sequence in an assertion\index{assertion} nor on any built-in meanings
attached to specific symbol names.  They are based strictly on symbol
matching:  constants\index{constant} must match themselves, and
variables\index{variable} may be replaced with anything that allows a match to
occur.  For example, instead of {\tt term}, {\tt 0}, and \verb$|-$ we could
have just as well used {\tt yellow}, {\tt zero}, and {\tt provable}, as long
as we did so consistently throughout the database.  Also, we could have used
{\tt is provable} (two tokens) instead of \verb$|-$ (one token) throughout the
database.  In each of these cases, the proof would be exactly the same.  The
independence of proofs and notation means that you have a lot of flexibility to
change the notation you use without having to change any proofs.

\section{A Trial Run}\label{trialrun}

Now you are ready to try out the Metamath\index{Metamath} program.

On all computer systems, Metamath has a standard ``command line interface''
(CLI)\index{command line interface (CLI)} that allows you to interact with it.
You supply commands to the CLI by typing them on the keyboard and pressing
your keyboard's {\em return} key after each line you enter.

On some computer systems, Metamath may also have a ``graphical user
interface''\index{graphical user interface (GUI)} (GUI) that makes use of the
computer's graphics capability and mouse\index{mouse}.\footnote{The current
version of Metamath (0.06)\index{Metamath!limitations of version 0.06} does
not have a GUI interface.} If your version of Metamath has a GUI, it is
described in a separate manual.  However, anything you can do with the GUI you
can also do with the CLI.  The CLI is designed to be easy to use and has
built-in help features.  If you are a reasonably good typist, after a while
you may find the CLI more convenient and faster than the GUI for most things
you will want to do. In this book, we will describe the CLI only.

The first thing you should do is to use a text editor to create a file called
{\tt demo0.mm} and type into it the Metamath source shown on
p.~\pageref{demo0}.  Actually, this file is probably included with your
Metamath software package, so check that first.  If you type it in, make sure
that you save it in the form of ``plain {\sc ascii} text with line breaks.''
Most word processors will have this feature.

Next you must run the Metamath program.  Depending on your computer system
and how Metamath is installed, this could range from clicking the mouse on the
Metamath icon to typing {\tt run metamath} to typing simply {\tt metamath}.

When you first enter Metamath\index{Metamath}, it will be at the CLI, waiting
for your input. You will see the following on your screen:
\begin{verbatim}
        Metamath - Version 0.06 4-May-97
        Copyright (C) 1997 Norman D. Megill
        Type HELP for help, EXIT to exit.
        MM>
\end{verbatim}
The {\tt MM>} prompt means that Metamath is waiting for a command.  (The help
message line suggests that commands should be typed in upper case, but
actually command keywords\index{command keyword} are not case sensitive.  We
will use lower case in our examples.)

The first thing that you need to do is to read in your database:\index{{\tt
read} command}\footnote{If a directory path is needed on Unix,\index{Unix
file names}\index{file names!Unix} you should
enclose the path/file name in quotes to prevent Metamath from thinking
that the {\tt /} in the path name is a command qualifier, e.g.,
{\tt read \char`\"db/set.mm\char`\"}.  Quotes are optional when there is
no ambiguity.}
\begin{verbatim}
       MM> read demo0.mm
\end{verbatim}
Remember to press the {\em return} key after entering this command. If you
omit the file name, Metamath will prompt you for one.  On the Macintosh, you
may type {\tt read} {\em return return} if you wish to invoke the Macintosh's
standard file opening protocol.\footnote{This feature does not exist in the
current version of Metamath (0.06)\index{Metamath!limitations of version
0.06}.}  The syntax for specifying a Macintosh file name path is
given in a footnote on p.~\pageref{includef}.\index{Macintosh file
names}\index{file names!Macintosh}

If there are any syntax errors in the database, Metamath will let you know
when it reads in the file.  The one thing that Metamath does not check when
reading in a database is that all proofs are correct, because this would
slow it down too much.  It is a good idea to periodically verify the proofs in
a database you are making changes to.  To do this, use the following command
(and do it for your {\tt demo0.mm} file now).  Note that the {\tt *} is a
``wild card'' meaning all proofs in the file.\index{{\tt verify proof} command}
\begin{verbatim}
        MM> verify proof *
\end{verbatim}
Metamath will report any proofs that are incorrect.

It is often useful to save the information that the Metamath program displays
on the screen. You can save everything that happens on the screen by opening a
log file. You may want to do this before you read in a database so that you
can examine any errors later on.  To open a log file, type
\begin{verbatim}
        MM> open log abc.log
\end{verbatim}
This will open a file called {\tt abc.log}, and everything that appears on the
screen from this point on will be stored in this file.  The name of the log file
is arbitrary. To close the log file, type
\begin{verbatim}
        MM> close log
\end{verbatim}

Several commands let you examine what's inside of your database.
Section~\ref{exploring} has an overview of some useful ones. The {\tt show
labels} command lets you see what statement labels\index{label} exist.  A {\tt
*} matches any combination of characters, and {\tt t*} refers to all labels
starting with the letter {\tt t}.\index{{\tt show labels} command}  The
{\tt /all} is a ``command qualifier''\index{command
qualifier} that tells Metamath to include labels of hypotheses.  (To
see the syntax explained, type {\tt help show labels}.)  Type
\begin{verbatim}
        MM> show labels t* /all
\end{verbatim}
Metamath will respond with
\begin{verbatim}
        The statement number, label, and type are shown.
        3 tt $f       4 tr $f       5 ts $f       8 tze $a
        9 tpl $a      19 th1 $p
\end{verbatim}

You can use the {\tt show statement} command to get information about a
particular statement.\index{{\tt show statement} command}
For example, you can get information about the statement with label {\tt mp}
by typing
\begin{verbatim}
        MM> show statement mp
\end{verbatim}
Metamath will respond with
\begin{verbatim}
        Statement 17, located on line 22 of the
        file "demo0.mm", is:
          mp $a |- Q $.
        Its mandatory hypotheses in RPN order are:
          wp $f wff P $.
          wq $f wff Q $.
          min $e |- P $.
          maj $e |- ( P -> Q ) $.
        The statement and its hypotheses require the
        variables:  Q P
\end{verbatim}
The mandatory hypotheses\index{mandatory hypothesis} and their
order\index{RPN order} are
useful to know when you are trying to understand or debug a proof.

Now you are ready to look at what's really inside of our proof.  First, here is
how to look at every step in the proof---not just the ones corresponding to an
ordinary formal proof\index{formal proof}, but also the ones that build up the
formulas that appear in each ordinary formal proof step.\index{{\tt show
proof} command}
\begin{verbatim}
        MM> show proof th1 /lemmon
\end{verbatim}

This will display the proof on the screen in the following format:
\begin{verbatim}
         1 tt            $f term t
         2 tze           $a term 0
         3 1,2 tpl       $a term ( t + 0 )
         4 tt            $f term t
         5 3,4 weq       $a wff ( t + 0 ) = t
         6 tt            $f term t
         7 tt            $f term t
         8 6,7 weq       $a wff t = t
         9 tt            $f term t
        10 9 a2          $a |- ( t + 0 ) = t
        11 tt            $f term t
        12 tze           $a term 0
        13 11,12 tpl     $a term ( t + 0 )
        14 tt            $f term t
        15 13,14 weq     $a wff ( t + 0 ) = t
        16 tt            $f term t
        17 tze           $a term 0
        18 16,17 tpl     $a term ( t + 0 )
        19 tt            $f term t
        20 18,19 weq     $a wff ( t + 0 ) = t
        21 tt            $f term t
        22 tt            $f term t
        23 21,22 weq     $a wff t = t
        24 20,23 wim     $a wff ( ( t + 0 ) = t -> t = t )
        25 tt            $f term t
        26 25 a2         $a |- ( t + 0 ) = t
        27 tt            $f term t
        28 tze           $a term 0
        29 27,28 tpl     $a term ( t + 0 )
        30 tt            $f term t
        31 tt            $f term t
        32 29,30,31 a1   $a |- ( ( t + 0 ) = t ->
                            ( ( t + 0 ) = t -> t = t ) )
        33 15,24,26,32 mp  $a |- ( ( t + 0 ) = t -> t = t )
        34 5,8,10,33 mp  $a |- t = t
\end{verbatim}

The {\tt /lemmon} command qualifier specifies what is known as a Lemmon-style
display\index{Lemmon-style proof}\index{proof!Lemmon-style}.  Omitting the
{\tt /lemmon} qualifier results in a tree-style proof (see
p.~\pageref{treeproof} for an example) that is somewhat less explicit but
easier to follow once you get used to it.\index{tree-style
proof}\index{proof!tree-style}

The first number on each line is the step
number of the proof.  Any numbers that follow are step numbers assigned to the
hypotheses of the statement in referenced by that step.  Next is the label of
the statement referenced by the step.  The statement type of the statement
referenced comes next, followed by the math symbol\index{math symbol} string
constructed by the proof up to that step.

The last step, 34, contains the statement that is being proved.

Looking at a small piece of the proof, notice that steps 3 and 4 have
established that
{\tt ( t + 0 )} and {\tt t} are {\tt term}\,s, and step 5 makes use of steps 3 and
4 to establish that {\tt ( t + 0 ) = t} is a {\tt wff}.  Let us let Metamath
itself tell us in detail what is happening in step 5.  Note that the
``target hypothesis'' refers to where step 5 is eventually used, i.e., in step
34.
\begin{verbatim}
        MM> show proof th1 /detailed_step 5
        Proof step 5:  wp=weq $a wff ( t + 0 ) = t
        This step assigns source "weq" ($a) to target "wp"
        ($f).  The source assertion requires the hypotheses
        "tt" ($f, step 3) and "tr" ($f, step 4).  The parent
        assertion of the target hypothesis is "mp" ($a,
        step 34).
        The source assertion before substitution was:
            weq $a wff t = r
        The following substitutions were made to the source
        assertion:
            Variable  Substituted with
             t         ( t + 0 )
             r         t
        The target hypothesis before substitution was:
            wp $f wff P
        The following substitution was made to the target
        hypothesis:
            Variable  Substituted with
             P         ( t + 0 ) = t
\end{verbatim}

The full proof just shown is useful to understand what is going on in detail.
However, most of the time you will just be interested in
the ``essential'' or logical steps of a proof, i.e.\ those steps
that correspond to an
ordinary formal proof\index{formal proof}.  If you type
\begin{verbatim}
        MM> show proof th1 /essential /lemmon /renumber
\end{verbatim}
you will see\label{demoproof}
\begin{verbatim}
        1 a2             $a |- ( t + 0 ) = t
        2 a2             $a |- ( t + 0 ) = t
        3 a1             $a |- ( ( t + 0 ) = t -> ( ( t + 0 )
                            = t -> t = t ) )
        4 2,3 mp         $a |- ( ( t + 0 ) = t -> t = t )
        5 1,4 mp         $a |- t = t
\end{verbatim}
Compare this to the formal proof on p.~\pageref{zeroproof} and
notice the resemblance.  The {\tt /essential} qualifier in the {\tt show
proof} command tells Metamath to discard all {\tt \$f}\index{{\tt \$f}
statement} hypotheses and everything branching off of them in the proof tree
when the proof is displayed; this makes the proof look more like an ordinary
mathematical proof, which does not normally incorporate the explicit
construction of expressions.  The {\tt /renumber} qualifier means to renumber
the steps to correspond only to what is displayed.\index{{\tt show proof}
command}

To exit Metamath, type\index{{\tt exit} command}
\begin{verbatim}
        MM> exit
\end{verbatim}

\subsection{Some Hints for Using the Command Line Interface}

We will conclude this quick introduction to Metamath\index{Metamath} with some
helpful hints on how to navigate your way through the commands.
\index{command line interface (CLI)}

When you type commands into Metamath's CLI, you only have to type as many
characters of a command keyword\index{command keyword} as are needed to make
it unambiguous.  If you type too few characters, Metamath will tell you what
the choices are.  In the case of the {\tt read} command, only the {\tt r} is
needed to specify it unambiguously, so you could have typed\index{{\tt read}
command} \begin{verbatim}
        MM> r demo0.mm
\end{verbatim}
instead of
\begin{verbatim}
        MM> read demo0.mm
\end{verbatim}
In our description, we always show the full command words.  When using the
Metamath CLI commands in a command file (to be read with the {\tt submit}
command)\index{{\tt submit} command}, it is good practice to use
the unabbreviated command to ensure your instructions will not become ambiguous
if more commands are added to the Metamath program in the future.

The command keywords\index{command
keyword} are not case sensitive; you may type either {\tt read} or
{\tt ReAd}.  File names may or may not be case sensitive, depending on your
computer's operating system.  Metamath label\index{label} and math
symbol\index{math symbol} tokens\index{token} are case-sensitive.

The {\tt help} command\index{{\tt help} command} will provide you with a list
of topics you can get help on.  You can then type {\tt help} {\em topic} to
get help on that topic.

If you are uncertain of a command's spelling, just type as many characters
as you remember of the command.  If you have not typed enough characters to
specify it unambiguously, Metamath will tell you what choices you have.

\begin{verbatim}
        MM> show s
                 ^
        ?Ambiguous keyword - please specify SETTINGS,
        STATEMENT, or SOURCE.
\end{verbatim}

If you don't what argument to use as part of a command, type a {\tt
?}\index{{\tt ]}@{\tt ?}\ in command lines}\ at the argument position.
Metamath will tell you what it expected there.

\begin{verbatim}
        MM> show ?
                 ^
        ?Expected SETTINGS, LABELS, STATEMENT, SOURCE,
        PROOF, or MEMORY.
\end{verbatim}

Finally, you may type just the first word or words of a command followed by
{\em return}.  Metamath will prompt you for the remaining part of the command,
showing you the choices at each step.  For example, instead of typing {\tt
show statement th1 /brief} you could interact in the
following manner:
\begin{verbatim}
        MM> show
        SETTINGS, LABELS, STATEMENT, SOURCE, PROOF,
        MEMORY, TRACE_BACK, or USAGE <SETTINGS>? st
        What is the statement label <th1>?
        / or nothing <nothing>? /
        TEX, COMMENT_ONLY, or BRIEF <TEX>? b
        / or nothing <nothing>?
          th1 $p |- t = t $= ... $.
\end{verbatim}
After each {\tt ?}\ in this mode, you must give Metamath the information it
requests. Sometimes Metamath gives you a list of choices with the default
choice indicated by brackets {\tt < > }.  Pressing {\em return} after the {\tt
?}\ will select the default choice.  Answering anything else will override the
default. Note that the {\tt /} in command qualifiers is considered a separate
token\index{token} by the parser, and this is why it is asked for separately.

\section{Your First Proof}

Proofs are developed with the aid of the Proof Assistant\index{Proof
Assistant}. We will now show you how the proof of theorem {\tt th1} was
built.  So that you can repeat these steps, we will first have the Proof
Assistant erase the proof in Metamath's source buffer\index{source
buffer}, then reconstruct it.  (The source buffer is the place in memory where
Metamath stores the information in the database when it is {\tt
read}\index{{\tt read} command} in.  New or modified proofs are kept in the
source buffer until a {\tt write} command\index{{\tt write} command} is
issued.)  In practice, you would place a {\tt ?}\index{{\tt ]}@{\tt ?}\ inside
proofs}\ between {\tt \$=}\index{{\tt \$=} keyword} and {\tt \$.}\index{{\tt
\$.}\ keyword}\ in the database to indicate to Metamath\index{Metamath}
that the proof is unknown, and that would be your starting point.  Whenever
{\tt verify proof} command encounters a proof with a {\tt ?}\ in place of
a proof step, the statement is identified as not proved.

Before you start, you should write down on a piece of paper the complete
formal proof\index{formal proof} as it would appear with the {\tt /essential}
qualifier in a {\tt show proof} command\index{{\tt show proof} command}; see
the display of {\tt show proof th1 /essential /lemmon /renumber} above as an
example.  After you get used to using the Proof Assistant\index{Proof
Assistant} you may get to a point where you can ``see'' the proof in your mind
and let the Proof Assistant guide you in filling in the details, at least for
simpler proofs, but until you gain that experience it is important to write
down all the details in advance.  Otherwise you may waste a lot of time as you
let it take you down a wrong path.

A proof is developed with the Proof Assistant by working backwards, starting
with the theorem\index{theorem} to be proved, and assigning each unknown step
with a theorem or hypothesis until no more unknown steps remain.  The Proof
Assistant will not let you make an assignment unless it can be ``unified''
with the unknown step.  This means that a
substitution\index{substitution!variable}\index{variable substitution} of
variables exists that will make the assignment match the unknown step.  On the
other hand, in the middle of a proof, when working backwards, often more than
one unification\index{unification} (set of substitutions) is possible, since
there is not enough information available at that point to uniquely establish
it.  In this case you can tell Metamath which unification to choose, or you
can continue to assign unknown steps until enough information is available to
make the unification unique.

We will assume you have entered Metamath and read in the database as described
above.  The following dialog shows how the proof was developed.  For more
details on what some of the commands do, refer to Section~\ref{pfcommands}.
\index{{\tt prove} command}

\begin{verbatim}
MM> prove th1
Entering the Proof Assistant.  Type HELP for help, EXIT
to exit.  You will be working on the proof of statement th1:
  $p |- t = t
Note:  The proof you are starting with is already complete.
MM-PA>
\end{verbatim}

The \verb/MM-PA>/ prompt means we are inside of the Proof
Assistant.\index{Proof Assistant}  Most of the regular Metamath commands ({\tt
show statement}, etc.) are still available if you need them.

\begin{verbatim}
MM-PA> set empty_substitution off
Substitution with empty symbol sequences will no longer be
allowed.  Note that this may make the Proof Assistant too
restrictive in some cases.
\end{verbatim}

The {\tt set empty{\char`\_}substitution off}\index{{\tt set
empty{\char`\_}substitution} command} command is optional, but without it more
unifications will be ambiguous\index{ambiguous
unification}\index{unification!ambiguous} in the middle of a
proof (because substitution\index{substitution!variable}\index{variable
substitution} of variables with empty symbol sequences will be one of the
possibilities).  In most formal systems\index{formal system}, empty
substitution\index{empty substitution} is never required and is best turned
off to eliminate unnecessary ambiguous unifications.  After going through this
example on your computer, you may want
to try it again without this command to see what happens.

\begin{verbatim}
MM-PA> delete all
The entire proof was deleted.
\end{verbatim}

We have deleted the whole proof so we can start from scratch.

\begin{verbatim}
MM-PA> show new_proof/lemmon
1 ?              $? |- t = t
\end{verbatim}

The {\tt show new{\char`\_}proof} command\index{{\tt show new{\char`\_}proof}
command} is like {\tt show proof} except that we don't specify a statement;
instead, the proof we're working on is displayed.

\begin{verbatim}
MM-PA> assign 1 mp
Step 1 was assigned statement mp.  Step 1 is now step 5.
Step 5 was successfully unified.
\end{verbatim}

The {\tt assign} command\index{{\tt assign} command} above means ``assign step
1 with the statement whose label is {\tt mp}.''  Note that step renumbering
will constantly occur as you assign steps in the middle of a proof;  in
general all steps from the step you assign to the end of the proof will get
moved up.  In this case, what used to be step 1 is now step 5, because the
(partial) proof now has five steps:  the four hypotheses of the {\tt mp}
statement and the {\tt mp} statement itself.  Let's look at all the steps in
our partial proof:

\begin{verbatim}
MM-PA> show new_proof/lemmon
1 ?              $? wff $2
2 ?              $? wff t = t
3 ?              $? |- $2
4 ?              $? |- ( $2 -> t = t )
5 1,2,3,4 mp     $a |- t = t
\end{verbatim}

The symbol {\tt \$2} is a temporary variable\index{temporary variable} that
represents a
symbol sequence not yet known.  In the final proof, all temporary variables
will be eliminated.  The general format for a temporary variable is {\tt \$}
followed by an integer.  Note that {\tt \$} is not a legal character in a
math symbol (see Section~\ref{dollardollar}, p.~\pageref{dollardollar}), so
there will never be ambiguity of symbols and temporary variables.

Unknown steps 1 and 2 are constructions of the two wffs used by the modus
ponens rule.  As you will see at the end of this section, the Proof
Assistant\index{Proof Assistant} can usually figure these steps out by itself,
and we will not have to worry about them.  Therefore from here on we will
display only the ``essential'' hypotheses, i.e.\ those steps that correspond to
traditional formal proofs\index{formal proof}.

\begin{verbatim}
MM-PA> show new_proof/essential/lemmon
3 ?              $? |- $2
4 ?              $? |- ( $2 -> t = t )
5 3,4 mp         $a |- t = t
\end{verbatim}

Unknown steps 3 and 4 are the ones we must focus on.  They correspond to the
minor and major premises of the modus ponens rule.  We will assign them as
follows.  Notice that because of the step renumbering that takes place
after an assignment, it is advantageous to assign unknown steps in reverse
order, because earlier steps will not get renumbered.

\begin{verbatim}
MM-PA> assign 4 mp
Step 4 was assigned statement mp.  Steps 4:5 are now 8:9.
Step 8 was successfully unified.
MM-PA> assign 3 a2
Step 3 was assigned statement a2.  Steps 3:9 are now 4:10.
Step 4 was successfully unified.
\end{verbatim}

Our two unknown steps were successfully assigned and unified.  Now we will
display the proof again to see what new unknown steps resulted from our
assignments.

\begin{verbatim}
MM-PA> show new_proof/essential/lemmon
 4 a2            $a |- ( $5 + 0 ) = $5
 7 ?             $? |- $4
 8 ?             $? |- ( $4 -> ( ( $5 + 0 ) = $5 -> t = t ) )
 9 7,8 mp        $a |- ( ( $5 + 0 ) = $5 -> t = t )
10 4,9 mp        $a |- t = t
MM-PA> assign 8 a1
Step 8 was assigned statement a1.  Steps 8:10 are now 11:13.
MM-PA> assign 7 a2
Step 7 was assigned statement a2.  Steps 7:13 are now 8:14.
Step 8 was successfully unified.
MM-PA> show new_proof/essential/lemmon
 4 a2            $a |- ( $5 + 0 ) = $5
 8 a2            $a |- ( $9 + 0 ) = $9
12 a1            $a |- ( ( $9 + 0 ) = $9 -> ( ( $5 + 0 ) =
                       $5 -> t = t ) )
                  = |- ( $6 = $7 -> ( $6 = $8 -> $7 = $8 ) )
13 8,12 mp       $a |- ( ( $5 + 0 ) = $5 -> t = t )
14 4,13 mp       $a |- t = t
\end{verbatim}

In step 12 above, the source and target did not get unified because there is
more than one possible unification.  Here you must help out the Proof
Assistant\index{Proof Assistant} by specifying the correct one.\footnote{The
current version of Metamath (0.06)\index{Metamath!limitations of version 0.06}
will also provide you with ambiguous unification choices immediately after the
{\tt assign} command.}  Usually this is quite easy because the incorrect ones
will be strange wff fragments.  If you specify it incorrectly, you will
eventually get stuck with a syntactically incorrect statement that you won't
be able to construct.  In other words, the Proof Assistant will let you make a
mistake in the middle, but you will never end up with a proof that is
incorrect.

\begin{verbatim}
MM-PA> unify step 12
There are 10 possible unifications.  Please select the
correct one.
Unify:  |- ( ( $9 + 0 ) = $9 -> ( ( $5 + 0 ) =
           $5 -> t = t ) )
 with:  |- ( $6 = $7 -> ( $6 = $8 -> $7 = $8 ) )
Unification #1:
  Replace "$6" with "( t + 0 )"
  Replace "$9" with "t"
  Replace "$5" with "t"
  Replace "$7" with "t"
  Replace "$8" with "t"
  Accept (A), reject (R), or quit (Q) <R>? a
\end{verbatim}

Luckily, the first unification turned out to be correct.  You might want
to try cycling through all possibilities (by rejecting each one) to see
the other unifications that are possible.

\begin{verbatim}
MM-PA> show new_proof/essential/lemmon
 4 a2            $a |- ( t + 0 ) = t
 8 a2            $a |- ( t + 0 ) = t
12 a1            $a |- ( ( t + 0 ) = t -> ( ( t + 0 ) =
                    t -> t = t ) )
13 8,12 mp       $a |- ( ( t + 0 ) = t -> t = t )
14 4,13 mp       $a |- t = t
\end{verbatim}

Now all temporary variables and unknown steps have been eliminated from the
``essential'' part of the proof.  When this is achieved, the Proof
Assistant\index{Proof Assistant} can usually figure out the rest of the proof
automatically.  (Note that the {\tt improve} command can occasionally be
useful for filling in essential steps as well, but it only tries to make use
of statements that introduce no new variables in their hypotheses, which is
not the case for {\tt mp}. Also it will not try to improve steps containing
temporary variables.)

\begin{verbatim}
MM-PA> improve all
A proof of length 1 was found for step 11.
A proof of length 1 was found for step 10.
A proof of length 3 was found for step 9.
A proof of length 1 was found for step 7.
A proof of length 9 was found for step 6.
A proof of length 5 was found for step 5.
A proof of length 1 was found for step 3.
A proof of length 3 was found for step 2.
A proof of length 5 was found for step 1.
Steps 1 and above have been renumbered.
CONGRATULATIONS!  The proof is complete.  Use SAVE
NEW_PROOF to save it.
\end{verbatim}

The {\tt save new{\char`\_}proof} command\index{{\tt save new{\char`\_}proof}
command} will save the proof in the database.  Here we will just display it in
a form that can be clipped out of a log file and inserted manually into the
database source file with a text editor.\index{normal
proof}\index{proof!normal}

\begin{verbatim}
MM-PA> show new_proof/normal
---------Clip out the proof below this line:
      tt tze tpl tt weq tt tt weq tt a2 tt tze tpl tt weq
      tt tze tpl tt weq tt tt weq wim tt a2 tt tze tpl tt
      tt a1 mp mp $.
---------The proof of 'th1' to clip out ends above this line.
\end{verbatim}

There is another proof format called
``compressed''\index{compressed proof}\index{proof!compressed}
that you will see in databases.  It is not important to
understand how it is encoded but only to recognize it when you see it.  Its
only purpose is to reduce storage requirements for large proofs.  A compressed
proof can always be converted to a normal one and vice-versa, and the Metamath
{\tt show proof} commands\index{{\tt show proof} command} work equally well
with compressed proofs.  The compressed proof format is described in
Appendix~\ref{compressed}.

\begin{verbatim}
MM-PA> show new_proof/compressed
---------Clip out the proof below this line:
      ( tze tpl weq a2 wim a1 mp ) ABCZADZAADZAEZJJKFLIA
      AGHH $.
---------The proof of 'th1' to clip out ends above this line.
\end{verbatim}

Now we will exit the Proof Assistant.  Since we made changes to the proof,
it will warn us that we have not saved it.  In this case, we don't care.

\begin{verbatim}
MM-PA> ex
Warning:  You have not saved changes to the proof.
Do you want to EXIT anyway (Y, N) <N>? y
Exiting the Proof Assistant.
Type EXIT again to exit Metamath.
\end{verbatim}

The Proof Assistant\index{Proof Assistant} has several other commands that can
help you while creating proofs.  See Section~\ref{pfcommands} for a list of
them.

\section{A Note About Editing a Data\-base File}

Once your source file contains proofs, there are some restrictions on how you
can edit it so that the proofs remain valid.  Pay particular attention to
these rules, since otherwise you can lose a lot of work.  It is a good idea to
periodically verify all proofs with {\tt verify proof *} to ensure their
integrity.

If your file contains only normal proofs, the main rule is that you may not
change the order of the mandatory hypotheses\index{mandatory hypothesis} of
any statement referenced in a proof.  For example, if you swap the order of
the major and minor premise in the modus ponens rule, all proofs making use of
that rule will become incorrect.  The {\tt show statement} command\index{{\tt
show statement} command} will show you the mandatory hypotheses of a statement
and their order.

If a statement has a compressed proof, you also must not change the order
of {\em its} mandatory hypotheses.  The compressed proof format makes use
of this information as part of the compression technique.


\chapter{Abstract Mathematics Revealed}\label{fol}

\section{Logic and Set Theory}\label{logicandsettheory}

\begin{quote}
  {\em Set theory can be viewed as a form of exact theology.}
  \flushright\sc  Rudy Rucker\footnote{\cite{Barrow}, p.~31}\\
\end{quote}\index{Rucker, Rudy}

Despite its seeming complexity, all of standard mathematics, no matter how
deep or abstract, can amazingly enough be derived from a relatively small set
of axioms\index{axiom} or first principles. The development of these axioms is
among the most impressive and important accomplishments of mathematics in the
20th century. Ultimately, these axioms can be broken down into a set of rules
for manipulating symbols that any technically oriented person can follow.

We will not spend much time trying to convey a deep, higher-level
understanding of the meaning of the axioms. This kind of understanding
requires some mathematical sophistication as well as an understanding of the
philosophy underlying the foundations of mathematics and typically develops
over time as you work with mathematics.  Our goal, instead, is to give you the
immediate ability to follow how theorems\index{theorem} are derived from the
axioms and from other theorems.  This will be similar to learning the syntax
of a computer language, which lets you follow the details in a program but
does not necessarily give you the ability to write non-trivial programs on
your own, an ability that comes with practice. For now don't be alarmed by
abstract-sounding names of the axioms; just focus on the rules for
manipulating the symbols, which follow the simple conventions of the
Metamath\index{Metamath} language.

The axioms that underlie all of standard mathematics consist of axioms of logic
and axioms of set theory. The axioms of logic are divided into two
subcategories, propositional calculus\index{propositional calculus} (sometimes
called sentential logic\index{sentential logic}) and predicate calculus
(sometimes called first-order logic\index{first-order logic}\index{quantifier
theory}\index{predicate calculus} or quantifier theory).  Propositional
calculus is a prerequisite for predicate calculus, and predicate calculus is a
prerequisite for set theory.  The version of set theory most commonly used is
Zermelo-Fraenkel set theory.\index{Zermelo-Fraenkel set theory}\index{set
theory}

Here in a nutshell is what the axioms are all about in an informal way. The
connection between this description and symbols we will show you won't be
immediately apparent and in principle needn't ever be.  Our description just
tries to summarizes what mathematicians think about when they work with the
axioms.

Logic is more or less the translation of what we would consider common sense
into a rigorous set of axioms.\index{axioms of logic}  Suppose $\varphi$,
$\psi$, and $\chi$ (the Greek letters phi, psi, and chi) represent statements
that are either true or false, and $x$ is a variable\index{variable!in predicate
calculus} ranging over some group of mathematical objects (sets, integers,
real numbers, etc.). In mathematics, a ``statement'' really means a formula,
and $\psi$ could be for example ``$x = 2$.'' Logic makes assertions such as
``if $\varphi$ implies $\psi$ and $\psi$ implies $\chi$, then $\varphi$
implies $\chi$'' (propositional calculus)\index{propositional calculus} and
``if $\varphi$ is true for all $x$, then $\varphi$ is true for some $x$''
(predicate calculus).\index{predicate calculus}

Set theory\index{set theory} has to do with the manipulation of objects and
collections of objects, specifically the abstract, imaginary objects that
mathematics deals with, such as numbers. Everything that is claimed to exist
in mathematics is considered to be a set.  A set called the empty
set\index{empty set} contains nothing.  We represent the empty set by
$\varnothing$.  Many sets can be built up from the empty set.  There is a set
represented by $\{\varnothing\}$ that contains the empty set, another set
represented by $\{\varnothing,\{\varnothing\}\}$ that contains this set as
well as the empty set, another set represented by $\{\{\varnothing\}\}$ that
contains just the set that contains the empty set, and so on ad infinitum. All
mathematical objects, no matter how complex, are defined as being identical to
certain sets: the integer\index{integer} 0 is defined as the empty set, the
integer 1 is defined as $\{\varnothing\}$, the integer 2 is defined as
$\{\varnothing,\{\varnothing\}\}$.  (How these definitions were chosen doesn't
matter now, but the idea behind it is that these sets have the properties we
expect of integers once suitable operations are defined.)  Mathematical
operations, such as addition, are defined in terms of operations on
sets---their union\index{set union}, intersection\index{set intersection}, and
so on---operations you may have used in elementary school when you worked
with groups of apples and oranges.

With a leap of faith, the axioms also postulate the existence of infinite
sets\index{infinite set}, such as the set of all non-negative integers ($0, 1,
2,\ldots$, also called ``natural numbers''\index{natural number}).  This set
can't be represented with the brace notation\index{brace notation} we just
showed you, but requires a more complicated notation called ``class
abstraction.''\index{class abstraction}\index{abstraction class}  For
example, the infinite set $\{ x |
\mbox{``$x$ is a natural number''} \} $ means the ``set of all objects $x$
such that $x$ is a natural number'' i.e.\ the set of natural numbers; here,
``$x$ is a natural number'' is a rather complicated formula when broken down
into the primitive symbols.\label{expandom}\footnote{The statement ``$x$ is a
natural number'' is formally expressed as ``$x \in \omega$,'' where $\in$
(stylized epsilon) means ``is in'' or ``is an element of'' and $\omega$
(omega) means ``the set of natural numbers.''  When ``$x\in\omega$'' is
completely expanded in terms of the primitive symbols of set theory, the
result is  $\lnot$ $($ $\lnot$ $($ $\forall$ $z$ $($ $\lnot$ $\forall$ $w$ $($
$z$ $\in$ $w$ $\rightarrow$ $\lnot$ $w$ $\in$ $x$ $)$ $\rightarrow$ $z$ $\in$
$x$ $)$ $\rightarrow$ $($ $\forall$ $z$ $($ $\lnot$ $($ $\forall$ $w$ $($ $w$
$\in$ $z$ $\rightarrow$ $w$ $\in$ $x$ $)$ $\rightarrow$ $\forall$ $w$ $\lnot$
$w$ $\in$ $z$ $)$ $\rightarrow$ $\lnot$ $\forall$ $w$ $($ $w$ $\in$ $z$
$\rightarrow$ $\lnot$ $\forall$ $v$ $($ $v$ $\in$ $z$ $\rightarrow$ $\lnot$
$v$ $\in$ $w$ $)$ $)$ $)$ $\rightarrow$ $\lnot$ $\forall$ $z$ $\forall$ $w$
$($ $\lnot$ $($ $z$ $\in$ $x$ $\rightarrow$ $\lnot$ $w$ $\in$ $x$ $)$
$\rightarrow$ $($ $\lnot$ $z$ $\in$ $w$ $\rightarrow$ $($ $\lnot$ $z$ $=$ $w$
$\rightarrow$ $w$ $\in$ $z$ $)$ $)$ $)$ $)$ $)$ $\rightarrow$ $\lnot$
$\forall$ $y$ $($ $\lnot$ $($ $\lnot$ $($ $\forall$ $z$ $($ $\lnot$ $\forall$
$w$ $($ $z$ $\in$ $w$ $\rightarrow$ $\lnot$ $w$ $\in$ $y$ $)$ $\rightarrow$
$z$ $\in$ $y$ $)$ $\rightarrow$ $($ $\forall$ $z$ $($ $\lnot$ $($ $\forall$
$w$ $($ $w$ $\in$ $z$ $\rightarrow$ $w$ $\in$ $y$ $)$ $\rightarrow$ $\forall$
$w$ $\lnot$ $w$ $\in$ $z$ $)$ $\rightarrow$ $\lnot$ $\forall$ $w$ $($ $w$
$\in$ $z$ $\rightarrow$ $\lnot$ $\forall$ $v$ $($ $v$ $\in$ $z$ $\rightarrow$
$\lnot$ $v$ $\in$ $w$ $)$ $)$ $)$ $\rightarrow$ $\lnot$ $\forall$ $z$
$\forall$ $w$ $($ $\lnot$ $($ $z$ $\in$ $y$ $\rightarrow$ $\lnot$ $w$ $\in$
$y$ $)$ $\rightarrow$ $($ $\lnot$ $z$ $\in$ $w$ $\rightarrow$ $($ $\lnot$ $z$
$=$ $w$ $\rightarrow$ $w$ $\in$ $z$ $)$ $)$ $)$ $)$ $\rightarrow$ $($
$\forall$ $z$ $\lnot$ $z$ $\in$ $y$ $\rightarrow$ $\lnot$ $\forall$ $w$ $($
$\lnot$ $($ $w$ $\in$ $y$ $\rightarrow$ $\lnot$ $\forall$ $z$ $($ $w$ $\in$
$z$ $\rightarrow$ $\lnot$ $z$ $\in$ $y$ $)$ $)$ $\rightarrow$ $\lnot$ $($
$\lnot$ $\forall$ $z$ $($ $w$ $\in$ $z$ $\rightarrow$ $\lnot$ $z$ $\in$ $y$
$)$ $\rightarrow$ $w$ $\in$ $y$ $)$ $)$ $)$ $)$ $\rightarrow$ $x$ $\in$ $y$
$)$ $)$ $)$. Section~\ref{hierarchy} shows the hierarchy of definitions that
leads up to this expression.}\index{stylized epsilon ($\in$)}\index{omega
($\omega$)}  Actually, the primitive symbols don't even include the brace
notation.  The brace notation is a high-level definition, which you can find in
Section~\ref{hierarchy}.

Interestingly, the arithmetic of integers\index{integer} and
rationals\index{rational number} can be developed without appealing to the
existence of an infinite set, whereas the arithmetic of real
numbers\index{real number} requires it.

Each variable\index{variable!in set theory} in the axioms of set theory
represents an arbitrary set, and the axioms specify the legal kinds of things
you can do with these variables at a very primitive level.

Now, you may think that numbers and arithmetic are a lot more intuitive and
fundamental than sets and therefore should be the foundation of mathematics.
What is really the case is that you've dealt with numbers all your life and
are comfortable with a few rules for manipulating them such as addition and
multiplication.  Those rules only cover a small portion of what can be done
with numbers and only a very tiny fraction of the rest of mathematics.  If you
look at any elementary book on number theory, you will quickly become lost if
these are the only rules that you know.  Even though such books may present a
list of ``axioms''\index{axiom} for arithmetic, the ability to use the axioms
and to understand proofs of theorems\index{theorem} (facts) about numbers
requires an implicit mathematical talent that frustrates many people
from studying abstract mathematics.  The kind of mathematics that most people
know limits them to the practical, everyday usage of blindly manipulating
numbers and formulas, without any understanding of why those rules are correct
nor any ability to go any further.  For example, do you know why multiplying
two negative numbers yields a positive number?  Starting with set theory, you
will also start off blindly manipulating symbols according to the rules we give
you, but with the advantage that these rules will allow you, in principle, to
access {\em all} of mathematics, not just a tiny part of it.

Of course, concrete examples are often helpful in the learning process. For
example, you can verify that that $2\cdot 3=3 \cdot 2$ by actually grouping
objects and can easily ``see'' how it generalizes to $x\cdot y = y\cdot x$,
even though you might not be able to rigorously prove it.  Similarly, in set
theory it can be helpful to understand how the axioms of set theory apply to
(and are correct for) small finite collections of objects.  You should be aware
that in set theory intuition can be misleading for infinite collections and
rigorous proofs become more important.  For example, while $x\cdot y = y\cdot
x$ is correct for finite ordinals (which are the natural numbers), it is not
usually true for infinite ordinals.

\section{The Axioms for All of Mathematics}

In this section\index{axioms for mathematics}, we will show you how the axioms
for all of standard mathematics (i.e.\ logic and set theory) as they are
traditionally presented.  The traditional presentation is useful for someone
with the mathematical experience needed to correctly manipulate high-level
abstract concepts.  For someone without this talent, knowing how to actually
make use of these axioms can be difficult.  The purpose of this section is to
allow you to see how the version of the axioms used in the standard
Metamath\index{Metamath} database {\tt set.mm}\index{set
theory database ({\tt set.mm})} relates to  the typical version
in textbooks, and also to give you an informal feel for them.

\subsection{Propositional Calculus}

Propositional calculus\index{propositional calculus} concerns itself with
statements that can be interpreted as either true or false.  Some examples of
statements (outside of mathematics) that are either true or false are ``It is
raining today'' and ``The United States has a female president.'' In
mathematics, as we mentioned, statements are really formulas.

In propositional calculus, we don't care what the statements are.  We also
treat a logical combination of statements, such as ``It is raining today and
the United States has a female president,'' no differently from a single
statement.  Statements and their combinations are called well-formed formulas
(wffs)\index{well-formed formula (wff)}.  We define wffs only in terms of
other wffs and don't define what a ``starting'' wff is.  As is common practice
in the literature, we use Greek letters to represent wffs.

Specifically, suppose $\varphi$ and $\psi$ are wffs.  Then the combinations
$\varphi\rightarrow\psi$ (``$\varphi$ implies $\psi$,'' also read ``if
$\varphi$ then $\psi$'')\index{implication ($\rightarrow$)} and $\lnot\varphi$
(``not $\varphi$'')\index{negation ($\lnot$)} are also wffs.

The three axioms of propositional calculus\index{axioms of propositional
calculus} are all wffs of the following form:\footnote{A remarkable result of
C.~A.~Meredith\index{Meredith, C. A.} squeezes these three axioms into the
single axiom $((((\varphi\rightarrow \psi)\rightarrow(\neg \chi\rightarrow\neg
\theta))\rightarrow \chi )\rightarrow \tau)\rightarrow((\tau\rightarrow
\varphi)\rightarrow(\theta\rightarrow \varphi))$ \cite{CAMeredith},
which is believed to be the shortest possible.}
\begin{center}
     $\varphi\rightarrow(\psi\rightarrow \varphi)$\\

     $(\varphi\rightarrow (\psi\rightarrow \chi))\rightarrow
((\varphi\rightarrow  \psi)\rightarrow (\varphi\rightarrow \chi))$\\

     $(\neg \varphi\rightarrow \neg\psi)\rightarrow (\psi\rightarrow
\varphi)$
\end{center}


There are an infinite number of axioms, one for each possible
wff\index{well-formed formula (wff)} of the above form.  (For this reason,
axioms such as the above are often called ``axiom schemes.''\index{axiom
scheme})  Each Greek letter in the axioms may be substituted with a more
complex wff to result in another axiom.  For example, substituting
$\neg(\varphi\rightarrow\chi)$ for $\varphi$ in the first axiom yields
$\neg(\varphi\rightarrow\chi)\rightarrow(\psi\rightarrow
\neg(\varphi\rightarrow\chi))$, which is still an axiom.

To deduce new true statements (theorems\index{theorem}) from the axioms, a
rule\index{rule} called ``modus ponens''\index{modus ponens} is used.  This
rule states that if the wff $\varphi$ is an axiom or a theorem, and the wff
$\varphi\rightarrow\psi$ is an axiom or a theorem, then the wff $\psi$ is also
a theorem\index{theorem}.

As a non-mathematical example of modus ponens, suppose we have proved (or
taken as an axiom) ``Bob is a man'' and separately have proved (or taken as
an axiom) ``If Bob is a man, then Bob is a human.''  Using the rule of modus
ponens, we can logically deduce, ``Bob is a human.''

From Metamath's\index{Metamath} point of view, the axioms and the rule of
modus ponens just define a mechanical means for deducing new true statements
from existing true statements, and that is the complete content of
propositional calculus as far as Metamath is concerned.  You can read a logic
textbook to gain a better understanding of their meaning, or you can just let
their meaning slowly become apparent to you after you use them for a while.

It is actually rather easy to check to see if a formula is a theorem of
propositional calculus.  Theorems of propositional calculus are also called
``tautologies.''\index{tautology}  The technique to check whether a formula is
a tautology is called the ``truth table method,''\index{truth table} and it
works like this.  A wff $\varphi\rightarrow\psi$ is false whenever $\varphi$ is true
and $\psi$ is false.  Otherwise it is true.  A wff $\lnot\varphi$ is false
whenever $\varphi$ is true and false otherwise. To verify a tautology such as
$\varphi\rightarrow(\psi\rightarrow \varphi)$, you break it down into sub-wffs and
construct a truth table that accounts for all possible combinations of true
and false assigned to the wff metavariables:
\begin{center}\begin{tabular}{|c|c|c|c|}\hline
\mbox{$\varphi$} & \mbox{$\psi$} & \mbox{$\psi\rightarrow\varphi$}
    & \mbox{$\varphi\rightarrow(\psi\rightarrow \varphi)$} \\ \hline \hline
              T   &  T    &      T       &        T    \\ \hline
              T   &  F    &      T       &        T    \\ \hline
              F   &  T    &      F       &        T    \\ \hline
              F   &  F    &      T       &        T    \\ \hline
\end{tabular}\end{center}
If all entries in the last column are true, the formula is a tautology.

Now, the truth table method doesn't tell you how to prove the tautology from
the axioms, but only that a proof exists.  Finding an actual proof (especially
one that is short and elegant) can be challenging.  Methods do exist for
automatically generating proofs in propositional calculus, but the proofs that
result can sometimes be very long.  In the Metamath {\tt set.mm}\index{set
theory database ({\tt set.mm})} database, most
or all proofs were created manually.

\subsection{Predicate Calculus}

Predicate calculus\index{predicate calculus} introduces the concept of
``individual variables,''\index{variable!in predicate calculus}\index{individual
variable} which
we will usually just call ``variables.''
These will always represent sets when we get to set theory.  There are also
three new symbols $\forall$\index{universal quantifier ($\forall$)},
$=$\index{equality ($=$)}, and $\in$\index{stylized epsilon ($\in$)},
read ``for all,'' ``equals,'' and ``is an element of''
respectively.  We will represent variables with the letters $x$, $y$, $z$, and
$w$, as is common practice in the literature.

To prevent confusion, it might be best at this point to think of the variables
of Metamath\index{Metamath} as ``metavariables,''\index{metavariable} because
they are not quite the same as the variables we are introducing here.  A
(meta)variable in Metamath can be a wff or an individual variable, as well
as many other things; in general, it represents a kind of place holder for an
unspecified sequence of math symbols\index{math symbol}.

In predicate calculus, we extend the definition of a wff\index{well-formed
formula (wff)}.  If $\varphi$ is a wff and $x$ and $y$ are variables, then
$\forall x \, \varphi$, $x=y$, and $x\in y$ are wffs. Note that these three new
types of wffs can be considered ``starting'' wffs from which we can build
other wffs with $\rightarrow$ and $\neg$ .  The concept of a starting wff was
absent in propositional calculus.  But starting wff or not, all we are really
concerned with is whether our wffs are correctly constructed according to
these mechanical rules.

In standard texts of logic, there are two axioms of predicate
calculus\index{axioms of predicate calculus}:
\begin{center}
  $\forall x \,\varphi ( x ) \rightarrow \varphi ( y )$,
      where ``$y$ is properly substituted for $x$.''\\
  $\forall x ( \varphi \rightarrow \psi )\rightarrow ( \varphi \rightarrow
    \forall x\, \psi )$,
    where ``$x$ is not free in $\varphi$.''
\end{center}

Now at first glance, this seems simple:  just two axioms.  However,
conditional clauses are attached to each axiom describing requirements that
may seem puzzling to you.  In addition, the first axiom puts a variable symbol
in parentheses after each wff, seemingly violating our definition of a
wff\index{well-formed formula (wff)}; this is just an informal way of
referring to some arbitrary variable that may occur in the wff.  The
conditional clauses do, of course, have a precise meaning, but as it turns out
the precise meaning is somewhat complicated and awkward to formalize in a
way that a computer handle easily.  Unlike propositional calculus, a certain
amount of mathematical sophistication and practice is needed to be able to
easily grasp and manipulate these concepts correctly.

We take a different approach in the Metamath\index{Metamath} database {\tt
set.mm}\index{set theory database ({\tt set.mm})}.  We do not use the
primitive notions of ``free variable''\index{free variable} and ``proper
substitution''\index{proper substitution}\index{substitution!proper} at all.
Instead, we use a set of axioms that are  almost as simple to manipulate as
those of propositional calculus.  Our axiom system avoids complex primitive
notions by effectively embedding the complexity into the axioms themselves.
As a result, we will end up with a larger number of axioms, but they are
ideally suited for a computer language such as Metamath.
(Section~\ref{metaaxioms} shows these axioms.)

We will not elaborate on the ``free variable'' and ``proper substitution''
concepts here.  We listed the two axioms above so that you will recognize them
when you encounter them in the literature. You may consult
\cite[ch.\ 3--4]{Hamilton}\index{Hamilton, Alan G.} (as well as
many other books) for a precise explanation
of these concepts.  If you intend to do serious mathematical work, it is wise
to become familiar with the traditional textbook approach; even though the
concepts embedded in their axioms require a higher level of sophistication,
they can be more practical to deal with on an everyday, informal basis.  Even
if you are just developing Metamath proofs, familiarity with the traditional
approach can help you arrive at a proof outline much faster, which you can
then convert to the detail required by Metamath.

There is also a new rule of inference in predicate calculus:  if $\varphi$ is
an axiom or a theorem, then $\forall x \,\varphi$ is also a
theorem\index{theorem}.  This is called the rule of
``generalization.''\index{rule of generalization}

Unlike propositional calculus, no decision procedure\index{decision procedure}
analogous to the truth table method exists (nor theoretically can exist) that
will definitely determine whether a formula is a theorem of predicate
calculus.  Much of the work in the field of automated theorem
proving\index{automated theorem proving} has been dedicated to coming up with
clever heuristics for proving theorems of predicate calculus, but they can
never be guaranteed to work always.

\subsection{Equality}

Predicate calculus may be presented with or without axioms for
equality\index{axioms of equality}\index{equality ($=$)}. We will require the
axioms of equality as a prerequisite for the version of set theory we will
use.  In standard systems, the axioms for equality are the following two:
\begin{center}
$x=x$\\ \ \\
$x=y\rightarrow (\varphi(x,y)\rightarrow\varphi(x,x))$ where ``$\varphi(x,x)$
   arises from $\varphi(x,y)$ by replacing some, but not necessarily all,
   free\index{free variable}
   occurrences of $x$ by $y$.'' \end{center}
The first equality axiom is simple, but the proviso on the second one is
somewhat awkward to implement on a computer.  Again, the axiom system we use in
the {\tt set.mm}\index{set theory database ({\tt set.mm})} database avoids the
complexity of this proviso by effectively embedding the complexity into the
axioms themselves.

\subsection{Set Theory}

Traditional Zermelo-Fraenkel set theory\index{Zermelo-Fraenkel set
theory}\index{set theory} has 10 axioms, which can be expressed in the
language of predicate calculus.  In this section, we will list only the names
and brief English descriptions of these axioms, since we will give you the
precise formulas used by the Metamath\index{Metamath} set theory database {\tt
set.mm} later on.

In the descriptions of the axioms, we assume that $x$, $y$, $z$, $w$, and $v$
represent sets.  These are the same as the variables\index{variable!in set
theory} in our predicate calculus system above, except that now we informally
think of the variables as ranging over sets.  Note that the terms
``object,''\index{object} ``set,''\index{set} ``element,''\index{element}
``collection,''\index{collection} and ``family''\index{family} are synonymous,
as are ``is an element of,'' ``is a member of,''\index{member} ``is contained
in,'' and ``belongs to.''  The different terms are used for convenience; for
example, ``a collection of sets'' is less confusing than ``a set of sets.''
A set $x$ is said to be a ``subset''\index{subset} of $y$ if every element of
$x$ is also an element of $y$; we also say $x$ is ``included in''
$y$.

The axioms are very general and apply to almost any conceivable mathematical
object, and this level of abstraction can be overwhelming at first.  To gain an
intuitive feel, it can be helpful to draw a picture illustrating the concept;
for example, a circle containing dots could represent a collection of sets,
and a smaller circle drawn inside of the circle could represent a subset.
Overlapping circles can illustrate intersection and union.  Circles that
illustrate the concepts of set theory are frequently used in elementary
textbooks and are called Venn diagrams\index{Venn diagram}.\index{axioms of
set theory}

1. Axiom of Extensionality:  Two sets are identical if they contain the same
   elements.\index{Axiom of Extensionality}

2. Axiom of Pairing:  The set $\{ x , y \}$ exists.\index{Axiom of Pairing}

3. Axiom of Power Sets:  The power set of a set (the collection of all of
   its subsets) exists.  For example, the power set of $\{x,y\}$ is
   $\{\varnothing,\{x\},\{y\},\{x,y\}\}$ and it exists.\index{Axiom
of Power Sets}

4. Axiom of the Null Set:  The empty set $\varnothing$ exists.\index{Axiom of
the Null Set}

5. Axiom of Union:  The union of a set (the set containing the elements of
   its members) exists.  For example, the union of $\{\{x,y\},\{z\}\}$ is
 $\{x,y,z\}$ and
   it exists.\index{Axiom of Union}

6. Axiom of Regularity:  Roughly, no set can contain itself, nor can there
   be membership ``loops,'' such as a set being an
   element of one of its members.\index{Axiom of Regularity}

7. Axiom of Infinity:  An infinite set exists.  An example of an infinite
   set is the set of all
   integers.\index{Axiom of Infinity}

8. Axiom of Separation:  The set exists that is obtained by restricting $x$
   with some property.  For example, if the set of all integers exists,
   then the set of all even integers exists.\index{Axiom of Separation}

9. Axiom of Replacement:  The range of a function whose domain is restricted
   to the elements of a set $x$, is also a set.  For example, there
   is a function
   from integers (the function's domain) to their squares (its
   range).  If we
   restrict the domain to even integers, its range will become the set of
   squares of even integers, so this axioms asserts that the set of
    squares of even numbers exists.  Technical note:  In general, the
   ``function'' need not be a set but can be a proper class.
   \index{Axiom of Replacement}

10. Axiom of Choice:  Let $x$ be a set whose members are pairwise
  disjoint\index{disjoint sets} (i.e,
  whose members contain no elements in common).  Then there exists another
  set containing one element from each member of $x$.  For
  example, if $x$ is
  $\{\{y,z\},\{w,v\}\}$, where $y$, $z$, $w$, and $v$ are
  different sets, then a set such as $\{z,w\}$
  exists (but the axiom doesn't tell
  us which one).  (Actually the Axiom
  of Choice is redundant if the set $x$, as in this example, has a finite
  number of elements.)\index{Axiom of Choice}

The Axiom of Choice is usually considered an extension of ZF set theory rather
than a proper part of it.  It is sometimes considered philosophically
controversial because it specifies the existence of a set without specifying
what the set is.  ZF set theory that includes the Axiom of Choice is
called ZFC.\index{ZFC set theory}

When expressed symbolically, the Axiom of Separation and the Axiom of
Replacement contain wff symbols and therefore each represent infinitely many
axioms, one for each possible wff. For this reason, they are often called
axiom schemes\index{axiom scheme}\index{well-formed formula (wff)}.

It turns out that the Axiom of the Null Set, the Axiom of Pairing, and the
Axiom of Separation can be derived from the other axioms and are therefore
unnecessary, although they tend to be included in standard texts for various
reasons (historical, philosophical, and possibly because some authors may not
know this).  In the Metamath\index{Metamath} set theory database, these
redundant axioms are derived from the other ones.

\section{The Axioms in the Metamath Language}\label{metaaxioms}

The standard textbook axioms of predicate calculus are somewhat cumbersome to
implement on a computer because of the complex notions of ``free
variable''\index{free variable} and ``proper substitution.''\index{proper
substitution}\index{substitution!proper}  While it is possible to use the
Metamath\index{Metamath} language to implement these concepts, we have chosen
not to do so in the {\tt set.mm} set theory database. Instead, we have
eliminated them by carefully crafting the axioms so as to avoid them.  This
makes it easy for a beginner to follow the steps in a proof without knowing
any advanced concepts other than the simple concept of
replacing\index{substitution!variable}\index{variable substitution} variables
with expressions.  Here we list the axioms as they appear in {\tt
set.mm}\index{set theory database ({\tt set.mm})} so you can look them up
there easily.  Incidentally, the {\tt show statement /tex} command\index{{\tt
show statement} command} was used to typeset them.

In order to develop the concepts of free variable and proper substitution from
the axioms described below, we use an additional Metamath statement type
called ``disjoint variable restriction''\index{disjoint variables} that we
have not encountered before.  In the context of the axioms, the statement {\tt
\$d} $ x\, y$\index{{\tt \$d} statement} simply means that $x$ and $y$ must be
distinct\index{distinct variables}, i.e.\ they may not be simultaneously
substituted\index{substitution!variable}\index{variable substitution} with the
same variable.  The statement {\tt \$d} $ x\, \varphi$ means variable $x$ must
not occur in wff $\varphi$.  For the precise definition of {\tt \$d}, see
Section~\ref{dollard}.

In our system, the axioms of predicate calculus have been divided into what we
call ``pure predicate calculus,'' which uses no $=$ or $\in$ symbols, and
``equality and substitution.''  The former is weaker than traditional
predicate calculus because it does not have substitution (although it is a
beautifully simple and interesting system in itself), and the latter extends
its power to the full predicate calculus with equality.

You should also note that our system of predicate calculus is specifically
tailored for set theory; thus there are only two specific predicates $=$ and
$\in$ and no functions\index{function!in predicate calculus}
or constants\index{constant!in predicate calculus} unlike more general systems.

Finally, I do not claim that these axioms are the most elegant possible.  They
have more ``metalogical''\index{metalogic} power than standard axioms
(although they are equivalent in a ``logical'' sense) and the ones I have
chosen at least do the job.  Perhaps a logician who reads this would be
interested in devising a set of equivalent axioms that are shorter or more
elegant in some sense.\index{axioms in {\tt set.mm}}  (For example, there used
to be an axiom {\tt ax-15} in our list that was later discovered to be
redundant.)

A rigorous justification for this system can be found in
\cite{Megill}\index{Megill, Norman}.

%macros from show statement /tex
\newbox\mlinebox
\newbox\mtrialbox
\newbox\startprefix  % Prefix for first line of a formula
\newbox\contprefix  % Prefix for continuation line of a formula
\def\startm{  % Initialize formula line
  \setbox\mlinebox=\hbox{\unhcopy\startprefix}
}
\def\m#1{  % Add a symbol to the formula
  \setbox\mtrialbox=\hbox{\unhcopy\mlinebox $\,#1$}
  \ifdim\wd\mtrialbox>\hsize
    \box\mlinebox
    \setbox\mlinebox=\hbox{\unhcopy\contprefix $\,#1$}
  \else
    \setbox\mlinebox=\hbox{\unhbox\mtrialbox}
  \fi
}
\def\endm{  % Output the last line of a formula
  \box\mlinebox
}



\subsection{Propositional Calculus}\label{propcalc}\index{axioms of
propositional calculus}

Axiom of Simplification.\label{ax1}

\setbox\startprefix=\hbox{\tt \ \ ax-1\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{\varphi}\m{\rightarrow}\m{(}\m{\psi}\m{\rightarrow}\m{\varphi}\m{)}
\m{)}
\endm

\noindent Axiom of Distribution.

\setbox\startprefix=\hbox{\tt \ \ ax-2\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{(}\m{\varphi}\m{\rightarrow}\m{(}\m{\psi}\m{\rightarrow}\m{\chi}
\m{)}\m{)}\m{\rightarrow}\m{(}\m{(}\m{\varphi}\m{\rightarrow}\m{\psi}\m{)}\m{
\rightarrow}\m{(}\m{\varphi}\m{\rightarrow}\m{\chi}\m{)}\m{)}\m{)}
\endm

\noindent Axiom of Contraposition.

\setbox\startprefix=\hbox{\tt \ \ ax-3\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{(}\m{\lnot}\m{\varphi}\m{\rightarrow}\m{\lnot}\m{\psi}\m{)}\m{
\rightarrow}\m{(}\m{\psi}\m{\rightarrow}\m{\varphi}\m{)}\m{)}
\endm


\noindent Rule of Modus Ponens.\index{modus ponens}

\setbox\startprefix=\hbox{\tt \ \ maj\ \$e\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{\varphi}\m{\rightarrow}\m{\psi}\m{)}
\endm

\setbox\startprefix=\hbox{\tt \ \ min\ \$e\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{\varphi}
\endm

\setbox\startprefix=\hbox{\tt \ \ ax-mp\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{\psi}
\endm


\subsection{Pure Predicate Calculus}\index{axioms of predicate calculus}

\noindent Axiom of Specialization.

\setbox\startprefix=\hbox{\tt \ \ ax-4\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{\forall}\m{x}\m{\varphi}\m{\rightarrow}\m{\varphi}\m{)}
\endm

\noindent Axiom of Quantified Implication.

\setbox\startprefix=\hbox{\tt \ \ ax-5\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{\forall}\m{x}\m{(}\m{\forall}\m{x}\m{\varphi}\m{\rightarrow}\m{
\psi}\m{)}\m{\rightarrow}\m{(}\m{\forall}\m{x}\m{\varphi}\m{\rightarrow}\m{
\forall}\m{x}\m{\psi}\m{)}\m{)}
\endm

\noindent Axiom of Quantified Negation.

\setbox\startprefix=\hbox{\tt \ \ ax-6\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{\lnot}\m{\forall}\m{x}\m{\lnot}\m{\forall}\m{x}\m{\varphi}\m{
\rightarrow}\m{\varphi}\m{)}
\endm

\noindent Axiom of Quantifier Commutation.

\setbox\startprefix=\hbox{\tt \ \ ax-7\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{\forall}\m{x}\m{\forall}\m{y}\m{\varphi}\m{\rightarrow}\m{
\forall}\m{y}\m{\forall}\m{x}\m{\varphi}\m{)}
\endm


\noindent Rule of Generalization.\index{rule of generalization}

\setbox\startprefix=\hbox{\tt \ \ ax-g.1\ \$e\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{\varphi}
\endm

\setbox\startprefix=\hbox{\tt \ \ ax-gen\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{\forall}\m{x}\m{\varphi}
\endm


\subsection{Equality and Substitution}\index{axioms of equality}

\noindent Axiom of Equality (1).

\setbox\startprefix=\hbox{\tt \ \ ax-8\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{x}\m{=}\m{y}\m{\rightarrow}\m{(}\m{x}\m{=}\m{z}\m{
\rightarrow}\m{y}\m{=}\m{z}\m{)}\m{)}
\endm

\noindent Axiom of Existence.

\setbox\startprefix=\hbox{\tt \ \ ax-9\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{\forall}\m{x}\m{(}\m{x}\m{=}\m{y}\m{\rightarrow}\m{\forall}
\m{x}\m{\varphi}\m{)}\m{\rightarrow}\m{\varphi}\m{)}
\endm

\noindent Axiom of Quantifier Substitution.

\setbox\startprefix=\hbox{\tt \ \ ax-10\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{\forall}\m{x}\m{\,x}\m{=}\m{y}\m{\rightarrow}\m{(}\m{\forall}
\m{x}\m{\varphi}\m{\rightarrow}\m{\forall}\m{y}\m{\varphi}\m{)}\m{)}
\endm


\noindent Axiom of Variable Substitution.

\setbox\startprefix=\hbox{\tt \ \ ax-11\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{\lnot}\m{\forall}\m{x}\m{\,x}\m{=}\m{y}\m{\rightarrow}\m{(}
\m{x}\m{=}\m{y}\m{\rightarrow}\m{(}\m{\varphi}\m{\rightarrow}\m{\forall}\m{x}\m{(}
\m{x}\m{=}\m{y}\m{\rightarrow}\m{\varphi}\m{)}\m{)}\m{)}\m{)}
\endm

\noindent Axiom of Quantifier Introduction (1).

\setbox\startprefix=\hbox{\tt \ \ ax-12\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{\lnot}\m{\forall}\m{z}\m{\,z}\m{=}\m{x}\m{\rightarrow}\m{(}
\m{\lnot}\m{\forall}\m{z}\m{\,z}\m{=}\m{y}\m{\rightarrow}\m{(}\m{x}\m{=}\m{y}
\m{\rightarrow}\m{\forall}\m{z}\m{\,x}\m{=}\m{y}\m{)}\m{)}\m{)}
\endm

\noindent Axiom of Equality (2).

\setbox\startprefix=\hbox{\tt \ \ ax-13\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{x}\m{=}\m{y}\m{\rightarrow}\m{(}\m{x}\m{\in}\m{z}\m{
\rightarrow}\m{y}\m{\in}\m{z}\m{)}\m{)}
\endm

\noindent Axiom of Equality (3).

\setbox\startprefix=\hbox{\tt \ \ ax-14\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{x}\m{=}\m{y}\m{\rightarrow}\m{(}\m{z}\m{\in}\m{x}\m{
\rightarrow}\m{z}\m{\in}\m{y}\m{)}\m{)}
\endm

\noindent Axiom of Distinct Variables.  (This axiom requires
that two individual variables
be distinct\index{{\tt \$d} statement}\index{distinct
variables}.)

\setbox\startprefix=\hbox{\tt \ \ \ \ \ \ \ \ \$d\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{x}\m{\,}\m{y}
\endm

\setbox\startprefix=\hbox{\tt \ \ ax-16\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{\forall}\m{x}\m{\,x}\m{=}\m{y}\m{\rightarrow}\m{(}\m{\varphi}\m{
\rightarrow}\m{\forall}\m{x}\m{\varphi}\m{)}\m{)}
\endm

\noindent Axiom of Quantifier Introduction (2).  (This axiom requires
that the individual variable not occur in the
wff\index{{\tt \$d} statement}\index{distinct variables}.)

\setbox\startprefix=\hbox{\tt \ \ \ \ \ \ \ \ \$d\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{x}\m{\,}\m{\varphi}
\endm
\setbox\startprefix=\hbox{\tt \ \ ax-17\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{\varphi}\m{\rightarrow}\m{\forall}\m{x}\m{\varphi}\m{)}
\endm

\subsection{Set Theory}

In order to make the axioms of set theory\index{axioms of set theory} a little
more compact, there are several definitions from logic that we make use of
implicitly, namely, ``logical {\sc and},''\index{conjunction ($\wedge$)}
\index{logical {\sc and} ($\wedge$)} ``logical equivalence,''\index{logical
equivalence ($\leftrightarrow$)}\index{biconditional ($\leftrightarrow$)} and
``there exists.''\index{existential quantifier ($\exists$)}

\begin{center}\begin{tabular}{rcl}
  $( \varphi \wedge \psi )$ &\mbox{stands for}& $\neg ( \varphi
     \rightarrow \neg \psi )$\\
  $( \varphi \leftrightarrow \psi )$& \mbox{stands
     for}& $( ( \varphi \rightarrow \psi ) \wedge
     ( \psi \rightarrow \varphi ) )$\\
  $\exists x \,\varphi$ &\mbox{stands for}& $\neg \forall x \neg \varphi$
\end{tabular}\end{center}

In addition, the axioms of set theory require that all variables be
dis\-tinct,\index{distinct variables}\footnote{Set theory axioms can be
devised so that {\em no} variables are required to be distinct, thus making
{\tt ax-16} and {\tt ax-17} the only axioms requiring the {\tt \$d}
statement.  These axioms are unconventional and are not presented
here.  See the Comment on p.~\pageref{nodd}.}\index{{\tt
\$d} statement} thus we also assume:
\begin{center}
  {\tt \$d }$x\,y\,z\,w$
\end{center}

\noindent Axiom of Extensionality.\index{Axiom of Extensionality}

\setbox\startprefix=\hbox{\tt \ \ ax-ext\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{\forall}\m{x}\m{(}\m{x}\m{\in}\m{y}\m{\leftrightarrow}\m{x}
\m{\in}\m{z}\m{)}\m{\rightarrow}\m{y}\m{=}\m{z}\m{)}
\endm

\noindent Axiom of Replacement.\index{Axiom of Replacement}

\setbox\startprefix=\hbox{\tt \ \ ax-rep\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{\exists}\m{x}\m{(\exists}\m{y}\m{%
\forall}\m{z}\m{(\varphi}\m{\rightarrow}\m{z}\m{%
=}\m{y)}\m{\rightarrow}\m{\forall}\m{z}%
\m{(}\m{z}\m{\in}\m{x}\m{\leftrightarrow}\m{\exists}\m{x}\m{(}\m{x}\m{\in}%
\m{y}\m{\wedge}\m{\forall}\m{y}\m{\varphi}\m{)}\m{)}\m{)}
\endm

\noindent Axiom of Union.\index{Axiom of Union}

\setbox\startprefix=\hbox{\tt \ \ ax-un\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{\exists}\m{x}\m{\forall}\m{y}\m{(}\m{\exists}\m{x}\m{(}\m{y}\m{
\in}\m{x}\m{\wedge}\m{x}\m{\in}\m{z}\m{)}\m{\rightarrow}\m{y}\m{\in}\m{x}\m{)}
\endm

\noindent Axiom of Power Sets.\index{Axiom of Power Sets}

\setbox\startprefix=\hbox{\tt \ \ ax-pow\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{\exists}\m{x}\m{\forall}\m{y}\m{(}\m{\forall}\m{x}\m{(}\m{x}\m{
\in}\m{y}\m{\rightarrow}\m{x}\m{\in}\m{z}\m{)}\m{\rightarrow}\m{y}\m{\in}\m{x}
\m{)}
\endm

\noindent Axiom of Regularity.\index{Axiom of Regularity}

\setbox\startprefix=\hbox{\tt \ \ ax-reg\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{\exists}\m{x}\m{\,x}\m{\in}\m{y}\m{\rightarrow}\m{\exists}
\m{x}\m{(}\m{x}\m{\in}\m{y}\m{\wedge}\m{\forall}\m{z}\m{(}\m{z}\m{\in}\m{x}\m{
\rightarrow}\m{\lnot}\m{z}\m{\in}\m{y}\m{)}\m{)}\m{)}
\endm

\noindent Axiom of Infinity.\index{Axiom of Infinity}

\setbox\startprefix=\hbox{\tt \ \ ax-inf\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{\exists}\m{x}\m{(}\m{y}\m{\in}\m{x}\m{\wedge}\m{\forall}\m{y}%
\m{(}\m{y}\m{\in}\m{x}\m{\rightarrow}\m{\exists}\m{z}\m{(}\m{y}\m{\in}\m{z}\m{%
\wedge}\m{z}\m{\in}\m{x}\m{)}\m{)}\m{)}
\endm

\noindent Axiom of Choice.\index{Axiom of Choice}

\setbox\startprefix=\hbox{\tt \ \ ax-ac\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{\exists}\m{x}\m{\forall}\m{y}\m{\forall}\m{z}\m{(}\m{(}\m{y}\m{%
\in}\m{z}\m{\wedge}\m{z}\m{\in}\m{w}\m{)}\m{\rightarrow}\m{\exists}\m{w}\m{%
\forall}\m{y}\m{(}\m{\exists}\m{w}\m{(}\m{(}\m{y}\m{\in}\m{z}\m{\wedge}\m{z}%
\m{\in}\m{w}\m{)}\m{\wedge}\m{(}\m{y}\m{\in}\m{w}\m{\wedge}\m{w}\m{\in}\m{x}%
\m{)}\m{)}\m{\leftrightarrow}\m{y}\m{=}\m{w}\m{)}\m{)}
\endm

\subsection{That's It}

There you have it, the axioms for all of mathematics!  Wonder at them and
stare at them in awe.  Put a copy in your wallet, and you will carry in your
pocket the encoding for all theorems ever proved and that ever will be proved,
from the most mundane to the most profound.

\section{A Hierarchy of Definitions}\label{hierarchy}

The axioms in the previous section in principle embody everything that can be
done within standard mathematics.  However, it is impractical to accomplish
very much by using them directly, for even simple concepts (from a human
perspective) can involve extremely long, incomprehensible formulas.
Mathematics is made practical by introducing definitions\index{definition}.
Definitions usually introduce new symbols, or at least new relationships among
existing symbols, to abbreviate more complex formulas.  An important
requirement for a definition is that there exist a straightforward
(algorithmic) method for eliminating the abbreviation by expanding it into the
more primitive symbol string that it represents.  Some
important definitions included in
the file {\tt set.mm} are listed in this section for reference, and also to
give you a feel for why something like $\omega$\index{omega ($\omega$)} (the
set of natural numbers\index{natural number} 0, 1, 2,\ldots) becomes very
complicated when completely expanded into primitive symbols.

What is the motivation for definitions, aside from allowing complicated
expressions to be expressed more simply?  In the case of  $\omega$, one goal is
to provide a basis for the theory of natural numbers.\index{natural number}
Before set theory was invented, a set of axioms for arithmetic, called Peano's
postulates\index{Peano's postulates}, was devised and shown to have the
properties the one expects for natural numbers.  Now anyone can postulate a
set of axioms, but if the axioms are inconsistent contradictions can be derived
from them.  Once a contradiction is derived, anything can be trivially
proved, including
all the facts of arithmetic and their negations.  To ensure that an
axiom system is at least as reliable as the axioms for set theory, we can
define sets and operations on those sets that satisfy the new axioms. In the
{\tt set.mm} Metamath database, we prove that the elements of $\omega$ satisfy
Peano's postulates, and it's a long and hard journey to get there directly
from the axioms of set theory.  But the result is confidence in the
foundations of arithmetic.  And there is another advantage:  we now have all
the tools of set theory at our disposal for manipulating objects that obey the
axioms for arithmetic.

What are the criteria we use for definitions?  First, and of utmost importance,
the definition should not be {\em creative}\index{creative
definition}\index{definition!creative}, that
is it should not allow an expression that previously qualified as a wff but
was not provable, to become provable.   Second, the definition should be {\em
eliminable}\index{definition!eliminability}, that is there should exist an
algorithmic method for proving any expression using the definition into
a logically equivalent expression that previously qualified as a wff.

In almost all cases below, definitions connect two expressions with either
$\leftrightarrow$ or $=$.  Eliminating\footnote{Here we mean the
elimination that a human might do in his or her head.  To eliminate them as
part of a Metamath proof we would invoke one of a number of
theorems that deal with transitivity of equivalence or equality; there are
many such examples in the proofs in {\tt set.mm}.} such a definition is a
simple matter of substituting the expression on the left-hand side ({\em
definiendum}\index{definiendum} or thing being defined) with the equivalent,
more primitive expression on the right-hand side ({\em
definiens}\index{definiens} or definition).

Often a definition has variables on the right-hand side which do not appear on
the left-hand side; these are called {\em dummy variables}.\index{dummy
variable!in definitions}  In this case, any
allowable substitution (such as a new, distinct
variable) can be used when the definition is eliminated.  Dummy variables may
be used only if they are {\em effectively bound}\index{effectively bound
variable}, meaning that the definition will remain logically equivalent upon
any substitution of a dummy variable with any other {\em qualifying
expression}\index{qualifying expression}, i.e.\ any symbol string (such as
another variable) that
meets the restrictions on the dummy variable imposed by {\tt \$d} and
{\tt \$f} statements.  For example, we could define a constant $\perp$
(inverted tee, meaning logical ``false'') as $( \varphi \wedge \lnot \varphi
)$, i.e.\ ``phi and not phi.''  Here $\varphi$ is effectively bound because the
definition remains logically equivalent when we replace $\varphi$ with any
other wff.  (We do not define $\perp$ in {\tt set.mm}.)

There are a few cases where eliminating definitions is a little more complex.
These cases are the definitions {\tt df-bi1}, {\tt df-bi2}, {\tt df-bi3},
and {\tt dm-cleq}.  The first three stretch the concept of a
definition a little, as in effect they ``define a definition''; however
taken together they meet our requirements for a definition.  Theorem {\tt bii}
shows the substitution needed to eliminate the $\leftrightarrow$\index{logical
equivalence ($\leftrightarrow$)}\index{biconditional ($\leftrightarrow$)}
symbol.

Definition {\tt dm-cleq}\index{equality ($=$)} extends the usage of
the equality symbol to include ``classes''\index{class} in set theory; the
reason it is potentially problematic is that it can lead to statements which
do not follow from logic alone but presuppose the Axiom of
Extensionality\index{Axiom of Extensionality}, so we include this axiom
as a hypothesis for the definition.  We could have made {\tt dm-cleq} directly
eliminable by introducing a new equality symbol, but have chosen not to do so
in keeping with standard textbook practice.  Definitions such as {\tt dm-cleq}
that extend the meaning of existing symbols must be introduced carefully so
that they do not lead to contradictions.  Definition {\tt df-clel} also
extends the meaning of an existing symbol ($\in$); while it doesn't strengthen
the language like {\tt dm-cleq}, this is not obvious and it must also be
subject to the same scrutiny.

Exercise:  Study how the wff $x\in\omega$, meaning ``$x$ is a natural
number,'' could be expanded in terms of primitive symbols, starting with the
definitions {\tt df-clel} on p.~\pageref{dfclel} and {\tt df-om} on
p.~\pageref{dfom} and working your way back.  Don't bother to work out the
details; just make sure that you understand how you could do it in principle.
The answer is shown in the footnote on p.~\pageref{expandom}.  If you
actually do work it out, you won't get exactly the same answer because we used
a few simplifications such as discarding occurrences of $\lnot\lnot$ (double
negation).

In the definitions below, we have placed the {\sc ascii} Metamath source below
each of the formulas to help you to become familiar with the notation in the
database.  For simplicity, the necessary {\tt \$f} and {\tt \$d} statements
are not shown.  If you are in doubt, use the {\tt show statement}\index{{\tt
show statement} command} command in the Metamath program to see the full
statement.

To understand the motivation for these definitions, you should consult the
references indicated:  Takeuti and Zaring \cite{Takeuti}\index{Takeuti, Gaisi},
Quine \cite{Quine}\index{Quine, Willard Van Orman}, Bell and Machover
\cite{Bell}\index{Bell, J. L.}, and Enderton \cite{Enderton}\index{Enderton,
Herbert B.}.  Our list of definitions is provided more for reference than as a
learning aid.  However, by looking at a few of them you can gain a feel for
how the hierarchy is built up.  The definitions are a representative sample of
the 130 or so in {\tt set.mm}, but they are complete with respect to the
theorem examples we will present in Section~\ref{sometheorems}.  Also, some are
slightly different from, but logically equivalent to, the ones in {\tt set.mm}
(some of which have been revised over time to shorten them, for example).

\subsection{Definitions for Propositional Calculus}\label{metadefprop}

The symbols $\varphi$, $\psi$, and $\chi$ represent wffs.

Our first definition introduces the biconditional connective\footnote{The term
``connective'' is informally used to mean a symbol that is placed
between two variables or adjacent to a variable, whereas a mathematical
``constant'' usually indicates a symbol such as the number 0 that may replace
a variable or metavariable.  From Metamath's point of view, there is no
distinction between a connective and a constant; both are constants in the
Metamath language.}\index{connective}\index{constant} (also called logical
equivalence)\index{logical equivalence ($\leftrightarrow$)}\index{biconditional
($\leftrightarrow$)}.  Unlike most traditional developments, we have chosen
not to have a separate symbol such as ``Df.'' to mean ``is defined as.''
Instead, we will use the biconditional connective for this purpose, as it lets
us to use logic to manipulate definitions directly.  Here we state the
properties of the biconditional connective with three {\tt \$a} statements,
which effectively use the biconditional connective to define itself.  While
the definition verges on being circular, the $\leftrightarrow$
symbol can be eliminated from a formula using theorem {\tt bii}, which is
derived later.

\vskip 2ex
\noindent Define the biconditional connective
(part 1 of 3).

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-bi1\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{(}\m{\varphi}\m{\leftrightarrow}\m{\psi}\m{)}\m{\rightarrow}
\m{(}\m{\varphi}\m{\rightarrow}\m{\psi}\m{)}\m{)}
\endm

\noindent\verb?  df-bi1 $a |- ( ( ph <-> ps ) -> ( ph -> ps ) ) $.?
\vskip 1ex

\noindent Define the biconditional connective (part 2 of 3).

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-bi2\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{(}\m{\varphi}\m{\leftrightarrow}\m{\psi}\m{)}\m{\rightarrow}
\m{(}\m{\psi}\m{\rightarrow}\m{\varphi}\m{)}\m{)}
\endm

\noindent\verb?  df-bi2 $a |- ( ( ph <-> ps ) -> ( ps -> ph ) ) $.?
\vskip 1ex

\noindent Define the biconditional connective (part 3 of 3).

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-bi3\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{(}\m{\varphi}\m{\rightarrow}\m{\psi}\m{)}\m{\rightarrow}\m{(}
\m{(}\m{\psi}\m{\rightarrow}\m{\varphi}\m{)}\m{\rightarrow}\m{(}\m{\varphi}\m{
\leftrightarrow}\m{\psi}\m{)}\m{)}\m{)}
\endm

\noindent\verb?  df-bi3 $a |- ( ( ph -> ps ) -> ( ( ps -> ph ) -> ( ph <->?

\noindent\verb?      ps ) ) ) $.?
\vskip 1ex

\noindent This theorem relates the biconditional connective to primitive
connectives and can be used to eliminate the $\leftrightarrow$ symbol from any
wff.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ bii\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{(}\m{\varphi}\m{\leftrightarrow}\m{\psi}\m{)}\m{\leftrightarrow}
\m{\lnot}\m{(}\m{(}\m{\varphi}\m{\rightarrow}\m{\psi}\m{)}\m{\rightarrow}\m{\lnot}
\m{(}\m{\psi}\m{\rightarrow}\m{\varphi}\m{)}\m{)}\m{)}
\endm

\noindent\verb?  bii $p |- ( ( ph <-> ps ) <-> -. ( ( ph -> ps ) -> -. ( ps?

\noindent\verb?      -> ph ) ) ) $= ... $.?
\vskip 1ex


\noindent Define disjunction ({\sc or}).\index{disjunction ($\vee$)}
\index{logical {\sc or} ($\vee$)}

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-or\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{(}\m{\varphi}\m{\vee}\m{\psi}\m{)}\m{\leftrightarrow}\m{(}\m{
\lnot}\m{\varphi}\m{\rightarrow}\m{\psi}\m{)}\m{)}
\endm

\noindent\verb?  df-or $a |- ( ( ph \/ ps ) <-> ( -. ph -> ps ) ) $.?
\vskip 1ex

\noindent Define conjunction ({\sc and}).\index{conjunction ($\wedge$)}
\index{logical {\sc and} ($\wedge$)}

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-an\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{(}\m{\varphi}\m{\wedge}\m{\psi}\m{)}\m{\leftrightarrow}\m{\lnot}
\m{(}\m{\varphi}\m{\rightarrow}\m{\lnot}\m{\psi}\m{)}\m{)}
\endm

\noindent\verb?  df-an $a |- ( ( ph /\ ps ) <-> -. ( ph -> -. ps ) ) $.?
\vskip 1ex

\noindent Define disjunction ({\sc or}) of 3 wffs.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-3or\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{(}\m{\varphi}\m{\vee}\m{\psi}\m{\vee}\m{\chi}\m{)}\m{
\leftrightarrow}\m{(}\m{(}\m{\varphi}\m{\vee}\m{\psi}\m{)}\m{\vee}\m{\chi}\m{)}
\m{)}
\endm

\noindent\verb?  df-3or $a |- ( ( ph \/ ps \/ ch ) <-> ( ( ph \/ ps ) \/ ch?

\noindent\verb?      ) ) $.?
\vskip 1ex

\noindent Define conjunction ({\sc and}) of 3 wffs.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-3an\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{(}\m{\varphi}\m{\wedge}\m{\psi}\m{\wedge}\m{\chi}\m{)}\m{
\leftrightarrow}\m{(}\m{(}\m{\varphi}\m{\wedge}\m{\psi}\m{)}\m{\wedge}\m{\chi}
\m{)}\m{)}
\endm

\noindent\verb?  df-3an $a |- ( ( ph /\ ps /\ ch ) <-> ( ( ph /\ ps ) /\ ch?

\noindent\verb?      ) ) $.?
%\vskip 1ex

\subsection{Definitions for Predicate Calculus}\label{metadefpred}

The symbols $x$, $y$, and $z$ represent individual variables of predicate
calculus.  In this section, they are not necessarily distinct unless it is
explicitly
mentioned.

\vskip 2ex
\noindent Define existential quantification.\index{existential quantifier
($\exists$)}

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-ex\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{\exists}\m{x}\m{\varphi}\m{\leftrightarrow}\m{\lnot}\m{\forall}
\m{x}\m{\lnot}\m{\varphi}\m{)}
\endm

\noindent\verb?  df-ex $a |- ( E. x ph <-> -. A. x -. ph ) $.?
\vskip 1ex

\noindent Define proper substitution.\index{proper
substitution}\index{substitution!proper}  Note that this
definition is valid even when
$x$ and $y$ are the same variable.  The first conjunct is a ``trick'' used to
achieve this property, making the definition look somewhat peculiar at
first.   For our notation, we use $(\varphi x|y)$ to mean ``the wff that
results when $x$ is properly substituted with $y$ in the wff $\varphi$.''  The
placement of parentheses is slightly different than in the notation $\varphi (
x | y )$ that is sometimes used, because the latter notation is ambiguous
for us:
for example, we don't know whether $\lnot \varphi ( x | y )$ is to be
interpreted as $\lnot ( \varphi x | y )$ or $( \lnot \varphi x | y
)$.\footnote{Because of the way we initially defined wffs, this is the case
with any postfix connective\index{postfix connective} (one occurring after the
symbols being connected) or infix connective\index{infix connective} (one
occurring between the symbols being connected).  Metamath does not have a
built-in notion of operator binding strength that could eliminate the
ambiguity.  The initial parenthesis effectively provides a prefix
connective\index{prefix connective} to eliminate ambiguity.  Some conventions,
such as Polish notation\index{Polish notation} used in the 1930's and 1940's
by Polish logicians, use only prefix connectives and thus allow the total
elimination of parentheses, at the expense of readability.  In Metamath we
could actually redefine all notation to be Polish if we wanted to without
having to change any proofs!}  Other texts often use $\varphi(y)$ to indicate
our $(\varphi x|y)$, but this notation is even more ambiguous since there is
no explicit indication of what is being substituted.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-sb\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{(}\m{\varphi}\m{x}\m{|}\m{y}\m{)}\m{\leftrightarrow}\m{(}\m{(}
\m{x}\m{=}\m{y}\m{\rightarrow}\m{\varphi}\m{)}\m{\wedge}\m{\exists}\m{x}\m{(}\m{x}
\m{=}\m{y}\m{\wedge}\m{\varphi}\m{)}\m{)}\m{)}
\endm

\noindent\verb?  df-sb $a |- ( ( ph x | y ) <-> ( ( x = y -> ph ) /\ E. x (?

\noindent\verb?      x = y /\ ph ) ) ) $.?
\vskip 1ex


\noindent Define existential uniqueness\index{existential uniqueness
quantifier ($\exists "!$)} (``there exists exactly one'').  Note that $y$ is a
variable distinct from $x$ and not occurring in $\varphi$.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-eu\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{\exists}\m{{!}}\m{x}\m{\varphi}\m{\leftrightarrow}\m{\exists}
\m{y}\m{\forall}\m{x}\m{(}\m{\varphi}\m{\leftrightarrow}\m{x}\m{=}\m{y}\m{)}\m{)}
\endm

\noindent\verb?  df-eu $a |- ( E! x ph <-> E. y A. x ( ph <-> x = y ) ) $.?
%\vskip 1ex

\subsection{Definitions for Set Theory}\label{setdefinitions}

The symbols $x$, $y$, $z$, and $w$ represent individual variables of predicate
calculus, which in set theory are understood to be sets.   To make set theory
more practical, we introduce the notion of a ``class.''  A class\index{class}
is either a set variable (such as $x$) or an expression of the form $\{ x |
\varphi\}$ (called an ``abstraction
class''\index{abstraction class}\index{class abstraction}).  Note
that sets (i.e.\ individual variables) always exist (this is a theorem of
logic, namely $\exists y \, y = x$ for any set $x$), whereas classes may or
may not exist (i.e.\ $\exists y \, y = A$ may or may not be true). If a class
does not exist it is called a ``proper class.''\index{proper
class}\index{class!proper}  Definitions {\tt df-clab}, {\tt dm-cleq}, and {\tt
df-clel} can be used to convert an expression containing classes into one
containing only set variables and wff metavariables.

The symbols $A$, $B$, $C$, $D$, $ F$, $G$, and $R$ are metavariables that range
over classes.  A class metavariable $A$ may be eliminated from a wff by
replacing it with $\{ x|\varphi\}$ where neither $x$ nor $\varphi$ occur in
the wff.

In this section, individual variables are always assumed to be distinct from
each other unless otherwise indicated.  In addition, dummy variables on the
right-hand side of a definition do not occur in the class and wff
metavariables in the definition.

\vskip 2ex
\noindent Define the abstraction class.\index{abstraction class}\index{class
abstraction}  $x$ and $y$
need not be distinct.  Definition 2.1 of Quine, p.~16.  This definition may
seem puzzling since it is shorter than the expression being defined and does not
buy us anything in terms of brevity.  The reason we introduce this definition
is because it fits in neatly with the extension of the $\in$ connective
provided by {\tt df-clel}.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-clab\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{x}\m{\in}\m{\{}\m{y}\m{|}\m{\varphi}\m{\}}\m{\leftrightarrow}
\m{(}\m{\varphi}\m{y}\m{|}\m{x}\m{)}\m{)}
\endm

\noindent\verb?  df-clab $a |- ( x e. { y | ph } <-> ( ph y | x ) ) $.?
\vskip 1ex

\noindent Define the equality connective between classes\index{class equality}.  See
Quine or Chapter 4 of Takeuti and Zaring for its justification and methods for
eliminating it. This is an example of a somewhat ``dangerous'' definition,
because it extends the use of the existing equality symbol rather than
introducing a new symbol, allowing us to make statements in the original
language that may not be true.  For example, it permits us to deduce $y = z
\leftrightarrow \forall x ( x \in y \leftrightarrow x  \in z )$ which is not a
theorem of logic but rather presupposes the Axiom of Extensionality,\index{Axiom
of Extensionality} which we include as a hypothesis so that we can
know when this axiom is assumed in a proof (with the {\tt
show trace{\char`\_}back} command).  We could
avoid the danger by introducing another symbol, say $\mbox{\rm {\tt ==}}$, in
place of $=$; this would also have the advantage of making elimination of the
definition straightforward and would eliminate the need for Extensionality as a
hypothesis.  We would then also have the advantage of being able to identify
exactly where Extensionality truly comes into play.  One of our theorems would
be $x \,\mbox{\rm {\tt ==}}\, y  \leftrightarrow x = y$ by invoking
Extensionality.  However in keeping with standard practice we retain the
``dangerous'' definition.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ dm-cleq.1\ \$e\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{\forall}\m{x}\m{(}\m{x}\m{\in}\m{y}\m{\leftrightarrow}\m{x}
\m{\in}\m{z}\m{)}\m{\rightarrow}\m{y}\m{=}\m{z}\m{)}
\endm
\setbox\startprefix=\hbox{\tt \ \ dm-cleq\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{A}\m{=}\m{B}\m{\leftrightarrow}\m{\forall}\m{x}\m{(}\m{x}\m{
\in}\m{A}\m{\leftrightarrow}\m{x}\m{\in}\m{B}\m{)}\m{)}
\endm

\vskip 1ex
\noindent\verb?  dm-cleq.1 $e |- ( A. x ( x e. y <-> x e. z ) -> y = z ) $.?

\noindent\verb?  dm-cleq $a |- ( A = B <-> A. x ( x e. A <-> x e. B ) ) $.?
\vskip 1ex

\noindent Define the membership connective between classes\index{class
membership}.  Theorem 6.3 of Quine, p.~41, which we adopt as a definition.
Note that it extends the use of the existing membership symbol, but unlike {
\tt dm-cleq} it does not extend the set of valid wffs of logic when the class
metavariables are replaced with set variables.\label{dfclel}

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-clel\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{A}\m{\in}\m{B}\m{\leftrightarrow}\m{\exists}\m{x}\m{(}\m{x}
\m{=}\m{A}\m{\wedge}\m{x}\m{\in}\m{B}\m{)}\m{)}
\endm

\noindent\verb?  df-clel $a |- ( A e. B <-> E. x ( x = A /\ x e. B ) ) $.?
\vskip 1ex

\noindent Define inequality.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-ne\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{A}\m{\ne}\m{B}\m{\leftrightarrow}\m{\lnot}\m{A}\m{=}\m{B}%
\m{)}
\endm

\noindent\verb?  df-ne $a |- ( A =/= B <-> -. A = B ) $.?
\vskip 1ex

\noindent Define restricted universal quantification.\index{universal
quantifier ($\forall$)!restricted}  Enderton, p.~22.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-ral\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{\forall}\m{x}\m{\in}\m{A}\m{\varphi}\m{\leftrightarrow}\m{%
\forall}\m{x}\m{(}\m{x}\m{\in}\m{A}\m{\rightarrow}\m{\varphi}\m{)}\m{)}
\endm

\noindent\verb?  df-ral $a |- ( A. x e. A ph <-> A. x ( x e. A -> ph ) ) $.?
\vskip 1ex

\noindent Define restricted existential quantification.\index{existential
quantifier ($\exists$)!restricted}  Enderton, p.~22.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-rex\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{\exists}\m{x}\m{\in}\m{A}\m{\varphi}\m{\leftrightarrow}\m{%
\exists}\m{x}\m{(}\m{x}\m{\in}\m{A}\m{\wedge}\m{\varphi}\m{)}\m{)}
\endm

\noindent\verb?  df-rex $a |- ( E. x e. A ph <-> E. x ( x e. A /\ ph ) ) $.?
\vskip 1ex

\noindent Define the universal class\index{universal class ($V$)}.  Definition
5.20, p.~21, of Takeuti and Zaring.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-v\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{V}\m{=}\m{\{}\m{x}\m{|}\m{x}\m{=}\m{x}\m{\}}
\endm

\noindent\verb?  df-v $a |- V = { x | x = x } $.?
\vskip 1ex

\noindent Define the subclass\index{subclass}\index{subset} relationship
between two classes (called the subset relation if the classes are sets i.e.\
are not proper).  Definition 5.9 of Takeuti and Zaring, p.~17.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-ss\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{A}\m{\subseteq}\m{B}\m{\leftrightarrow}\m{\forall}\m{x}\m{(}
\m{x}\m{\in}\m{A}\m{\rightarrow}\m{x}\m{\in}\m{B}\m{)}\m{)}
\endm

\noindent\verb?  df-ss $a |- ( A (_ B <-> A. x ( x e. A -> x e. B ) ) $.?
\vskip 1ex

\noindent Define the union\index{union} of two classes.  Definition 5.6 of Takeuti and Zaring,
p.~16.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-un\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{A}\m{\cup}\m{B}\m{)}\m{=}\m{\{}\m{x}\m{|}\m{(}\m{x}\m{\in}
\m{A}\m{\vee}\m{x}\m{\in}\m{B}\m{)}\m{\}}
\endm

\noindent\verb?  df-un $a |- ( A u. B ) = { x | ( x e. A \/ x e. B ) } $.?
\vskip 1ex

\noindent Define the intersection\index{intersection} of two classes.  Definition 5.6 of
Takeuti and Zaring, p.~16.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-in\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{A}\m{\cap}\m{B}\m{)}\m{=}\m{\{}\m{x}\m{|}\m{(}\m{x}\m{\in}
\m{A}\m{\wedge}\m{x}\m{\in}\m{B}\m{)}\m{\}}
\endm

\noindent\verb?  df-in $a |- ( A i^i B ) = { x | ( x e. A /\ x e. B ) } $.?
\vskip 1ex

\noindent Define class difference\index{class difference}\index{set difference}.
Definition 5.12 of Takeuti and Zaring, p.~20.  Several notations are used in
the literature; we chose the $\setminus$ convention instead of a minus sign to
reserve the latter for later use in, e.g., arithmetic.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-dif\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{A}\m{\setminus}\m{B}\m{)}\m{=}\m{\{}\m{x}\m{|}\m{(}\m{x}\m{
\in}\m{A}\m{\wedge}\m{\lnot}\m{x}\m{\in}\m{B}\m{)}\m{\}}
\endm

\noindent\verb?  df-dif $a |- ( A \ B ) = { x | ( x e. A /\ -. x e. B ) } $.?
\vskip 1ex

\noindent Define the empty or null set\index{empty set}\index{null set}.
Compare  Definition 5.14 of Takeuti and Zaring, p.~20.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-null\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{\varnothing}\m{=}\m{(}\m{V}\m{\setminus}\m{V}\m{)}
\endm

\noindent\verb?  df-null $a |- (/) = ( V \ V ) $.?
\vskip 1ex

\noindent Define power class\index{power set}\index{power class}.  Definition 5.10 of
Takeuti and Zaring, p.~17, but we also let it apply to proper classes.  (Note
that \verb$P~$ is the symbol for calligraphic P, the tilde
suggesting ``curly;'' see Appendix~\ref{ASCII}.)

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-pw\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{{\cal P}}\m{A}\m{=}\m{\{}\m{x}\m{|}\m{x}\m{\subseteq}\m{A}\m{\}}
\endm

\noindent\verb?  df-pw $a |- P~ A = { x | x (_ A } $.?
\vskip 1ex

\noindent Define the singleton of a class\index{singleton}.  Definition 7.1 of
Quine, p.~48.  It is well-defined for proper classes, although
it is not very meaningful in this case, where it evaluates to the empty
set.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-sn\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{\{}\m{A}\m{\}}\m{=}\m{\{}\m{x}\m{|}\m{x}\m{=}\m{A}\m{\}}
\endm

\noindent\verb?  df-sn $a |- { A } = { x | x = A } $.?
\vskip 1ex

\noindent Define an unordered pair of classes\index{unordered pair}\index{pair}.  Definition
7.1 of Quine, p.~48.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-pr\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{\{}\m{A}\m{,}\m{B}\m{\}}\m{=}\m{(}\m{\{}\m{A}\m{\}}\m{\cup}\m{\{}
\m{B}\m{\}}\m{)}
\endm

\noindent\verb?  df-pr $a |- { A , B } = ( { A } u. { B } ) $.?
\vskip 1ex

\noindent Define an unordered triple of classes\index{unordered triple}.  Definition of
Enderton, p.~19.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-tp\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{\{}\m{A}\m{,}\m{B}\m{,}\m{C}\m{\}}\m{=}\m{(}\m{\{}\m{A}\m{,}\m{B}
\m{\}}\m{\cup}\m{\{}\m{C}\m{\}}\m{)}
\endm

\noindent\verb?  df-tp $a |- { A , B , C } = ( { A , B } u. { C } ) $.?
\vskip 1ex

\noindent Kuratowski's\index{Kuratowski, Kazimierz} ordered pair\index{ordered
pair} definition.  Definition 9.1 of Quine, p.~58. For proper classes it is
not meaningful but is well-defined for convenience.  (Note that \verb$<.$
stands for $\langle$ whereas \verb$<$ stands for $<$, and similarly for
\verb$>.$\,.)

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-op\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{\langle}\m{A}\m{,}\m{B}\m{\rangle}\m{=}\m{\{}\m{\{}\m{A}\m{\}}
\m{,}\m{\{}\m{A}\m{,}\m{B}\m{\}}\m{\}}
\endm

\noindent\verb?  df-op $a |- <. A , B >. = { { A } , { A , B } } $.?
\vskip 1ex

\noindent Define the union of a class\index{union}.  Definition 5.5, p.~16,
of Takeuti and Zaring.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-uni\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{\bigcup}\m{A}\m{=}\m{\{}\m{x}\m{|}\m{\exists}\m{y}\m{(}\m{x}\m{
\in}\m{y}\m{\wedge}\m{y}\m{\in}\m{A}\m{)}\m{\}}
\endm

\noindent\verb?  df-uni $a |- U. A = { x | E. y ( x e. y /\ y e. A ) } $.?
\vskip 1ex

\noindent Define the intersection\index{intersection} of a class.  Definition 7.35,
p.~44, of Takeuti and Zaring.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-int\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{\bigcap}\m{A}\m{=}\m{\{}\m{x}\m{|}\m{\forall}\m{y}\m{(}\m{y}\m{
\in}\m{A}\m{\rightarrow}\m{x}\m{\in}\m{y}\m{)}\m{\}}
\endm

\noindent\verb?  df-int $a |- |^| A = { x | A. y ( y e. A -> x e. y ) } $.?
\vskip 1ex

\noindent Define a transitive class\index{transitive class}\index{transitive
set}.  This should not be confused with a transitive relation, which is a different
concept.  Definition from p.~71 of Enderton, extended to classes.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-tr\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{\mbox{\rm Tr}}\m{A}\m{\leftrightarrow}\m{\bigcup}\m{A}\m{
\subseteq}\m{A}\m{)}
\endm

\noindent\verb?  df-tr $a |- ( Tr A <-> U. A (_ A ) $.?
\vskip 1ex

\noindent Define a notation for a general binary relation\index{binary
relation}.  Definition 6.18, p.~29, of Takeuti and Zaring, generalized to
arbitrary classes.  This definition is well-defined, although not very
meaningful, when classes $A$ and/or $B$ are proper.\label{dfbr}  The lack of
parentheses (or any other connective) is not ambiguous since we are defining
an atomic wff.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-br\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{A}\m{\,R}\m{\,B}\m{\leftrightarrow}\m{\langle}\m{A}\m{,}\m{B}
\m{\rangle}\m{\in}\m{R}\m{)}
\endm

\noindent\verb?  df-br $a |- ( A R B <-> <. A , B >. e. R ) $.?
\vskip 1ex

\noindent Define an abstraction class of ordered pairs\index{abstraction
class!of ordered
pairs}.  A special case of Definition 4.16, p.~14, of Takeuti and Zaring.  Note
that $x$, $y$, and $z$ must be distinct but that $x$ and $y$ may occur in $\varphi$.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-opab\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{\{}\m{\langle}\m{x}\m{,}\m{y}\m{\rangle}\m{|}\m{\varphi}\m{\}}\m{=}
\m{\{}\m{z}\m{|}\m{\exists}\m{x}\m{\exists}\m{y}\m{(}\m{z}\m{=}\m{\langle}\m{x}
\m{,}\m{y}\m{\rangle}\m{\wedge}\m{\varphi}\m{)}\m{\}}
\endm

\noindent\verb?  df-opab $a |- { <. x , y >. | ph } = { z | E. x E. y ( z =?

\noindent\verb?      <. x , y >. /\ ph ) } $.?
\vskip 1ex

\noindent Define the epsilon relation\index{epsilon relation}.  Similar to Definition
6.22, p.~30, of Takeuti and Zaring.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-eprel\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{E}\m{=}\m{\{}\m{\langle}\m{x}\m{,}\m{y}\m{\rangle}\m{|}\m{x}\m{
\in}\m{y}\m{\}}
\endm

\noindent\verb?  df-eprel $a |- E = { <. x , y >. | x e. y } $.?
\vskip 1ex

\noindent Define a founded relation\index{founded relation}.  $R$ is a founded
relation on $A$ iff\index{iff} (if and only if) each nonempty subset of $A$
has an ``$R$-minimal element.''  Similar to Definition 6.21, p.~30, of
Takeuti and Zaring.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-fr\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{R}\m{\,\mbox{\rm Fr}}\m{\,A}\m{\leftrightarrow}\m{\forall}\m{x}
\m{(}\m{(}\m{x}\m{\subseteq}\m{A}\m{\wedge}\m{\lnot}\m{x}\m{=}\m{\varnothing}
\m{)}\m{\rightarrow}\m{\exists}\m{y}\m{(}\m{y}\m{\in}\m{x}\m{\wedge}\m{(}\m{x}
\m{\cap}\m{\{}\m{z}\m{|}\m{z}\m{\,R}\m{\,y}\m{\}}\m{)}\m{=}\m{\varnothing}\m{)}
\m{)}\m{)}
\endm

\noindent\verb?  df-fr $a |- ( R Fr A <-> A. x ( ( x (_ A /\ -. x = (/) ) ->?

\noindent\verb?      E. y ( y e. x /\ ( x i^i { z | z R y } ) = (/) ) ) ) $.?
\vskip 1ex

\noindent Define a well-ordering\index{well-ordering}.  $R$ is a well-ordering of $A$ iff
it is founded on $A$ and the elements of $A$ are pairwise $R$-comparable.
Similar to Definition 6.24(2), p.~30, of Takeuti and Zaring.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-we\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{R}\m{\,\mbox{\rm We}}\m{\,A}\m{\leftrightarrow}\m{(}\m{R}\m{\,
\mbox{\rm Fr}}\m{\,A}\m{\wedge}\m{\forall}\m{x}\m{\forall}\m{y}\m{(}\m{(}\m{x}\m{
\in}\m{A}\m{\wedge}\m{y}\m{\in}\m{A}\m{)}\m{\rightarrow}\m{(}\m{x}\m{\,R}\m{\,y}
\m{\vee}\m{x}\m{=}\m{y}\m{\vee}\m{y}\m{\,R}\m{\,x}\m{)}\m{)}\m{)}\m{)}
\endm

\noindent\verb?  df-we $a |- ( R We A <-> ( R Fr A /\ A. x A. y ( ( x e.?

\noindent\verb?      A /\ y e. A ) -> ( x R y \/ x = y \/ y R x ) ) ) ) $.?
\vskip 1ex

\noindent Define the ordinal predicate\index{ordinal predicate}, which is true for a class
that is transitive and is well-ordered by the epsilon relation.  Similar to
definition on p.~468, Bell and Machover.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-ord\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{\mbox{\rm Ord}}\m{\,A}\m{\leftrightarrow}\m{(}
\m{\mbox{\rm Tr}}\m{\,A}\m{\wedge}\m{E}\m{\,\mbox{\rm We}}\m{\,A}\m{)}\m{)}
\endm

\noindent\verb?  df-ord $a |- ( Ord A <-> ( Tr A /\ E We A ) ) $.?
\vskip 1ex

\noindent Define class of all ordinal numbers\index{ordinal number}.  An ordinal number is
a set that satisfies the ordinal predicate.  Definition 7.11 of Takeuti and
Zaring, p.~38.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-on\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{\,\mbox{\rm On}}\m{=}\m{\{}\m{x}\m{|}\m{\mbox{\rm Ord}}\m{\,x}
\m{\}}
\endm

\noindent\verb?  df-on $a |- On = { x | Ord x } $.?
\vskip 1ex

\noindent Define the limit ordinal predicate\index{limit ordinal}, which is true for a
non-empty ordinal that is not a successor (i.e.\ that is the union of itself).
Compare Bell and Machover, p.~471 and Exercise (1), p.~42 of Takeuti and
Zaring.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-lim\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{\mbox{\rm Lim}}\m{\,A}\m{\leftrightarrow}\m{(}\m{\mbox{
\rm Ord}}\m{\,A}\m{\wedge}\m{\lnot}\m{A}\m{=}\m{\varnothing}\m{\wedge}\m{A}
\m{=}\m{\bigcup}\m{A}\m{)}\m{)}
\endm

\noindent\verb?  df-lim $a |- ( Lim A <-> ( Ord A /\ -. A = (/) /\ A = U.?

\noindent\verb?      A ) ) $.?
\vskip 1ex

\noindent Define the successor\index{successor} of a class.  Definition 7.22 of Takeuti
and Zaring, p.~41.  Our definition is a generalization to classes, although it
is meaningless when classes are proper.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-suc\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{\,\mbox{\rm suc}}\m{\,A}\m{=}\m{(}\m{A}\m{\cup}\m{\{}\m{A}\m{\}}
\m{)}
\endm

\noindent\verb?  df-suc $a |- suc A = ( A u. { A } ) $.?
\vskip 1ex

\noindent Define the class of natural numbers\index{natural number}\index{omega
($\omega$)}.  Compare Bell and Machover, p.~471.\label{dfom}

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-om\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{\omega}\m{=}\m{\{}\m{x}\m{|}\m{(}\m{\mbox{\rm Ord}}\m{\,x}\m{
\wedge}\m{\forall}\m{y}\m{(}\m{\mbox{\rm Lim}}\m{\,y}\m{\rightarrow}\m{x}\m{
\in}\m{y}\m{)}\m{)}\m{\}}
\endm

\noindent\verb?  df-om $a |- om = { x | ( Ord x /\ A. y ( Lim y -> x e. y )?

\noindent\verb?      ) } $.?
\vskip 1ex

\noindent Define the cross product\index{cross product} of two classes.  Definition 9.11
of Quine, p.~64.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-xp\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{A}\m{\times}\m{B}\m{)}\m{=}\m{\{}\m{\langle}\m{x}\m{,}\m{y}
\m{\rangle}\m{|}\m{(}\m{x}\m{\in}\m{A}\m{\wedge}\m{y}\m{\in}\m{B}\m{)}\m{\}}
\endm

\noindent\verb?  df-xp $a |- ( A X. B ) = { <. x , y >. | ( x e. A /\ y e. B?

\noindent\verb?      ) } $.?
\vskip 1ex

\noindent Define the domain\index{domain} of a class.  Definition 6.5(1) of
Takeuti and Zaring, p.~24.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-dm\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{\,\mbox{\rm dom}}\m{A}\m{=}\m{\{}\m{x}\m{|}\m{\exists}\m{y}\m{
\langle}\m{x}\m{,}\m{y}\m{\rangle}\m{\in}\m{A}\m{\}}
\endm

\noindent\verb?  df-dm $a |- dom A = { x | E. y <. x , y >. e. A } $.?
\vskip 1ex

\noindent Define the range\index{range} of a class.  Definition 6.5(2) of
Takeuti and Zaring, p.~24.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-rn\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{\,\mbox{\rm ran}}\m{A}\m{=}\m{\{}\m{y}\m{|}\m{\exists}\m{x}\m{
\langle}\m{x}\m{,}\m{y}\m{\rangle}\m{\in}\m{A}\m{\}}
\endm

\noindent\verb?  df-rn $a |- ran A = { y | E. x <. x , y >. e. A } $.?
\vskip 1ex

\noindent Define the restriction\index{restriction} of a class.  Definition
6.6(1) of Takeuti and Zaring, p.~24.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-res\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{A}\m{\restriction}\m{B}\m{)}\m{=}\m{(}\m{A}\m{\cap}\m{(}\m{B}
\m{\times}\m{V}\m{)}\m{)}
\endm

\noindent\verb?  df-res $a |- ( A |` B ) = ( A i^i ( B X. V ) ) $.?
\vskip 1ex

\noindent Define the image\index{image} of a class.  Definition 6.6(2) of
Takeuti and Zaring, p.~24.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-ima\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{A}\m{``}\m{B}\m{)}\m{=}\m{\,\mbox{\rm ran}}\m{\,(}\m{A}\m{
\restriction}\m{B}\m{)}
\endm

\noindent\verb?  df-ima $a |- ( A " B ) = ran ( A |` B ) $.?
\vskip 1ex

\noindent Define the composition\index{composition} of two classes.  Definition 6.6(3) of
Takeuti and Zaring, p.~24.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-com\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{A}\m{\circ}\m{B}\m{)}\m{=}\m{\{}\m{\langle}\m{x}\m{,}\m{y}\m{
\rangle}\m{|}\m{\exists}\m{z}\m{(}\m{\langle}\m{x}\m{,}\m{z}\m{\rangle}\m{\in}
\m{B}\m{\wedge}\m{\langle}\m{z}\m{,}\m{y}\m{\rangle}\m{\in}\m{A}\m{)}\m{\}}
\endm

\noindent\verb?  df-com $a |- ( A o. B ) = { <. x , y >. | E. z ( <. x , z?

\noindent\verb?      >. e. B /\ <. z , y >. e. A ) } $.?
\vskip 1ex

\noindent Define a relation\index{relation}.  Definition 6.4(1) of Takeuti and
Zaring, p.~23.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-rel\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{\mbox{\rm Rel}}\m{\,A}\m{\leftrightarrow}\m{A}\m{\subseteq}
\m{(}\m{V}\m{\times}\m{V}\m{)}\m{)}
\endm

\noindent\verb?  df-rel $a |- ( Rel A <-> A (_ ( V X. V ) ) $.?
\vskip 1ex

\noindent Define a function\index{function}.  Definition 6.4(4) of Takeuti and
Zaring, p.~24.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-fun\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{\mbox{\rm Fun}}\m{\,A}\m{\leftrightarrow}\m{(}
\m{\mbox{\rm Rel}}\m{\,A}\m{\wedge}
\m{\forall}\m{x}\m{\exists}\m{z}\m{\forall}\m{y}\m{(}
\m{\langle}\m{x}\m{,}\m{y}\m{\rangle}\m{\in}\m{A}\m{\rightarrow}\m{y}\m{=}\m{z}
\m{)}\m{)}\m{)}
\endm

\noindent\verb?  df-fun $a |- ( Fun A <-> ( Rel A /\ A. x E. z A. y ( <. x?

\noindent\verb?      , y >. e. A -> y = z ) ) ) $.?
\vskip 1ex

\noindent Define a function with domain.  Definition 6.15(1) of Takeuti and
Zaring, p.~27.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-fn\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{A}\m{\,\mbox{\rm Fn}}\m{\,B}\m{\leftrightarrow}\m{(}
\m{\mbox{\rm Fun}}\m{\,A}\m{\wedge}\m{\mbox{\rm dom}}\m{\,A}\m{=}\m{B}\m{)}
\m{)}
\endm

\noindent\verb?  df-fn $a |- ( A Fn B <-> ( Fun A /\ dom A = B ) ) $.?
\vskip 1ex

\noindent Define a function with domain and co-domain.  Definition 6.15(3)
of Takeuti and Zaring, p.~27.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-f\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{F}\m{:}\m{A}\m{\longrightarrow}\m{B}\m{
\leftrightarrow}\m{(}\m{F}\m{\,\mbox{\rm Fn}}\m{\,A}\m{\wedge}\m{
\mbox{\rm ran}}\m{\,F}\m{\subseteq}\m{B}\m{)}\m{)}
\endm

\noindent\verb?  df-f $a |- ( F : A --> B <-> ( F Fn A /\ ran F (_ B ) ) $.?
\vskip 1ex

\noindent Define a one-to-one function\index{one-to-one function}.  Compare
Definition 6.15(5) of Takeuti and Zaring, p.~27.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-f1\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{F}\m{:}\m{A}\m{
\raisebox{.5ex}{${\textstyle{\:}_{\mbox{\footnotesize\rm
1\tt -\rm 1}}}\atop{\textstyle{
\longrightarrow}\atop{\textstyle{}^{\mbox{\footnotesize\rm {\ }}}}}$}
}\m{B}
\m{\leftrightarrow}\m{(}\m{F}\m{:}\m{A}\m{\longrightarrow}\m{B}
\m{\wedge}\m{\forall}\m{y}\m{\exists}\m{z}\m{\forall}\m{x}\m{(}\m{\langle}\m{x}
\m{,}\m{y}\m{\rangle}\m{\in}\m{F}\m{\rightarrow}\m{x}\m{=}\m{z}\m{)}\m{)}\m{)}
\endm

\noindent\verb?  df-f1 $a |- ( F : A -1-1-> B <-> ( F : A --> B /\?

\noindent\verb?      A. y E. z A. x ( <. x , y >. e. F -> x = z ) ) ) $.?
\vskip 1ex

\noindent Define an onto function\index{onto function}.  Definition 6.15(4) of Takeuti and
Zaring, p.~27.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-fo\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{F}\m{:}\m{A}\m{
\raisebox{.5ex}{${\textstyle{\:}_{\mbox{\footnotesize\rm
{\ }}}}\atop{\textstyle{
\longrightarrow}\atop{\textstyle{}^{\mbox{\footnotesize\rm onto}}}}$}
}\m{B}
\m{\leftrightarrow}\m{(}\m{F}\m{\,\mbox{\rm Fn}}\m{\,A}\m{\wedge}
\m{\mbox{\rm ran}}\m{\,F}\m{=}\m{B}\m{)}\m{)}
\endm

\noindent\verb?  df-fo $a |- ( F : A -onto-> B <-> ( F Fn A /\ ran F?

\noindent\verb?      = B ) ) $.?
\vskip 1ex

\noindent Define a one-to-one, onto function.  Compare Definition 6.15(6) of
Takeuti and Zaring, p.~27.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-f1o\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{F}\m{:}\m{A}
\m{
\raisebox{.5ex}{${\textstyle{\:}_{\mbox{\footnotesize\rm
1\tt -\rm 1}}}\atop{\textstyle{
\longrightarrow}\atop{\textstyle{}^{\mbox{\footnotesize\rm onto}}}}$}
}
\m{B}
\m{\leftrightarrow}\m{(}\m{F}\m{:}\m{A}
\m{
\raisebox{.5ex}{${\textstyle{\:}_{\mbox{\footnotesize\rm
1\tt -\rm 1}}}\atop{\textstyle{
\longrightarrow}\atop{\textstyle{}^{\mbox{\footnotesize\rm {\ }}}}}$}
}
\m{B}\m{\wedge}\m{F}\m{:}\m{A}
\m{
\raisebox{.5ex}{${\textstyle{\:}_{\mbox{\footnotesize\rm
{\ }}}}\atop{\textstyle{
\longrightarrow}\atop{\textstyle{}^{\mbox{\footnotesize\rm onto}}}}$}
}
\m{B}\m{)}\m{)}
\endm

\noindent\verb?  df-f1o $a |- ( F : A -1-1-onto-> B <-> ( F : A -1-1-> B?

\noindent\verb?      /\ F : A -onto-> B ) ) $.?
\vskip 1ex

\noindent Define the value of a function\index{function value}.  This
definition applies to any class and evaluates to the empty set when it is not
meaningful. Note that $ F`A$ means the same thing as the more familiar $ F(A)$
notation for a function's value at $A$.  The $ F`A$ notation is common in
formal set theory.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-fv\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{F}\m{`}\m{A}\m{)}\m{=}\m{\bigcup}\m{\{}\m{x}\m{|}\m{(}\m{F}%
\m{``}\m{\{}\m{A}\m{\}}\m{)}\m{=}\m{\{}\m{x}\m{\}}\m{\}}
\endm

\noindent\verb?  df-fv $a |- ( F ` A ) = U. { x | ( F " { A } ) = { x } } $.?
\vskip 1ex

\noindent Define the result of an operation.\index{operation}  Here, $F$ is
     an operation on two
     values (such as $+$ for real numbers).   This is defined for proper
     classes $A$ and $B$ even though not meaningful in that case.  However,
     the definition can be meaningful when $F$ is a proper class.\label{dfopr}

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ df-opr\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{A}\m{\,F}\m{\,B}\m{)}\m{=}\m{(}\m{F}\m{`}\m{\langle}\m{A}%
\m{,}\m{B}\m{\rangle}\m{)}
\endm

\noindent\verb?  df-opr $a |- ( A F B ) = ( F ` <. A , B >. ) $.?
%\vskip 1ex

\section{Tricks of the Trade}\label{tricks}

In the {\tt set.mm}\index{set theory database ({\tt set.mm})} database our goal
was usually to conform to modern notation.  However in some cases the
relationship to standard textbook language may be obscured by several
unconventional devices we used to simplify the development and to take
advantage of the Metamath language.  In this section we will describe some
common conventions used in {\tt set.mm}.

\begin{itemize}
\item
The turnstile\index{turnstile ({$\,\vdash$})} symbol, $\vdash$, meaning ``it
is provable that,'' is the first token of all assertions and hypotheses that
aren't syntax constructions.  This is a standard convention in logic.  (We
mentioned this earlier, but this symbol is bothersome to some people without a
logic background.  It has no deeper meaning but just provides us with a way to
distinguish syntax constructions from ordinary mathematical statements.)

\item
A hypothesis of the form

\vskip 1ex
\setbox\startprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \$e\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{\varphi}\m{\rightarrow}\m{\forall}\m{x}\m{\varphi}\m{)}
\endm
\vskip 1ex

should be read ``assume variable $x$ is (effectively) not free in wff
$\varphi$.''\index{effectively not free}
Literally, this says ``assume it is provable that $\varphi \rightarrow \forall
x\, \varphi$.''  This device lets us to avoid the complexities associated with
the standard treatment of free and bound variables.  The footnote
on p.~\pageref{effectivelybound} discusses this further.

\item
A statement of one of the forms

\vskip 1ex
\setbox\startprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{\lnot}\m{\forall}\m{x}\m{\,x}\m{=}\m{y}\m{\rightarrow}
\m{\ldots}\m{)}
\endm
\setbox\startprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{\lnot}\m{\forall}\m{x}\m{\,x}\m{=}\m{y}\m{\rightarrow}
\m{\ldots}\m{)}
\endm
\vskip 1ex

should be read ``if $x$ and $y$ are distinct variables, then...''  This
antecedent provides us with a technical device to avoid the need for the {\tt
\$d} statement early in our development of predicate calculus, permitting symbol
manipulations to be as conceptually simple as those in propositional calculus.
However, the {\tt \$d} statement eventually becomes a requirement, and after
that this device is rarely used.

\item
The statement

\vskip 1ex
\setbox\startprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \$d\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ }
\startm
\m{x}\m{\,y}
\endm
\vskip 1ex

should be read ``assume $x$ and $y$ are distinct variables.''

\item
The statement

\vskip 1ex
\setbox\startprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \$d\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ }
\startm
\m{x}\m{\,\varphi}
\endm
\vskip 1ex

should be read ``assume $x$ does not occur in $\varphi$.''

\item
The statement

\vskip 1ex
\setbox\startprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \$d\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ }
\startm
\m{x}\m{\,A}
\endm
\vskip 1ex

should be read ``assume variable $x$ does not occur in class $A$.''

\item
The restriction and hypothesis group

\vskip 1ex
\setbox\startprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \$d\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ }
\startm
\m{x}\m{\,A}
\endm
\setbox\startprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \$d\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ }
\startm
\m{x}\m{\,\psi}
\endm
\setbox\startprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \$e\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{x}\m{=}\m{A}\m{\rightarrow}\m{(}\m{\varphi}\m{\leftrightarrow}
\m{\psi}\m{)}\m{)}
\endm
\vskip 1ex

is frequently used in place of explicit substitution, meaning ``assume $\psi$
results from the proper
substitution of $A$ for $x$ in $\varphi$.''  Sometimes ``{\tt
\$e} $\vdash ( \psi \rightarrow \forall x \, \psi )$'' is used instead of
``{\tt \$d} $x\, \psi $,'' which requires only that $x$ be effectively
not free in $\varphi$ but not necessarily absent from it.  The use of
implicit
substitution\index{substitution!implicit} is partly a
matter of personal style, although it may make proofs somewhat shorter than
would be the case with explicit substitution.

\item
The hypothesis


\vskip 1ex
\setbox\startprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \$e\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{A}\m{\in}\m{V}
\endm
\vskip 1ex

should be read ``assume class $A$ is a set (i.e.\ exists).''
This is a convenient convention used by Quine.

\item
The restriction and hypothesis

\vskip 1ex
\setbox\startprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \$d\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ }
\startm
\m{x}\m{\,y}
\endm
\setbox\startprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \$e\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{y}\m{\in}\m{A}\m{\rightarrow}\m{\forall}\m{x}\m{\,y}
\m{\in}\m{A}\m{)}
\endm
\vskip 1ex

should be read ``assume variable $x$ is
(effectively) not free in class $A$.''

\end{itemize}

\section{A Theorem Sampler}\label{sometheorems}

In this section we list some of the more important theorems that are proved in
the {\tt set.mm} database, and they illustrate the kinds of things that can be
done with Metamath.  While all of these facts are well-known results in set
theory, Metamath offers the advantage of easily allowing you to trace their
derivation back to axioms.  Our intent here is not to try to explain the
details or motivation; for this we refer you to the textbooks that are
mentioned in the descriptions.  (The {\tt set.mm} file has bibliographic
references for the text references.)  Their proofs often embody important
concepts you may wish to explore with the Metamath program (see
Section~\ref{exploring}).  All the symbols that are used here are defined in
Section~\ref{hierarchy}.  For brevity we haven't included the {\tt \$d}
restrictions or {\tt \$f} hypothesis for these theorems; when you are
uncertain consult the {\tt set.mm} database.

Our first theorem is not very deep but provides us with a notational device
that is frequently used.  It allows us to use the expression ``$A \in V$'' as
a compact way of saying that class $A$ exists, i.e.\ is a set.

\vskip 2ex
\noindent Two ways to say ``$A$ is a set'':  $A$ is a member of the universe
$V$ if and only if $A$ exists (i.e.\ there exists a set equal to $A$).
Theorem 6.9 of Quine, p. 43.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ isset\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{A}\m{\in}\m{V}\m{\leftrightarrow}\m{\exists}\m{x}\m{\,x}\m{=}
\m{A}\m{)}
\endm
\vskip 1ex

Next we prove the axioms of standard ZF set theory that were missing from our
axiom system.  From our point of view they are theorems since they
can be derived from the other axioms.

\vskip 2ex
\noindent Axiom of Separation\index{Axiom of Separation}
(Aussonderung)\index{Aussonderung} proved from the other axioms of ZF set
theory.  Compare Exercise 4 of Takeuti and Zaring, p.~22.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ zfauscl.1\ \$e\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{A}\m{\in}\m{V}
\endm
\setbox\startprefix=\hbox{\tt \ \ zfauscl\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{A}\m{\cap}\m{B}\m{)}\m{\in}\m{V}
\endm
\vskip 1ex

\noindent Axiom of the Null Set\index{Axiom of the Null Set} proved from the
other axioms of ZF set theory. Corollary 5.16 of Takeuti and Zaring, p.~20.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ zfnull\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{\varnothing}\m{\in}\m{V}
\endm
\vskip 1ex

\noindent The Axiom of Pairing\index{Axiom of Pairing} proved from the other
axioms of ZF set theory.  Theorem 7.13 of Quine, p.~51.
\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ zfpaircl\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{\{}\m{A}\m{,}\m{B}\m{\}}\m{\in}\m{V}
\endm
\vskip 2ex

Next we will list some famous or important theorems that are proved in
the {\tt set.mm} database.  None of them except {\tt omex}
require the Axiom of Infinity, as you can verify with the {\tt show
trace{\char`\_}back} Metamath command.

\vskip 2ex
\noindent The resolution of Russell's paradox\index{Russell's paradox}.  There
exists no set containing the set of all sets which are not members of
themselves.  Proposition 4.14 of Takeuti and Zaring, p.~14.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ ru\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{\lnot}\m{\exists}\m{x}\m{\,x}\m{=}\m{\{}\m{y}\m{|}\m{\lnot}\m{y}
\m{\in}\m{y}\m{\}}
\endm
\vskip 1ex

\noindent Cantor's theorem\index{Cantor's theorem}.  No set can be mapped onto
its power set.  Compare Theorem 6B(b) of Enderton, p.~132.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ canth.1\ \$e\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{A}\m{\in}\m{V}
\endm
\setbox\startprefix=\hbox{\tt \ \ canth\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{\lnot}\m{F}\m{:}\m{A}\m{\raisebox{.5ex}{${\textstyle{\:}_{
\mbox{\footnotesize\rm {\ }}}}\atop{\textstyle{\longrightarrow}\atop{
\textstyle{}^{\mbox{\footnotesize\rm onto}}}}$}}\m{{\cal P}}\m{A}
\endm
\vskip 1ex

\noindent The Burali-Forti paradox\index{Burali-Forti paradox}.  No set
contains all ordinal numbers. Enderton, p.~194.  (Burali-Forti was one person,
not two.)

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ tz7.13\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{\lnot}\m{\mbox{\rm On}}\m{\in}\m{V}
\endm
\vskip 1ex

\noindent Peano's postulates\index{Peano's postulates} for arithmetic.
Proposition 7.30 of Takeuti and Zaring, pp.~42--43.  The objects being
described are the members of $\omega$ i.e.\ the natural numbers 0, 1, 2,\ldots.
The successor\index{successor} operation suc means ``plus one.''  {\tt peano1}
says that 0 (which is defined as the empty set) is a natural number.  {\tt
peano2} says that if $A$ is a natural number, so is $A+1$.  {\tt peano3} says
that 0 is not the successor of any natural number.  {\tt peano4} says that two
natural numbers are equal if and only if their successors are equal. {\tt
peano5} is essentially the same as mathematical induction.

\vskip 1ex
\setbox\startprefix=\hbox{\tt \ \ peano1\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{\varnothing}\m{\in}\m{\omega}
\endm
\vskip 1.5ex

\setbox\startprefix=\hbox{\tt \ \ peano2.1\ \$e\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{A}\m{\in}\m{\omega}
\endm
\setbox\startprefix=\hbox{\tt \ \ peano2\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{\mbox{\rm suc}}\m{\,A}\m{\in}\m{\omega}
\endm
\vskip 1.5ex

\setbox\startprefix=\hbox{\tt \ \ peano3.1\ \$e\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{A}\m{\in}\m{\omega}
\endm
\setbox\startprefix=\hbox{\tt \ \ peano3\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{\lnot}\m{\mbox{\rm suc}}\m{\,A}\m{=}\m{\varnothing}
\endm
\vskip 1.5ex

\setbox\startprefix=\hbox{\tt \ \ peano4.1\ \$e\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{A}\m{\in}\m{\omega}
\endm
\setbox\startprefix=\hbox{\tt \ \ peano4.2\ \$e\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{B}\m{\in}\m{\omega}
\endm
\setbox\startprefix=\hbox{\tt \ \ peano4\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{\mbox{\rm suc}}\m{\,A}\m{=}\m{\mbox{\rm suc}}\m{\,B}
\m{\leftrightarrow}\m{A}\m{=}\m{B}\m{)}
\endm
\vskip 1.5ex

\setbox\startprefix=\hbox{\tt \ \ peano5\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{(}\m{\varnothing}\m{\in}\m{A}\m{\wedge}\m{\forall}\m{x}\m{(}
\m{x}\m{\in}\m{\omega}\m{\rightarrow}\m{(}\m{x}\m{\in}\m{A}\m{\rightarrow}
\m{\mbox{\rm suc}}\m{\,x}\m{\in}\m{A}\m{)}\m{)}\m{)}\m{\rightarrow}\m{\omega}
\m{\subseteq}\m{A}\m{)}
\endm
\vskip 1.5ex

\noindent The Principle of Finite Induction (mathematical induction).
\index{finite induction}\index{mathematical induction}  Corollary
7.31 of Takeuti and Zaring, p.~43.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ find.1\ \$e\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{A}\m{\subseteq}\m{\omega}\m{\wedge}\m{\varnothing}\m{\in}
\m{A}\m{\wedge}\m{\forall}\m{x}\m{(}\m{x}\m{\in}\m{\omega}\m{\rightarrow}\m{(}
\m{x}\m{\in}\m{A}\m{\rightarrow}\m{\,\mbox{\rm suc}}\m{\,x}\m{\in}\m{A}\m{)}
\m{)}\m{)}
\endm
\setbox\startprefix=\hbox{\tt \ \ find\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{A}\m{=}\m{\omega}
\endm
\vskip 1ex

\noindent Transfinite Induction Schema.\index{transfinite induction}  Compare
Exercise 25 of Enderton, p.~200.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ tfis.1\ \$e\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{x}\m{\in}\m{\mbox{\rm On}}\m{\rightarrow}\m{(}\m{\forall}
\m{y}\m{(}\m{y}\m{\in}\m{x}\m{\rightarrow}\m{(}\m{\varphi}\m{x}\m{|}\m{y}\m{)}
\m{)}\m{\rightarrow}\m{\varphi}\m{)}\m{)}
\endm
\setbox\startprefix=\hbox{\tt \ \ tfis\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{x}\m{\in}\m{\mbox{\rm On}}\m{\rightarrow}\m{\varphi}\m{)}
\endm
\vskip 1ex

\noindent Principle of Transfinite Recursion.\index{transfinite recursion}
Theorem 7.41 of Takeuti and Zaring, p.~47.  Transfinite recursion is the key
theorem that allows arithmetic of ordinals to be rigorously defined, and has
many
other important uses as well.  Hypotheses {\tt tfr.1} and {\tt tfr.2} specify
a certain (proper) class $ F$.  The complicated definition of $ F$ is not
important in itself; what is important is that there be such an $ F$ with the
required properties, and we show this by displaying $ F$ explicitly.
{\tt tfr1} states that $ F$ is a function whose domain is the set of ordinal
numbers.  {\tt tfr2} states that any value of $ F$ is completely determined by
its previous values and the values of an auxiliary function, $G$.  {\tt tfr3}
states that $ F$ is unique, i.e.\ it is the only function that satisfies {\tt
tfr1} and {\tt tfr2}.  Note that $ f$ is an individual variable like $x$ and
$y$; it is just a mnemonic to remind us that $A$ is a collection of functions.

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ tfr.1\ \$e\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{A}\m{=}\m{\{}\m{f}\m{|}\m{\exists}\m{x}\m{(}\m{x}\m{\in}
\m{\mbox{\rm On}}\m{\wedge}\m{(}\m{(}\m{f}\m{\,\mbox{\rm Fn}}\m{\,x}\m{)}
\m{\wedge}\m{\forall}\m{y}\m{(}\m{y}\m{\in}\m{x}\m{\rightarrow}\m{(}\m{f}
\m{`}
\m{y}\m{)}\m{=}\m{(}\m{G}\m{`}\m{(}\m{f}\m{\restriction}\m{y}\m{)}\m{)}
\m{)}
\m{)}\m{)}\m{\}}
\endm
\setbox\startprefix=\hbox{\tt \ \ tfr.2\ \$e\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{F}\m{=}\m{\bigcup}\m{A}
\endm
\setbox\startprefix=\hbox{\tt \ \ tfr1\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{F}\m{\,\mbox{\rm Fn}}\m{\,\mbox{\rm On}}
\endm
\setbox\startprefix=\hbox{\tt \ \ tfr2\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{x}\m{\in}\m{\mbox{\rm On}}\m{\rightarrow}\m{(}\m{F}\m{`}
\m{x}\m{)}\m{=}\m{(}\m{G}\m{`}\m{(}\m{F}\m{\restriction}\m{x}\m{)}\m{)}\m{)}
\endm
\setbox\startprefix=\hbox{\tt \ \ tfr3\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{(}\m{B}\m{\,\mbox{\rm Fn}}\m{\,\mbox{\rm On}}
\m{\wedge}\m{\forall}\m{x}\m{(}\m{x}\m{\in}\m{\mbox{\rm On}}\m{\rightarrow}
\m{(}\m{B}\m{`}\m{x}\m{)}\m{=}\m{(}\m{G}\m{`}\m{(}\m{B}\m{\restriction}\m{x}
\m{)}\m{)}\m{)}\m{)}\m{\rightarrow}\m{B}\m{=}\m{F}\m{)}
\endm
\vskip 1ex

\noindent The existence of omega (the class of natural numbers).\index{natural
number}\index{omega ($\omega$)}\index{Axiom of Infinity}  Axiom 7 of Takeuti
and Zaring, p.~43.  (This is the only theorem in this section requiring the
Axiom of Infinity.)

\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \
\ omex\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{\omega}\m{\in}\m{V}
\endm
%\vskip 2ex


\section{Axioms for Real and Complex Numbers}\label{real}
\index{real and complex numbers!axioms for}

This section presents the axioms for real and complex numbers.  Analysis
textbooks implicitly or explicity use these axioms or their equivalents are
used as their starting point.  In the database {\tt set.mm}, we define real
and complex numbers as (rather complicated) specific sets and derive the these
axioms as {\em theorems} from the axioms of ZF set theory, using a method
called Dedekind cuts.  We omit the details of this construction, which you can
follow if you wish using the {\tt set.mm} database in conjunction with the
textbooks referenced therein.  The construction is actually unimportant other
than to show that sets exist that satisfy the axioms, and thus that the axioms
are consistent if ZF set theory is consistent.  When working with real numbers
you can think of them as being the actual sets resulting
from the construction (for definiteness), or you can
think of them as otherwise unspecified sets that happen to satisfy the axioms.

For the axioms we are given (or postulate) 8 classes: ${\Bbb C}$ (the set of
complex numbers), ${\Bbb R}$ (the set of real numbers, a subset of ${\Bbb C}$),
$0_{10}$ (zero), $1_{10}$ (one), $i$ (square root of $-1$), $+$ (plus),
$\cdot$ (times), and $<$ (less than).  The subscript on $0_{10}$ and
$1_{10}$ may seem odd, but later in {\tt set.mm} we define a decimal number
as a string of digits, and to prevent ambiguity we need a symbol
identifying the end of the string; for this we use the subscript
denoting ``base 10.''\footnote{If the base 10 seems annoyingly verbose, you
can modify the {\tt latex.def} file to map it to the LaTeX null {\tt
\char`\{\,\char`\}}.}\index{latex@{\LaTeX}}  Subtraction and division are
defined terms and are not part of the axioms; for their definitions see {\tt
set.mm}.

Note that the notation $(A+B)$ (and similarly $(A\cdot B)$) specifies a class
called an {\em operation},\index{operation} and is the function value of the
class $+$ at ordered pair $\langle A,B \rangle$.  An operation is defined by
statement {\tt df-opr} on p.~\pageref{dfopr}.  The notation $A<B$ specifies a
wff called a {\em binary relation}\index{binary relation} and means $\langle
A,B \rangle \in \,<$, as defined by statement {\tt df-br} on p.~\pageref{dfbr}.

Our set of 8 given classes is assumed to satisfy the following 28 axioms.

\vskip 2ex

\noindent 1. The class of complex numbers is a set.

%\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ axcnex\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{{\Bbb C}}\m{\in}\m{V}
\endm
%\vskip 1ex

\noindent 2. The real numbers are a subset of the complex numbers.

%\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ axresscn\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{{\Bbb R}}\m{\subseteq}\m{{\Bbb C}}
\endm
%\vskip 1ex

\noindent 3. Zero is a real number.

%\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ ax0re\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{0}\m{_{10}}\m{\in}\m{{\Bbb R}}
\endm
%\vskip 1ex

\noindent 4. One is a real number.

%\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ ax1re\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{1}\m{_{10}}\m{\in}\m{{\Bbb R}}
\endm
%\vskip 1ex

\noindent 5. The imaginary number $i$ is a complex number.

%\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ axicn\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{i}\m{\in}\m{{\Bbb C}}
\endm
%\vskip 1ex

\noindent 6. Complex numbers are closed under addition.

%\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ axaddcl\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{(}\m{A}\m{\in}\m{{\Bbb C}}\m{\wedge}\m{B}\m{\in}\m{{\Bbb C}}%
\m{)}\m{\rightarrow}\m{(}\m{A}\m{+}\m{B}\m{)}\m{\in}\m{{\Bbb C}}\m{)}
\endm
%\vskip 1ex

\noindent 7. Real numbers are closed under addition.

%\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ axaddrcl\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{(}\m{A}\m{\in}\m{{\Bbb R}}\m{\wedge}\m{B}\m{\in}\m{{\Bbb R}}%
\m{)}\m{\rightarrow}\m{(}\m{A}\m{+}\m{B}\m{)}\m{\in}\m{{\Bbb R}}\m{)}
\endm
%\vskip 1ex

\noindent 8. Complex numbers are closed under multiplication.

%\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ axmulcl\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{(}\m{A}\m{\in}\m{{\Bbb C}}\m{\wedge}\m{B}\m{\in}\m{{\Bbb C}}%
\m{)}\m{\rightarrow}\m{(}\m{A}\m{\cdot}\m{B}\m{)}\m{\in}\m{{\Bbb C}}\m{)}
\endm
%\vskip 1ex

\noindent 9. Real numbers are closed under multiplication.

%\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ axmulrcl\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{(}\m{A}\m{\in}\m{{\Bbb R}}\m{\wedge}\m{B}\m{\in}\m{{\Bbb R}}%
\m{)}\m{\rightarrow}\m{(}\m{A}\m{\cdot}\m{B}\m{)}\m{\in}\m{{\Bbb R}}\m{)}
\endm
%\vskip 1ex

\noindent 10. Addition of complex numbers is commutative.

%\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ axaddcom\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{(}\m{A}\m{\in}\m{{\Bbb C}}\m{\wedge}\m{B}\m{\in}\m{{\Bbb C}}%
\m{)}\m{\rightarrow}\m{(}\m{A}\m{+}\m{B}\m{)}\m{=}\m{(}\m{B}\m{+}\m{A}\m{)}%
\m{)}
\endm
%\vskip 1ex

\noindent 11. Multiplication of complex numbers is commutative.

%\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ axmulcom\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{(}\m{A}\m{\in}\m{{\Bbb C}}\m{\wedge}\m{B}\m{\in}\m{{\Bbb C}}%
\m{)}\m{\rightarrow}\m{(}\m{A}\m{\cdot}\m{B}\m{)}\m{=}\m{(}\m{B}\m{\cdot}\m{A}%
\m{)}\m{)}
\endm
%\vskip 1ex

\noindent 12. Addition of complex numbers is associative.

%\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ axaddass\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{(}\m{A}\m{\in}\m{{\Bbb C}}\m{\wedge}\m{B}\m{\in}\m{{\Bbb C}}%
\m{\wedge}\m{C}\m{\in}\m{{\Bbb C}}\m{)}\m{\rightarrow}\m{(}\m{(}\m{A}\m{+}%
\m{B}\m{)}\m{+}\m{C}\m{)}\m{=}\m{(}\m{A}\m{+}\m{(}\m{B}\m{+}\m{C}\m{)}\m{)}%
\m{)}
\endm
%\vskip 1ex

\noindent 13. Multiplication of complex numbers is associative.

%\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ axmulass\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{(}\m{A}\m{\in}\m{{\Bbb C}}\m{\wedge}\m{B}\m{\in}\m{{\Bbb C}}%
\m{\wedge}\m{C}\m{\in}\m{{\Bbb C}}\m{)}\m{\rightarrow}\m{(}\m{(}\m{A}\m{\cdot}%
\m{B}\m{)}\m{\cdot}\m{C}\m{)}\m{=}\m{(}\m{A}\m{\cdot}\m{(}\m{B}\m{\cdot}\m{C}%
\m{)}\m{)}\m{)}
\endm
%\vskip 1ex

\noindent 14. Multiplication distributes over addition for complex numbers.

%\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ axdistr\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{(}\m{A}\m{\in}\m{{\Bbb C}}\m{\wedge}\m{B}\m{\in}\m{{\Bbb C}}%
\m{\wedge}\m{C}\m{\in}\m{{\Bbb C}}\m{)}\m{\rightarrow}\m{(}\m{A}\m{\cdot}\m{(}%
\m{B}\m{+}\m{C}\m{)}\m{)}\m{=}\m{(}\m{(}\m{A}\m{\cdot}\m{B}\m{)}\m{+}\m{(}%
\m{A}\m{\cdot}\m{C}\m{)}\m{)}\m{)}
\endm
%\vskip 1ex

\noindent 15. One and zero are distinct.

%\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ ax1ne0\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{1}\m{_{10}}\m{\ne}\m{0}\m{_{10}}
\endm
%\vskip 1ex

\noindent 16. Zero is an identity element for addition.

%\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ ax0id\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{A}\m{\in}\m{{\Bbb C}}\m{\rightarrow}\m{(}\m{A}\m{+}\m{0}%
\m{_{10}}\m{)}\m{=}\m{A}\m{)}
\endm
%\vskip 1ex

\noindent 17. One is an identity element for multiplication.

%\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ ax1id\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{A}\m{\in}\m{{\Bbb C}}\m{\rightarrow}\m{(}\m{A}\m{\cdot}\m{1}%
\m{_{10}}\m{)}\m{=}\m{A}\m{)}
\endm
%\vskip 1ex

\noindent 18. Every complex number has a negative.

%\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ axnegex\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{A}\m{\in}\m{{\Bbb C}}\m{\rightarrow}\m{\exists}\m{x}\m{\in}%
\m{{\Bbb C}}\m{(}\m{A}\m{+}\m{x}\m{)}\m{=}\m{0}\m{_{10}}\m{)}
\endm
%\vskip 1ex

\noindent 19. Every nonzero complex number has a reciprocal.

%\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ axrecex\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{A}\m{\in}\m{{\Bbb C}}\m{\rightarrow}\m{(}\m{A}\m{\ne}\m{0}%
\m{_{10}}\m{\rightarrow}\m{\exists}\m{x}\m{\in}\m{{\Bbb C}}\m{(}\m{A}\m{\cdot}%
\m{x}\m{)}\m{=}\m{1}\m{_{10}}\m{)}\m{)}
\endm
%\vskip 1ex

\noindent 20. Every real number has a negative.

%\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ axrnegex\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{A}\m{\in}\m{{\Bbb R}}\m{\rightarrow}\m{\exists}\m{x}\m{\in}%
\m{{\Bbb R}}\m{(}\m{A}\m{+}\m{x}\m{)}\m{=}\m{0}\m{_{10}}\m{)}
\endm
%\vskip 1ex

\noindent 21. Every nonzero real number has a reciprocal.

%\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ axrrecex\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{A}\m{\in}\m{{\Bbb R}}\m{\rightarrow}\m{(}\m{A}\m{\ne}\m{0}%
\m{_{10}}\m{\rightarrow}\m{\exists}\m{x}\m{\in}\m{{\Bbb R}}\m{(}\m{A}\m{\cdot}%
\m{x}\m{)}\m{=}\m{1}\m{_{10}}\m{)}\m{)}
\endm
%\vskip 1ex

\noindent 22. The square of $i$ equals $-1$ (expressed as $i$-squared plus 1 is
0).

%\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ axi2m1\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{(}\m{i}\m{\cdot}\m{i}\m{)}\m{+}\m{1}\m{_{10}}\m{)}\m{=}\m{0}%
\m{_{10}}
\endm
%\vskip 1ex

\noindent 23. Ordering on reals satisfies strict trichotomy.

%\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ axlttri\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{(}\m{A}\m{\in}\m{{\Bbb R}}\m{\wedge}\m{B}\m{\in}\m{{\Bbb R}}%
\m{)}\m{\rightarrow}\m{(}\m{A}\m{<}\m{B}\m{\leftrightarrow}\m{\lnot}\m{(}\m{A}%
\m{=}\m{B}\m{\vee}\m{B}\m{<}\m{A}\m{)}\m{)}\m{)}
\endm
%\vskip 1ex

\noindent 24. Ordering on reals is transitive.

%\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ axlttrn\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{(}\m{A}\m{\in}\m{{\Bbb R}}\m{\wedge}\m{B}\m{\in}\m{{\Bbb R}}%
\m{\wedge}\m{C}\m{\in}\m{{\Bbb R}}\m{)}\m{\rightarrow}\m{(}\m{(}\m{A}\m{<}%
\m{B}\m{\wedge}\m{B}\m{<}\m{C}\m{)}\m{\rightarrow}\m{A}\m{<}\m{C}\m{)}\m{)}
\endm
%\vskip 1ex

\noindent 25. Ordering on reals is preserved after addition to both sides.

%\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ axltadd\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{(}\m{A}\m{\in}\m{{\Bbb R}}\m{\wedge}\m{B}\m{\in}\m{{\Bbb R}}%
\m{\wedge}\m{C}\m{\in}\m{{\Bbb R}}\m{)}\m{\rightarrow}\m{(}\m{A}\m{<}\m{B}\m{%
\rightarrow}\m{(}\m{C}\m{+}\m{A}\m{)}\m{<}\m{(}\m{C}\m{+}\m{B}\m{)}\m{)}\m{)}
\endm
%\vskip 1ex

\noindent 26. The product of two positive reals is positive.

%\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ axmulgt0\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{(}\m{A}\m{\in}\m{{\Bbb R}}\m{\wedge}\m{B}\m{\in}\m{{\Bbb R}}%
\m{)}\m{\rightarrow}\m{(}\m{(}\m{0}\m{_{10}}\m{<}\m{A}\m{\wedge}\m{0}\m{_{10}}%
\m{<}\m{B}\m{)}\m{\rightarrow}\m{0}\m{_{10}}\m{<}\m{(}\m{A}\m{\cdot}\m{B}\m{)}%
\m{)}\m{)}
\endm
%\vskip 1ex

\noindent 27. A complex number can be expressed in terms of two reals.

%\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ axcnre\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{A}\m{\in}\m{{\Bbb C}}\m{\rightarrow}\m{\exists}\m{x}\m{\in}%
\m{{\Bbb R}}\m{\exists}\m{y}\m{\in}\m{{\Bbb R}}\m{A}\m{=}\m{(}\m{x}\m{+}\m{(}%
\m{y}\m{\cdot}\m{i}\m{)}\m{)}\m{)}
\endm
%\vskip 1ex

\noindent 28. A non-empty, bounded-above set of reals has a supremum.

%\vskip 0.5ex
\setbox\startprefix=\hbox{\tt \ \ axsup\ \$p\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{(}\m{(}\m{A}\m{\subseteq}\m{{\Bbb R}}\m{\wedge}\m{A}\m{\ne}\m{%
\varnothing}\m{\wedge}\m{\exists}\m{x}\m{\in}\m{{\Bbb R}}\m{\forall}\m{y}\m{%
\in}\m{A}\m{\,y}\m{<}\m{x}\m{)}\m{\rightarrow}\m{\exists}\m{x}\m{\in}\m{{%
\Bbb R}}\m{(}\m{\forall}\m{y}\m{\in}\m{A}\m{\lnot}\m{x}\m{<}\m{y}\m{\wedge}\m{%
\forall}\m{y}\m{\in}\m{{\Bbb R}}\m{(}\m{y}\m{<}\m{x}\m{\rightarrow}\m{\exists}%
\m{z}\m{\in}\m{A}\m{\,y}\m{<}\m{z}\m{)}\m{)}\m{)}
\endm
\vskip 2ex

This completes the set of axioms for real and complex numbers.  You may
wish to look at how subtraction, division, and decimal numbers
are defined in {\tt set.mm}, and for fun look at the proof of $2_{10}+
2_{10} = 4_{10}$ (theorem {\tt 2p2e4} in {\tt set.mm}).

In {\tt set.mm} we define the non-negative integers ${\Bbb N}$, the integers
${\Bbb Z}$, and the rationals ${\Bbb Q}$ as subsets of ${\Bbb R}$.  This leads
the nice inclusion ${\Bbb N} \subseteq {\Bbb Z} \subseteq {\Bbb Q} \subseteq
{\Bbb R} \subseteq {\Bbb C}$, giving us a uniform framework in which, for
example, a property such as commutativity of complex number addition
automatically applies to integers.  The natural numbers ${\Bbb N}$
are different from the set $\omega$ we defined earlier, but both satisfy
Peano's postulates.

\subsubsection{Complex Number Axioms in Analysis Texts}

Most analysis texts construct complex numbers as ordered pairs of reals,
leading to construction-dependent properties that satisfy
these axioms but are not
stated in their pure form.  (This is also done in {\tt set.mm} but our axioms
are extracted from that construction.)  Other texts will simply state that
$\Bbb R$ is a ``complete ordered subfield of $\Bbb C$,'' leading to redundant
axioms when this phrase is completely expanded out.  In fact I have not seen a
text with the axioms in the explicit form above.  It is possible that one or
more of the axioms above are redundant or could be made weaker; if you
discover an improvement, please let me know, and I will properly acknowledge
your contribution.

\section{Exploring the Set Theory Database}\label{exploring}

At this point you may wish to study the {\tt set.mm}\index{set
theory database ({\tt set.mm})} file in more detail.  Pay
particular attention to the assumptions needed to define
wffs\index{well-formed formula (wff)} (which are not included above),
the variable types ({\tt \$f}\index{{\tt
\$f} statement} statements), and the definitions that are introduced.  Start
with some simple theorems in propositional calculus, making sure you
understand in detail each step of a proof.  Once you get past the first few
proofs and become familiar with the Metamath language, any part of the {\tt
set.mm} database will be as easy to follow, step by step, as any other
part---you won't have to undergo a ``quantum leap'' in mathematical
sophistication to be able to follow a deep proof in set theory.

Next, you may want to explore how concepts such as natural numbers are
defined and described.  This is probably best done in conjunction with
standard set theory textbooks, which can help give you a higher-level
understanding.  The {\tt set.mm} database provides references that will get
you started.  From there, you will be on your way towards a very deep,
rigorous understanding of abstract mathematics.

The Metamath\index{Metamath} program help you peruse a Metamath data\-base,
wheth\-er you are trying to figure out how a certain step follows in a proof or
just have a general curiosity.  We will go through some examples of the
commands, using the {\tt set.mm}\index{set theory database ({\tt set.mm})}
database provided with the Metamath software.  These should help get you
started.  See Chapter~\ref{commands} for a more detailed description of
the commands.  Note that we have included the full spelling of all commands to
prevent ambiguity with future commands.  In practice you may type just the
characters needed to specify each command keyword\index{command keyword}
unambiguously, often just one or two characters per keyword, and you don't
need to type them in upper
case.

First run the Metamath program as described earlier.  You should see the
\verb/MM>/ prompt.  Read in the {\tt set.mm} file:\index{{\tt read}
command}

\begin{verbatim}
MM> READ set.mm
Reading source file "set.mm"...
27302 lines (1172057 characters) were read from "set.mm".
The source file has 10166 statements; 292 are $a and 2340 are
$p.
No errors were found.  However, proofs were not checked.  Use
VERIFY PROOF * if you want to check them.
\end{verbatim}

Let's check the database integrity.  This may take a minute or two to run if
your computer is slow.\footnote{Under Unix, the status dots are displayed only
after the verification is completed due to line buffering in the current
version of Metamath (0.06)\index{Metamath!limitations of version 0.06}.  This
deficiency may be corrected in a future version.}\index{{\tt verify proofs}
command}

\begin{verbatim}
MM> VERIFY PROOFS *
0 10%  20%  30%  40%  50%  60%  70%  80%  90% 100%
..................................................
\end{verbatim}

No errors were reported, so every proof is correct.

You need to know the names (labels) of theorems before you can look at them.
Often just examining the database file(s) with a text editor is the best
approach.  In {\tt set.mm} there are many detailed comments, especially near
the beginning, that can help guide you. The {\tt SEARCH} command in the
Metamath program is also handy.  The {\tt COMMENTS} qualifier will list the
statements whose associated comment (the one immediately before it) contain a
string you give it.  For example, if you are studying Enderton's {\em Elements
of Set Theory} \cite{Enderton}\index{Enderton, Herbert B.} you may want to see
the references to it in the database.  The search string {\tt enderton} is not
case sensitive.  (This will not show you all the database theorems that are in
Enderton's book because there is usually only one citation for a given
theorem, which may appear in several textbooks.)\index{{\tt search}
command}

\begin{verbatim}
MM> SEARCH * "enderton" / COMMENTS
3332 df-ral $a "...niversal quantification. Enderton, p. 22."
3333 df-rex $a "...stential quantification. Enderton, p. 22."
4828 df-tp $a "...of classes. Definition of Enderton, p. 19."
5200 ssuniss $p "...nd union. Exercise 5 of Enderton, p. 26."
5217 opeluu $p "...air belongs. Lemma 3D of Enderton, p. 41."
\end{verbatim}
\begin{center}
(etc.)
\end{center}

Or you may want to see what theorems have something to do with
conjunction (logical {\sc and}).  The quotes around the search
string are optional when there's no ambiguity.\index{{\tt search}
command}

\begin{verbatim}
MM> SEARCH * conjunction / COMMENTS
634 wa $a "...wff definition to include conjunction ('and')."
636 df-an $a "Define conjunction ('and')."
654 iman $p "Express implication in terms of conjunction."
655 annim $p "Express conjunction in terms of implication."
687 pm3.2 $p "... antecedents with conjunction. Theorem *..."
751 anor $p "Conjunction in terms of disjunction (de Morg..."
\end{verbatim}
\begin{center}
(etc.)
\end{center}


Now we will start to look at some details.  Let's look at the first
axiom of propositional calculus.\index{{\tt show statement}
command}

\begin{verbatim}
MM> SHOW STATEMENT ax-1
Statement 10 is located on line 240 of the file "set.mm".
"Axiom of Simplification.
One of the 3 axioms of propositional calculus."
  ax-1 $a |- ( ph -> ( ps -> ph ) ) $.
Its mandatory hypotheses in RPN order are:
  wph $f wff ph $.
  wps $f wff ps $.
The statement and its hypotheses require the variables:  ph
      ps
The variables it contains are:  ph ps
\end{verbatim}

Compare this to {\tt ax-1} on p.~\pageref{ax1}.  You can see that
the symbol {\tt ph} is the {\sc ascii} notation for $\varphi$, etc.  To see the
mathematical symbols for any expression you may typeset it in \LaTeX\ (type
{\tt HELP TEX} for instructions)\index{latex@{\LaTeX}} or, easier, just
use a text editor to look at the
comments where symbols are first introduced in {\tt set.mm}.  The hypotheses
{\tt wph} and {\tt wps} required by {\tt ax-1} mean that variables {\tt ph}
and {\tt ps} must be wffs.

Next we'll pick a simple theorem of propositional calculus, the Principle of
Identity, which is proved directly from the axioms.  We'll look at the
statement then its proof.\index{{\tt show statement}
command}

\begin{verbatim}
MM> SHOW STATEMENT id1
Statement 27 is located on line 307 of the file "set.mm".
"Principle of identity.  Theorem *2.08 of Whitehead and
Russell.  This version is proved directly from the axioms
for demonstration purposes."
  id1 $p |- ( ph -> ph ) $= ... $.
Its mandatory hypotheses in RPN order are:
  wph $f wff ph $.
Its optional hypotheses are:  wps wch wth wet
The statement and its hypotheses require the variables:  ph
These additional variables are allowed in its proof:  ps ch
      th et
The variables it contains are:  ph
\end{verbatim}

The optional variables\index{optional variable} {\tt ps}, {\tt ch}, etc.\ are
available for use in a proof of this statement if we wish, and were we to do
so we would make use of optional hypotheses {\tt wps}, {\tt wch}, etc.  (See
Section~\ref{dollaref} for the meaning of ``optional
hypothesis.''\index{optional hypothesis}) The reason these show up in the
statement display is that statement {\tt id1} happens to be in their scope
(see Section~\ref{scoping} for the definition of ``scope''\index{scope}), but
in fact in propositional calculus we will never make use of optional
hypotheses or variables.  This becomes important after quantifiers are
introduced, where ``dummy'' variables\index{dummy variable} are often needed
in the middle of a proof.

Let's look at the proof of statement {\tt id1}.  We'll suppress the
``non-essential'' steps that construct the wffs.\index{{\tt show proof}
command}

\begin{verbatim}
MM> SHOW PROOF id1 / ESSENTIAL / LEMMON / RENUMBER
1 ax-2           $a |- ( ( ph -> ( ( ph -> ph ) -> ph ) ) ->
                     ( ( ph -> ( ph -> ph ) ) -> ( ph -> ph )
                                                          ) )
2 ax-1           $a |- ( ph -> ( ( ph -> ph ) -> ph ) )
3 1,2 ax-mp      $a |- ( ( ph -> ( ph -> ph ) ) -> ( ph -> ph
                                                          ) )
4 ax-1           $a |- ( ph -> ( ph -> ph ) )
5 3,4 ax-mp      $a |- ( ph -> ph )
\end{verbatim}

If you have read Section~\ref{trialrun}, you'll know how to interpret this
proof.  Step~2, for example, is an application of axiom {\tt ax-1}.  This
proof is identical to the one in Hamilton's {\em Logic for Mathematicians}
\cite[p.~32]{Hamilton}\index{Hamilton, Alan G.}.

You may want to look at what
substitutions\index{substitution!variable}\index{variable substitution} are
made into {\tt ax-1} to arrive at step~2.  The command to do this needs to
know the ``real'' step number, so we'll display the proof again without
the {\tt RENUMBER} qualifier.\index{{\tt show proof}
command}

\begin{verbatim}
MM> SHOW PROOF id1 / LEMMON / ESSENTIAL
18 ax-2          $a |- ( ( ph -> ( ( ph -> ph ) -> ph ) ) ->
                     ( ( ph -> ( ph -> ph ) ) -> ( ph -> ph )
                                                          ) )
21 ax-1          $a |- ( ph -> ( ( ph -> ph ) -> ph ) )
22 18,21 ax-mp   $a |- ( ( ph -> ( ph -> ph ) ) -> ( ph -> ph
                                                          ) )
25 ax-1          $a |- ( ph -> ( ph -> ph ) )
26 22,25 ax-mp   $a |- ( ph -> ph )
\end{verbatim}

The ``real'' step number is 21.  Let's look at its details.

\begin{verbatim}
MM> SHOW PROOF id1 / DETAILED_STEP 21
Proof step 21:  min=ax-1 $a |- ( ph -> ( ( ph -> ph ) -> ph )
  )
This step assigns source "ax-1" ($a) to target "min" ($e).
The source assertion requires the hypotheses "wph" ($f, step
19) and "wps" ($f, step 20).  The parent assertion of the
target hypothesis is "ax-mp" ($a, step 22).
The source assertion before substitution was:
    ax-1 $a |- ( ph -> ( ps -> ph ) )
The following substitutions were made to the source
assertion:
    Variable  Substituted with
     ph        ph
     ps        ( ph -> ph )
The target hypothesis before substitution was:
    min $e |- ph
The following substitution was made to the target hypothesis:
    Variable  Substituted with
     ph        ( ph -> ( ( ph -> ph ) -> ph ) )
\end{verbatim}

This shows the substitutions\index{substitution!variable}\index{variable
substitution} made to the variables in {\tt ax-1}.  References are made to
steps 19 and 20 which are not shown in our proof display.  To see these steps,
you can display the proof without the {\tt ESSENTIAL} qualifier.

Let's look at a slightly more advanced proof of propositional calculus.  Note
that \verb+/\+ is the symbol for $\wedge$ (logical {\sc and}, also
called conjunction).\index{conjunction ($\wedge$)}
\index{logical {\sc and} ($\wedge$)}

\begin{verbatim}
MM> SHOW STATEMENT prth
Statement 931 is located on line 2324 of the file "set.mm".
"Theorem *3.47 of Whitehead and Russell, called 'praeclarum
theorema' by Leibniz."
  prth $p |- ( ( ( ph -> ps ) /\ ( ch -> th ) ) -> ( ( ph /\
      ch ) -> ( ps /\ th ) ) ) $= ... $.
Its mandatory hypotheses in RPN order are:
  wph $f wff ph $.
  wps $f wff ps $.
  wch $f wff ch $.
  wth $f wff th $.
Its optional hypotheses are:  wet
The statement and its hypotheses require the variables:  ph
      ps ch th
These additional variables are allowed in its proof:  et
The variables it contains are:  ph ps ch th

MM> SHOW PROOF prth / ESSENTIAL / LEMMON / RENUMBER
1 pm3.2          $p |- ( ps -> ( th -> ( ps /\ th ) ) )
2 1 syl3dt       $p |- ( ps -> ( ( ch -> th ) -> ( ch -> ( ps
                                                /\ th ) ) ) )
3 2 syl3         $p |- ( ( ph -> ps ) -> ( ph -> ( ( ch -> th
                            ) -> ( ch -> ( ps /\ th ) ) ) ) )
4 3 com23        $p |- ( ( ph -> ps ) -> ( ( ch -> th ) -> (
                           ph -> ( ch -> ( ps /\ th ) ) ) ) )
5 4 impa         $p |- ( ( ( ph -> ps ) /\ ( ch -> th ) ) ->
                           ( ph -> ( ch -> ( ps /\ th ) ) ) )
6 impexp         $p |- ( ( ( ph /\ ch ) -> ( ps /\ th ) ) <->
                           ( ph -> ( ch -> ( ps /\ th ) ) ) )
7 5,6 sylibr     $p |- ( ( ( ph -> ps ) /\ ( ch -> th ) ) ->
                           ( ( ph /\ ch ) -> ( ps /\ th ) ) )
\end{verbatim}

There are references to a lot of unfamiliar statements.  To see what they are,
you may type the following:

\begin{verbatim}
MM> SHOW PROOF prth / STATEMENT_SUMMARY / ESSENTIAL
Summary of statements used in the proof of "prth":

Statement "syl3" is located on line 355 of the file "set.mm".
"Inference adding common antecedents in an implication."
  syl3.1 $e |- ( ph -> ps ) $.
  syl3 $p |- ( ( ch -> ph ) -> ( ch -> ps ) ) $= ... $.

Statement "syl3dt" is located on line 438 of the file
"set.mm".
"Deduction adding nested antecedents."
  syl3dt.1 $e |- ( ph -> ( ps -> ch ) ) $.
  syl3dt $p |- ( ph -> ( ( th -> ps ) -> ( th -> ch ) ) ) $=
      ... $.
\end{verbatim}
\begin{center}
(etc.)
\end{center}

Of course you can look at each of these statements and their proofs, and
so on, back to the axioms of propositional calculus if you wish.

The {\tt SEARCH} command is useful for finding statements when you
know all or part of their contents.  The following example finds all
statements containing \verb@ph -> ps@ followed by \verb@ch -> th@.  The
\verb@$*@ is a wildcard that matches anything; the {\tt \$} before the
\verb$*$ prevents conflicts with math symbol token names.  The \verb@*@ after
{\tt SEARCH} is also a wildcard that in this case means ``match any label.''
\index{{\tt search} command}

\begin{verbatim}
MM> SEARCH * "ph -> ps $* ch -> th"
86 syl9 $p  |- ( ( ph -> ps ) -> ( ( ch -> th ) -> ( ( th ->
    ph ) -> ( ch -> ps ) ) ) )
941 prth $p  |- ( ( ( ph -> ps ) /\ ( ch -> th ) ) -> ( ( ph
    /\ ch ) -> ( ps /\ th ) ) )
\end{verbatim}

Two statements, {\tt syl9} and {\tt prth}, were found to match.

To see what axioms\index{axiom} and definitions\index{definition} {\tt prth}
ultimately depends on for its proof, you can have the program backtrack
through the hierarchy\index{hierarchy} of theorems and definitions.\index{{\tt
show trace{\char`\_}back} command}

\begin{verbatim}
MM> SHOW TRACE_BACK prth / ESSENTIAL / AXIOMS
Statement "prth" assumes the following axioms ($a
statements):
  ax-1 ax-2 ax-3 ax-mp df-bi1 df-bi2 df-bi3 df-an
\end{verbatim}

Note that the 3 axioms of propositional calculus and the modus ponens rule are
needed (as expected); in addition, there are several definitions that are used
along the way.  Note that Metamath makes no distinction\index{axiom vs.\
definition} between axioms\index{axiom} and definitions\index{definition}.  In
{\tt set.mm} they have been distinguished artificially by prefixing their
labels\index{labels in {\tt set.mm}} with {\tt ax-} and {\tt df-}
respectively.  For example, {\tt df-an} defines conjunction (logical {\sc
and}), which is represented by the symbol \verb+/\+.
Section~\ref{definitions} discusses the philosophy of definitions, and the
Metamath language takes a particularly simple, conservative approach by using
the {\tt \$a}\index{{\tt \$a} statement} statement for both axioms and
definitions.

You can also have the program compute how many steps a proof would
have\index{proof length} if all references to theorems were completely
expanded out into references only to {\tt \$a} statements.

\begin{verbatim}
MM> SHOW TRACE_BACK prth / ESSENTIAL / COUNT_STEPS
The proof would have 1255 steps if fully expanded.  The proof
tree has 1714 nodes.  A random backtrack path has an average
path length of 2.996383.  The maximum path length is 12.  A
longest path is:  prth <- impa <- impi <- impt <- pm2.15dt <-
pm2.15 <- negb <- nega <- pm2.18 <- pm2.21 <- syl <- a1d <-
ax-1 .
\end{verbatim}

A proof directly from axioms would thus have 1255 (essential) steps.
The other statistics shown by this command are interpreted as follows.
The proof can be thought of as a tree in which branches fork as many times
as there are steps in the proof: each step refers to an earlier theorem
(or axiom); each step in the earlier theorem refers to an even earlier
theorem, and so on, with all branches ultimately ending with axioms.
There is a node for every step of every proof in this tree.  There are
one or more paths back to axioms that are the longest; this command ferrets
out one of them and shows it to you.  There may be a sense in which the
longest path length is related to how ``deep'' theorem is.

If you were to expand some of the proofs in the later development of set
theory you would often find proofs with billions\index{proof length} or
trillions of steps.  You may wish to try out the {\tt SHOW TRACE{\char`\_}BACK}
command on a few of them.

Finally, we might be curious about what proofs depend the theorem {\tt prth}.
If it is never used later on, we could eliminate it as redundant
if it has no intrinsic interest by itself.\index{{\tt show
usage} command}

\begin{verbatim}
MM> SHOW USAGE prth
Statement "prth" is directly referenced in the proofs of 4
statements:
  im2andt mo trin tfrlem5
\end{verbatim}

Thus {\tt prth} is used by 4 proofs, and indirectly by many more that make
use of {\em those} proofs, and so on.  (The {\tt /RECURSIVE} qualifier gives
you all of them.)

\subsection{A Note on ``Compact'' Proof Format}

The present version of Metamath (0.06)\index{Metamath!limitations of version
0.06} uses an internal proof format called ``compact''\index{compact proof}
that may show up in proof displays and will be slightly confusing unless you
know how to interpret it.  (A future version may eliminate this format from
displays.)  For example, if you display the complete proof of theorem {\tt
id1} it will start off as follows:

\begin{verbatim}
MM> SHOW PROOF id1 / LEMMON
 1 wph           $f wff ph
 2 wph           $f wff ph
 3 wph           $f wff ph
 4 2,3 wi    @1: $a wff ( ph -> ph )
 5 1,4 wi    @2: $a wff ( ph -> ( ph -> ph ) )
 6 @1            $a wff ( ph -> ph )
 7 wph           $f wff ph
 8 @1            $a wff ( ph -> ph )
 9 wph           $f wff ph
10 8,9 wi        $a wff ( ( ph -> ph ) -> ph )
11 7,10 wi       $a wff ( ph -> ( ( ph -> ph ) -> ph ) )
12 @2            $a wff ( ph -> ( ph -> ph ) )
\end{verbatim}

\begin{center}
{etc.}
\end{center}

Step 4 has a ``local label,''\index{local label} {\tt @1}, assigned to it.
Later on, at steps 6 and 8, the label {\tt @1} is referenced instead of
displaying the explicit proof for that step.  This technique takes advantage
of the fact that steps in a proof often repeat, especially during the
construction of wffs.  The compact format reduces the number of steps in the
proof and thus the internal storage requirements for the proof.

If you want to see the normal format with the ``true'' step numbers, you can
use the following workaround:\index{{\tt save proof} command}

\begin{verbatim}
MM> SAVE PROOF id1 / NORMAL
The proof of "id1" has been reformatted and saved internally.
Remember to use WRITE SOURCE to save it permanently.
MM> SHOW PROOF id1 / LEMMON
 1 wph           $f wff ph
 2 wph           $f wff ph
 3 wph           $f wff ph
 4 2,3 wi        $a wff ( ph -> ph )
 5 1,4 wi        $a wff ( ph -> ( ph -> ph ) )
 6 wph           $f wff ph
 7 wph           $f wff ph
 8 6,7 wi        $a wff ( ph -> ph )
 9 wph           $f wff ph
10 wph           $f wff ph
11 wph           $f wff ph
12 10,11 wi      $a wff ( ph -> ph )
13 wph           $f wff ph
14 12,13 wi      $a wff ( ( ph -> ph ) -> ph )
15 9,14 wi       $a wff ( ph -> ( ( ph -> ph ) -> ph ) )
16 wph           $f wff ph
17 wph           $f wff ph
18 wph           $f wff ph
19 17,18 wi      $a wff ( ph -> ph )
20 16,19 wi      $a wff ( ph -> ( ph -> ph ) )
\end{verbatim}

\begin{center}
{etc.}
\end{center}

Note that the original 12 steps are now 20 steps.  However, the format is
now the same as that described in Chapter~\ref{using}.

\chapter{The Metamath Language}
\label{languagespec}

\begin{quote}
  {\em Thus mathematics may be defined as the subject in which we never know
what we are talking about, nor whether what we are saying is true.}
    \flushright\sc  Bertrand Russell\footnote{\cite[p.~84]{Russell2}}\\
\end{quote}\index{Russell, Bertrand}

Probably the most striking feature of the Metamath language is its almost
complete absence of hard-wired syntax. Metamath\index{Metamath} does not
understand any mathematics or logic other than that needed to construct finite
sequences of symbols according to a small set of simple, built-in rules.  The
only rule it uses in a proof is the substitution of an expression (symbol
sequence) for a variable, subject to a simple constraint to prevent
bound-variable clashes.  The primitive notions built into Metamath involve the
simple manipulation of finite objects (symbols) that we as humans can easily
visualize and that computers can easily deal with.  They seem to be just
about the simplest notions possible that are required to do standard
mathematics.

This chapter is serves as a reference manual for the Metamath\index{Metamath}
language. It covers the tedious technical details of the language, some of
which you may wish to skim in a first reading.  On the other hand, you should
pay close attention to the defined terms in {\bf boldface}; they have precise
meanings that are important to keep in mind for later understanding.  It may
be best to first become familiar with the examples in Chapter~\ref{using} to
gain some motivation for the language.

If you are have some knowledge of set theory, you may wish to study this
chapter in conjunction with the formal set-theoretical description of the
Metamath language in Appendix~\ref{formalspec}.

We will use the name ``Metamath''\index{Metamath} to mean either the Metamath
computer language or the Metamath software associated with the computer
language.  We will not distinguish these two when the context is clear.

The next section contains the complete specification of the Metamath
language.\footnote{The current version of the Metamath program
(0.06)\index{Metamath!limitations of version 0.06} implements an older spec
with a slightly more general syntax than described here.  Among the
differences: missing white space between tokens is sometimes tolerated and the
requirement that a {\tt \$f} statement specify a variable before the variable
is used is not enforced.  A future version of the program will conform to the
current spec.} It serves as an authoritative reference and presents the syntax
in enough detail to write a parser\index{parsing Metamath} and proof verifier.
The specification is terse and it is probably hard to learn the language
directly from it, but we include it here for those impatient people who prefer
to see everything up front before looking at verbose expository material.
Later sections explain this material and provide examples.  We will repeat the
definitions in those sections, and you may skip the next section at first
reading and proceed to Section~\ref{tut1} (p.~\pageref{tut1}).  You may want
to come back to it to clarify any fine points.

\section{Specification of the Metamath Language}\label{spec}
\index{Metamath!specification}

\begin{quote}
  {\em Sometimes one has to say difficult things, but one ought to say
them as simply as one knows how.}
    \flushright\sc  G. H. Hardy\footnote{As quoted in
    \cite{deMillo}, p.~273}\\
\end{quote}\index{Hardy, G. H.}

\subsection{Preliminaries}\label{spec1}

A Metamath {\bf database}\index{database} is built up from a top-level source
file together with any source files that are brought in through file inclusion
commands (see below).  The only characters that are allowed to appear in a
Metamath source file are the 94 printable characters on standard {\sc
ascii}\index{ascii@{\sc ascii}} keyboards, which are digits, upper and lower
case letters, and the following 32 special characters\index{special characters}
\label{spec1chars}

\begin{verbatim}
        ` ~ ! @ # $ % ^ & * ( ) - _ = +
        [ ] { } ; : ' " , . < > / ? \ |
\end{verbatim}
plus the following non-printable (white space) characters: space, tab,
carriage return, line feed, and form feed.  We will use {\tt typewriter}
font to display the printable characters.

A Metamath database consists of a sequence of three kinds of {\bf
tokens}\index{token} separated by {\bf white space}\index{white space} (which
is any sequence of one or more white space characters).  The set of {\bf
keyword}\index{keyword} tokens is {\tt \$\char`\{}, {\tt \$\char`\}}, {\tt \$c}, {\tt
\$v}, {\tt \$f}, {\tt \$e}, {\tt \$d}, {\tt \$a}, {\tt \$p}, {\tt \$.}, {\tt
\$=}, {\tt \$(}, {\tt \$)}, {\tt \$[}, and {\tt \$]}.  The last four are
called {\bf auxiliary}\index{auxiliary keyword} or preprocessing keywords.
A {\bf label}\index{label} token consists of any combination of letters,
digits, and the characters hyphen, underscore, and period.  A {\bf math
symbol}\index{math symbol} token may consist of any combination of the 93
printable standard {\sc ascii} characters other than {\tt \$}\ .  All tokens
are case-sensitive.

\subsection{Preprocessing}

{\tt \$(} begins a {\bf comment} and {\tt \$)} ends a comment.\index{{\tt \$(}
and {\tt \$)} auxiliary keywords}\index{comment}  Comments may contain any of
the 94 printable characters and white space, except they may not contain the
2-character sequences {\tt \$(} or {\tt \$)}.  Comments are ignored (treated
like white space) for the purpose of parsing.

Two special characters inside comments, \verb$`$ and \verb$~$, control the
typesetting of comments and are discussed in Section~\ref{mathcomments}. They
may be ignored for the purpose of parsing.

A {\bf file inclusion command} consists of {\tt \$[} followed by a file name
followed by {\tt \$]}.\index{{\tt \$[} and {\tt \$]} auxiliary
keywords}\index{included file}\index{file inclusion}  The file name may not
contain a {\tt \$} or white space.  The file must exist.  The case-sensitivity
of its name follows the conventions of the operating system.  The contents of
the file replace the inclusion command.  Included files may include other
files. Only the first reference to a given file is included; any later
references to the same file (whether in the top-level file or in included
files) cause the inclusion command to be ignored (treated like white space).
A file self-reference is ignored, as is any reference to the top-level file.

Like all tokens, the {\tt \$(}, {\tt \$)}, {\tt \$[}, and {\tt \$]} keywords
must be surrounded by white space.

\subsection{Basic Syntax}

After preprocessing, a database will consist of a sequence of {\bf
statements}.  It may contain only the statement types defined below.  These
are the scoping statements {\tt \$\char`\{} and {\tt \$\char`\}}, along with the {\tt
\$c}, {\tt \$v}, {\tt \$f}, {\tt \$e}, {\tt \$d}, {\tt \$a}, and {\tt \$p}
statements.

A {\bf scoping statement}\index{scoping statement} consists only of its
keyword, {\tt \$\char`\{} or {\tt \$\char`\}}. {\tt \$\char`\{} begins a {\bf
block}\index{block} and a matching {\tt \$\char`\}} ends the block. Every {\tt \$\char`\{}
must have a matching {\tt \$\char`\}}. Defining it recursively, we say a block
contains a sequence of zero or more tokens other
than {\tt \$\char`\{} and {\tt \$\char`\}} and
possibly other blocks.  There is an {\bf outermost
block}\index{block!outermost} not bracketed by {\tt \$\char`\{} {\tt \$\char`\}}; the end
of the outermost block is the end of the database.

% LaTeX bug? can't do \bf\tt

A {\bf \$v} or {\bf \$c statement}\index{{\tt \$v} statement}\index{{\tt \$c}
statement} consists of the keyword token {\tt \$v} or {\tt \$c} respectively,
followed by one or more math symbols, followed by {\tt \$.}\,.  These
statements {\bf declare}\index{declaration} the math symbols to be {\bf
variables}\index{variable!Metamath} or {\bf constants}\index{constant}
respectively. The same math symbol may not occur twice in a given {\tt \$v} or
{\tt \$c} statement.

%c%A math symbol becomes an {\bf active}\index{active math symbol}
%c%when declared and stays active until the end of the block in which it is
%c%declared.  A math symbol may not be declared a second time while it is active,
%c%but it may be declared again after it becomes inactive.

A math symbol becomes {\bf active}\index{active math symbol} when declared
and stays active until the end of the block in which it is declared.  A
variable may not be declared a second time while it is active, but it
may be declared again (as a variable, but not as a constant) after it
becomes inactive.  A constant must be declared in the outermost block and may
not be declared a second time.\footnote{The rules for redeclaration may
become more general in the future; see footnote on
p.~\pageref{redeclarationf}.}\index{redeclaration of symbols}

A {\bf \$f statement}\index{{\tt \$f} statement} consists of a label,
followed by {\tt \$f}, followed by an active constant, followed by an active
variable, followed by {\tt \$.}\,.  A {\bf \$e statement}\index{{\tt
\$e} statement} consists of a label, followed by {\tt \$e}, followed by an
active constant, followed zero or more active math symbols, followed by {\tt
\$.}\,. A {\bf hypothesis}\index{hypothesis} is a {\tt \$f} or {\tt \$e}
statement.

A {\bf simple \$d statement}\index{{\tt \$d} statement!simple} consists
of {\tt \$d}, followed by two different active variables, followed by {\tt
\$.}\,.  A {\bf compound \$d statement}\index{{\tt \$d}
statement!compound} consists of {\tt \$d}, followed by three or more variables
(all different), followed by {\tt \$.}\,.  The order of the variables in a
{\tt \$d} statement is unimportant.  A compound {\tt \$d} statement is
equivalent to a set of simple {\tt \$d} statements, one for each possible pair
of variables occurring in the compound {\tt \$d} statement. Henceforth in this
specification we shall assume all {\tt \$d} statements are simple. A {\tt \$d}
statement is also called a {\bf disjoint} (or {\bf distinct}) {\bf variable
restriction}.\index{disjoint-variable restriction}

A {\bf \$a statement}\index{{\tt \$a} statement} consists of a label,
followed by {\tt \$a}, followed by an active constant, followed by zero or
more active math symbols, followed by {\tt \$.}\,.  A {\bf \$p
statement}\index{{\tt \$p} statement} consists of a label, followed by {\tt
\$p}, followed by an active constant, followed by a zero or more
active math symbols, followed by {\tt \$=}, followed by a sequence of labels,
followed by {\tt \$.}\,. An {\bf assertion}\index{assertion} is a {\tt \$a} or
{\tt \$p} statement.

A {\tt \$f}, {\tt \$e}, or {\tt \$d} statement is {\bf active}\index{active
statement} from the place it occurs until the end of the block it occurs in.
A {\tt \$a} or {\tt \$p} statement is {\bf active} from the place it occurs
through the end of the database.

There may not be two active {\tt \$f} statements containing the same variable.
Each variable in a {\tt \$e}, {\tt \$d}, {\tt \$a}, or {\tt \$p} statement
must exist in an active {\tt \$f} statement.

The label that begins each {\tt \$f}, {\tt \$e}, {\tt \$a}, and {\tt \$p}
statement must be unique.

The set of {\bf mandatory variables}\index{mandatory variable} associated with
an assertion is the set of (zero or more) variables in the assertion and in any
active {\tt \$e} statements.  The (possibly empty) set of {\bf mandatory
hypotheses}\index{mandatory hypothesis} is the set of all active {\tt \$f}
statements containing mandatory variables, together with all active {\tt \$e}
statements.

The set of {\bf mandatory {\bf \$d} statements}\index{mandatory
disjoint-variable restriction} associated with an assertion are those active
{\tt \$d} statements whose variables are both among the assertion's
mandatory variables.

\subsection{Proof Verification}\label{spec4}

The sequence of labels between the {\tt \$=} and {\tt \$.}\ tokens in a {\tt
\$p} statement is a {\bf proof}.\index{proof!Metamath}  Each label in a
proof must be the label of an active statement other than the {\tt \$p}
statement itself; thus a label must refer either to an active hypothesis of
the {\tt \$p} statement or to an earlier assertion.

An {\bf expression}\index{expression} is a sequence of math symbols. A {\bf
substitution map}\index{substitution map} associates a set of variables with a
set of expressions.  It is acceptable for a variable to be mapped to an
expression containing it.  A {\bf
substitution}\index{substitution!variable}\index{variable substitution} is the
simultaneous replacement of all variables in one or more expressions with the
expressions that the variables map to.

A proof is scanned in order of its label sequence.  If the label refers to an
active hypothesis, the expression in the hypothesis is pushed onto a
stack.\index{stack}\index{RPN stack}  If the label refers to an assertion, a
(unique) substitution must exist that, when made to the mandatory hypotheses
of the referenced assertion, causes them to match the topmost (i.e.\ most
recent) entries of the stack, in order of occurrence of the mandatory
hypotheses, with the topmost stack entry matching the last mandatory
hypothesis of the referenced assertion.  As many stack entries as there are
mandatory hypotheses are then popped from the stack.  The same substitution is
made to the referenced assertion, and the result is pushed onto the stack.
After the last label in the proof is processed, the stack must have a single
entry that matches the expression in the {\tt \$p} statement containing the
proof.

%c%{\footnotesize\begin{quotation}\index{redeclaration of symbols}
%c%{{\em Comment.}\label{spec4comment} Whenever a math symbol token occurs in a
%c%{{\tt \$c} or {\tt \$v} statement, it is considered to designate a distinct new
%c%{symbol, even if the same token was previously declared (and is now inactive).
%c%{Thus a math token declared as a constant in two different blocks is considered
%c%{to designate two distinct constants (even though they have the same name).
%c%{The two constants will not match in a proof that references both blocks.
%c%{However, a proof referencing both blocks is acceptable as long as it doesn't
%c%{require that the constants match.  Similarly, a token declared to be a
%c%{constant for a referenced assertion will not match the same token declared to
%c%{be a variable for the {\tt \$p} statement containing the proof.  In the case
%c%{of a token declared to be a variable for a referenced assertion, this is not
%c%{an issue since the variable can be substituted with whatever expression is
%c%{needed to achieve the required match.
%c%{\end{quotation}}
%c2%A proof may reference an assertion that contains or whose hypotheses contain a
%c2%constant that is not active for the {\tt \$p} statement containing the proof.
%c2%However, the final result of the proof may not contain that constant. A proof
%c2%may also reference an assertion that contains or whose hypotheses contain a
%c2%variable that is not active for the {\tt \$p} statement containing the proof.
%c2%That variable, of course, will be substituted with whatever expression is
%c2%needed to achieve the required match.

A proof may contain a {\tt ?}\ in place of a label to indicate an unknown step
(Section~\ref{unknown}).  A proof verifier may ignore any proof containing
{\tt ?}\ but should warn the user that the proof is incomplete.

A {\bf compressed proof}\index{compressed proof}\index{proof!compressed} is an
alternate proof notation described in Appendix~\ref{compressed}; also see
references to ``compressed proof'' in the Index.  Compressed proofs are a
Metamath language extension which a complete proof verifier should be able to
parse and verify.

\subsubsection{Verifying Disjoint Variable Restrictions}

Each substitution made in a proof must be checked to verify that any
disjoint variable restrictions are satisfied, as follows.

If two variables replaced by a substitution exist in a mandatory {\tt \$d}
statement\index{{\tt \$d} statement} of the assertion referenced, the two
expressions resulting from the substitution must meet satisfy the following
conditions.  First, the two expressions must have no variables in common.
Second, each possible pair of variables, one from each expression, must exist
in an active {\tt \$d} statement of the {\tt \$p} statement containing the
proof.

\vskip 1ex

This ends the specification of the Metamath language.


\section{The Basic Keywords}\label{tut1}

Our expository material begins here.

Like most computer languages, Metamath\index{Metamath} takes its input from
one or more {\bf source files}\index{source file} which contain characters
expressed in the standard {\sc ascii} (American Standard for Coded Information
Interchange)\index{ascii@{\sc ascii}} code for computers.  A source file
consists of a series of {\bf tokens}\index{token}, which are strings of
printable characters (from the set of 94 shown on p.~\pageref{spec1chars})
separated by {\bf white space}\index{white space} (spaces, tabs, carriage
returns, line feeds, and form feeds). Any string consisting only of these
characters is treated the same as a single space.  The printable
characters\index{printable character} that Metamath recognizes are the 94
characters on standard {\sc ascii} keyboards.

Metamath has the ability to join several files together to form its input
(Section~\ref{include}).  We call the aggregate contents of all the files
after they have been joined together a {\bf database}\index{database} to
distinguish it from an individual source file. The tokens in a database
consist of {\bf keywords}\index{keyword}, which are built into the language,
together with two kinds of user-defined tokens called {\bf
labels}\index{label} and {\bf math symbols}\index{math symbol}.  (Often we
will simply say {\bf symbol}\index{symbol} instead of  math symbol for
brevity).  The set of {\bf basic keywords}\index{basic keyword} is {\tt
\$c}\index{{\tt \$c} statement}, {\tt \$v}\index{{\tt \$v} statement}, {\tt
\$e}\index{{\tt \$e} statement}, {\tt \$f}\index{{\tt \$f} statement}, {\tt
\$d}\index{{\tt \$d} statement}, {\tt \$a}\index{{\tt \$a} statement}, {\tt
\$p}\index{{\tt \$p} statement}, {\tt \$=}\index{{\tt \$=} keyword}, {\tt
\$.}\index{{\tt \$.}\ keyword}, {\tt \$\char`\{}\index{{\tt \$\char`\{} and {\tt \$\char`\}}
keywords}, and {\tt \$\char`\}}.  This is the complete set of syntactical elements
of what we call the {\bf basic language}\index{basic language} of Metamath,
and with them you can express all of the mathematics that were
intended by the design of Metamath.  You should make it a point to become very
familiar with them. Table~\ref{basickeywords} lists the basic keywords along
with a brief description of their functions.  For now, this description will
give you only a vague notion of what the keywords are for; later we will
describe
the keywords in detail.


\begin{table}[htp] \caption{Summary of the basic Metamath
keywords} \label{basickeywords} \begin{center}
\begin{tabular}{|p{4pc}|l|}
\hline
\em \centering Keyword&\em Description\\
\hline
\hline
\centering
   {\tt \$c}&Constant symbol declaration\\
\hline
\centering
   {\tt \$v}&Variable symbol declaration\\
\hline
\centering
   {\tt \$d}&Disjoint variable restriction\\
\hline
\centering
   {\tt \$f}&Variable-type (``floating'') hypothesis\\
\hline
\centering
   {\tt \$e}&Logical (``essential'') hypothesis\\
\hline
\centering
   {\tt \$a}&Axiomatic assertion\\
\hline
\centering
   {\tt \$p}&Provable assertion\\
\hline
\centering
   {\tt \$=}&Start of proof in {\tt \$p} statement\\
\hline
\centering
   {\tt \$.}&End of the above statement types\\
\hline
\centering
   {\tt \$\char`\{}&Start of block\\
\hline
\centering
   {\tt \$\char`\}}&End of block\\
\hline
\end{tabular}
\end{center}
\end{table}

%For LaTeX bug(?) where it puts tables on blank page instead of btwn text
%May have to adjust if text changes
%\newpage

There are some additional keywords, called {\bf auxiliary
keywords}\index{auxiliary keyword} that help make Metamath\index{Metamath}
more practical. These are part of the {\bf extended language}\index{extended
language}. They provide you with a means to put comments into a Metamath
source file\index{source file} and reference other source files.  We will
introduce these in later sections. Table~\ref{otherkeywords} summarizes them
so that you can recognize them now if you want to peruse some source
files while learning the basic keywords.


\begin{table}[htp] \caption{Auxiliary Metamath
keywords} \label{otherkeywords} \begin{center}
\begin{tabular}{|p{4pc}|l|}
\hline
\em \centering Keyword&\em Description\\
\hline
\hline
\centering
   {\tt \$(}&Start of comment\\
\hline
\centering
   {\tt \$)}&End of comment\\
\hline
\centering
   {\tt \$[}&Start of included source file name\\
\hline
\centering
   {\tt \$]}&End of included source file name\\
\hline
\end{tabular}
\end{center}
\end{table}
\index{{\tt \$(} and {\tt \$)} auxiliary keywords}
\index{{\tt \$[} and {\tt \$]} auxiliary keywords}


Unlike those in some computer languages, the keywords\index{keyword} are short
two-character sequences rather than English-like words.  While this may make
them slightly more difficult to remember at first, their brevity allows
them to blend in with the mathematics being described, not
distract from it, like punctuation marks.


\subsection{User-Defined Tokens}\label{dollardollar}\index{token}

As you may have noticed, all keywords\index{keyword} begin with the {\tt \$}
character.  This mundane monetary symbol is not ordinarily used in higher
mathematics (outside of grant proposals), so we have appropriated it to
distinguish the Metamath\index{Metamath} keywords from ordinary mathematical
symbols. The {\tt \$} character is thus considered special and may not be
used as a character in a user-defined token.  All tokens and keywords are
case-sensitive; for example, {\tt n} is considered to be a different character
from {\tt N}.  Case-sensitivity makes the available {\sc ascii} character set
as rich as possible.

\subsubsection{Math Symbol Tokens}\index{token}

Math symbols\index{math symbol} are tokens used to represent the symbols that
appear in ordinary mathematical formulas.  They may consist of any combination
of the 93 printable {\sc ascii} characters other than {\tt
\$}\ .  Some examples are {\tt x}, {\tt +}, {\tt (}, {\tt |-}, \verb$!%@?&$,
and {\tt bounded}.  For readability, it is best to try to make these look as
similar to actual mathematical symbols as possible, within the constraints of
the {\sc ascii} character set, in order to make the resulting mathematical
expressions more readable.

In the Metamath\index{Metamath} language, you express ordinary mathematical
formulas and statements as sequences of math symbols such as {\tt 2 + 2 = 4}
(five symbols, all constants).\footnote{To eliminate ambiguity with other
expressions, this is expressed in the set theory database {\tt set.mm} as {\tt
|- ( 2 {\char`\_}10 + 2 {\char`\_}10 ) = 4 {\char`\_}10}, whose
\LaTeX\ equivalent is
$\vdash (2_{10}+2_{10})=4_{10}$.  The \,$\vdash$  means ``is a theorem,'' the
parentheses allow explicit associative grouping, and the explicit base 10 is
a actually a device to unambiguously indicate the end of a digit
string.}\index{turnstile ({$\,\vdash$})}  They may even be English sentences,
as in {\tt E is closed and bounded} (five symbols)---here {\tt E} would be a
variable and the other four symbols constants.  In principle, a Metamath
database could be constructed to work with almost any unambiguous
English-language mathematical statement, but as a practical matter the
definitions needed to provide for all possible syntax variations would be
cumbersome and distracting and possibly have subtle pitfalls accidentally built
in.  We generally recommend that you express mathematical statements with
compact standard mathematical symbols whenever possible and put their
English-language descriptions in comments.  Axioms\index{axiom} and
definitions\index{definition} ({\tt \$a}\index{{\tt \$a} statement}
statements) are the only places where Metamath will not detect an error, and
doing this will help reduce the number of definitions needed.

You are free to use any tokens\index{token} you like for math
symbols\index{math symbol}.  Appendix~\ref{ASCII} recommends token names to
use for symbols in set theory, and we suggest you adopt these in order to be
able to include the {\tt set.mm} set theory database in your database.  For
printouts, you can convert the tokens in a database
to standard mathematical symbols with the \LaTeX\ typesetting program.  The
Metamath command {\tt open tex} {\em filename}\index{{\tt open tex} command}
produces output that can be read by \LaTeX\ (with
AMSFonts).\index{latex@{\LaTeX}}  The file that defines the correspondence
between tokens and the actual symbols is called {\tt latex.def}.  You can edit
this file to change the definitions or add new ones, although you may want to
call the file a different name to distinguish it from the original provided
with Metamath.  Appendix~\ref{ASCII} describes how to do this in more detail.

% White space\index{white space} is normally used to separate math
% symbol\index{math symbol} tokens, but they may be juxtaposed without white
% space in {\tt \$d}\index{{\tt \$d} statement}, {\tt \$e}\index{{\tt \$e}
% statement}, {\tt \$f}\index{{\tt \$f} statement}, {\tt \$a}\index{{\tt \$a}
% statement}, and {\tt \$p}\index{{\tt \$p} statement} statements when no
% ambiguity will result.  Specifically, Metamath parses the math symbol sequence
% in one of these statements in the following manner:  when the math symbol
% sequence has been broken up into tokens\index{token} up to a given character,
% the next token is the longest string of characters that could constitute a
% math symbol that is active\index{active
% math symbol} at that point.  (See Section~\ref{scoping} for the
% definition of an active math symbol.)  For example, if {\tt -}, {\tt >}, and
% {\tt ->} are the only active math symbols, the juxtaposition {\tt >-} will be
% interpreted as the two symbols {\tt >} and {\tt -}, whereas {\tt ->} will
% always be interpreted as that single symbol.\footnote{For better readability we
% recommend a white space between each token.  This also makes searching for a
% symbol easier to do with an editor.  Omission of optional white space is useful
% for reducing typing when assigning an expression to a temporary
% variable\index{temporary variable} with the {\tt let variable} Metamath
% program command.}\index{{\tt let variable} command}
%
% Keywords\index{keyword} may be placed next to math symbols without white
% space\index{white space} between them.\footnote{Again, we do not recommend
% this for readability.}
%
% The math symbols\index{math symbol} in {\tt \$c}\index{{\tt \$c} statement}
% and {\tt \$v}\index{{\tt \$v} statement} statements must always be separated
% by white space\index{white
% space}, for the obvious reason that these statements define the names
% of the symbols.
%
% Math symbols referred to in comments (see Section~\ref{comments}) must also be
% separated by white space.  This allows you to make comments about symbols that
% are not yet active\index{active
% math symbol}.  (The ``math mode'' feature of comments is also a quick and
% easy way to obtain word processing text with embedded mathematical symbols,
% independently of the main purpose of Metamath; the way to do this is described
% in Section~\ref{comments})

\subsubsection{Label Tokens}\index{token}\index{label}

Label tokens are used to identify Metamath\index{Metamath} statements for
later reference. Label tokens may contain only letters, digits, and the three
characters period, hyphen, and underscore:\begin{verbatim}
        . - _
\end{verbatim}

A label is {\bf declared}\index{label declaration} by placing it immediately
before the keyword of the statement it identifies.  For example, the label
{\tt axiom.1} might be declared as follows:
\begin{verbatim}
        axiom.1 $a |- x = x $.
\end{verbatim}

Each {\tt \$e}\index{{\tt \$e} statement}, {\tt \$f}\index{{\tt \$f}
statement}, {\tt \$a}\index{{\tt \$a} statement}, and {\tt \$p}\index{{\tt
\$p} statement} statement in a database must have a label declared
for it.  No other statement types may have label declarations.  Every
label must be unique.

A label (and the statement it identifies) is {\bf referenced}\index{label
reference} by including the label between the {\tt \$=}\index{{\tt \$=}
keyword} and {\tt \$.}\index{{\tt \$.}\ keyword}\ keywords in a {\tt \$p}
statement.  The sequence of labels\index{label sequence} between these two
keywords is called a {\bf proof}\index{proof}.  An example of a statement with
a proof that we will encounter later (Section~\ref{proof}) is
\begin{verbatim}
        wnew $p wff ( s -> ( r -> p ) )
             $= ws wr wp w2 w2 $.
\end{verbatim}

You don't have to know what this means just yet, but you should know that the
label {\tt wnew} is declared by this {\tt \$p} statement and that the labels
{\tt ws}, {\tt wr}, {\tt wp}, and {\tt w2} are assumed to have been declared
earlier in the database and are referenced here.

\subsection{Constants and Variables}
\index{constant}
\index{variable}

An {\bf expression}\index{expression} is any sequence of math
symbols, possibly empty.

The basic Metamath\index{Metamath} language\index{basic language} has two
kinds of math symbols\index{math symbol}:  {\bf constants}\index{constant} and
{\bf variables}\index{variable}.  In a Metamath proof, a constant may not be
substituted with any expression.  A variable can be
substituted\index{substitution!variable}\index{variable substitution} with any
expression.  This sequence may include other variables and may even include
the variable being substituted.  This substitution takes place when proofs are
verified, and it will be described in Section~\ref{proof}.  The {\tt \$f}
statement (described later in Section~\ref{dollaref}) is used to specify the
{\bf type} of a variable (i.e.\ what kind of
variable it is)\index{variable type}\index{type} and
give it a meaning typically
associated with a ``metavariable''\index{metavariable}\footnote{A metavariable
is a variable that ranges over the syntactical elements of the object language
being discussed; for example, one metavariable might represent a variable of
the object language and another metavariable might represent a formula in the
object language.} in ordinary mathematics; for example, a variable may be
specified to be a wff or well-formed formula (in logic), a set (in set
theory), or a non-negative integer (in number theory).

\subsection{The {\tt \$c} and {\tt \$v} Declaration Statements}
\index{{\tt \$c} statement}
\index{constant declaration}
\index{{\tt \$v} statement}
\index{variable declaration}

Constants are introduced or {\bf declared}\index{constant
declaration} with {\tt \$c}\index{{\tt \$c}
statement} statements, and variables are declared\index{variable
declaration} with {\tt \$v}\index{{\tt
\$v} statement} statements.  A {\bf simple} declaration\index{simple
declaration} statement introduces a
single constant or variable.  Its syntax is one of the following:
\begin{center}
  {\tt \$c} {\em math-symbol} {\tt \$.}\\
  {\tt \$v} {\em math-symbol} {\tt \$.}
\end{center}
The notation {\em math-symbol} means any math symbol token\index{token}.

Some examples of simple declaration statements are:
\begin{center}
  {\tt \$c + \$.}\\
  {\tt \$c -> \$.}\\
  {\tt \$c ( \$.}\\
  {\tt \$v x \$.}\\
  {\tt \$v y2 \$.}
\end{center}

The characters in a math symbol\index{math symbol} being declared are
irrelevant to Meta\-math; for example, we could declare a right parenthesis to
be a variable,
\begin{center}
  {\tt \$v ) \$.}\\
\end{center}
although this would be unconventional.

A {\bf compound} declaration\index{compound declaration} statement is a
shorthand for declaring several symbols at once.  Its syntax is one of the
following:
\begin{center}
  {\tt \$c} {\em math-symbol}\ \,$\cdots$\ {\em math-symbol} {\tt \$.}\\
  {\tt \$v} {\em math-symbol}\ \,$\cdots$\ {\em math-symbol} {\tt \$.}
\end{center}\index{{\tt \$c} statement}
Here, the ellipsis (\ldots) means any number of {\em math-symbol}\,s.

An example of a compound declaration statement is:
\begin{center}
  {\tt \$v x y mu \$.}\\
\end{center}
This is equivalent to the three simple declaration statements
\begin{center}
  {\tt \$v x \$.}\\
  {\tt \$v y \$.}\\
  {\tt \$v mu \$.}\\
\end{center}
\index{{\tt \$v} statement}

There are certain rules on where in the database math symbols may be declared,
what sections of the database are aware of them (i.e.\ where they are
``active''), and when they may be declared more than once.  These will be
discussed in Section~\ref{scoping} and specifically on
p.~\pageref{redeclaration}.

\subsection{The {\tt \$d} Statement}\label{dollard}
\index{{\tt \$d} statement}

The {\tt \$d} statement is called a {\bf disjoint-variable restriction}.  The
syntax of the {\bf simple} version of this statement is \begin{center}
  {\tt \$d} {\em variable variable} {\tt \$.}
\end{center}
where each {\em variable} is a previously declared variable and the two {\em
variable}\,s are different.  (More specifically, each  {\em variable} must be
an {\bf active} variable\index{active math symbol}, which means there must be
a previous {\tt \$v} statement whose {\bf scope}\index{scope} includes the
{\tt \$d} statement.  These terms will be defined when we discuss scoping
statements in Section~\ref{scoping}.)

In ordinary mathematics, formulas may arise that are true if the variables in
them are distinct\index{distinct variables}, but become false when those
variables are made identical. For example, the formula in logic $\exists x\,x
\neq y$, which means ``for a given $y$, there exists an $x$ that is not equal
to $y$,'' is true in most mathematical theories (namely all non-trivial
theories\index{non-trivial theory}, i.e.\ those that describe more than one
individual, such as arithmetic).  However, if we substitute $y$ with $x$, we
obtain $\exists x\,x \neq x$, which is always false, as it means ``there
exists something that is not equal to itself.''\footnote{If you are a
logician, you will recognize this as the improper substitution\index{proper
substitution}\index{substitution!proper} of a free variable\index{free
variable} with a bound variable\index{bound variable}.  Metamath makes no
inherent distinction between free and bound variables; instead, you let
Metamath know what substitutions are permissible by using {\tt \$d} statements
in the right way in your axiom system.}\index{free vs.\ bound variable}  The
{\tt \$d} statement allows you to specify a restriction that forbids the
substitution of one variable with another.  In
this case, we would use the statement
\begin{center}
  {\tt \$d x y \$.}
\end{center}\index{{\tt \$d} statement}
to specify this restriction.

The order in which the variables appear in a {\tt \$d} statement is not
important.  We could also use
\begin{center}
  {\tt \$d y x \$.}
\end{center}

The {\tt \$d} statement is actually more general than this, as the
``disjoint''\index{disjoint variables} in its name suggests.  The full meaning
is that if any substitution is made to its two variables (during the
course of a proof that references a {\tt \$a} or {\tt \$p} statement
associated with the {\tt \$d}), the two expressions that result from the
substitution must have no variables in common.  In addition, each possible
pair of variables, one from each expression, must be in a {\tt \$d} statement
associated with the statement being proved.  (This requirement forces the
statement being proved to ``inherit'' the original disjoint variable
restriction.)

For example, suppose {\tt u} is a variable.  If the restriction
\begin{center}
  {\tt \$d A B \$.}
\end{center}
has been specified for a theorem referenced in a
proof, we may not substitute {\tt A} with \mbox{\tt a + u} and
{\tt B} with \mbox{\tt b + u} because these two symbol sequences have the
variable {\tt u} in common.  Furthermore, if {\tt a} and {\tt b} are
variables, we may not substitute {\tt A} with {\tt a} and {\tt B} with {\tt b}
unless we have also specified {\tt \$d a b} for the theorem being proved; in
other words, the {\tt \$d} property associated with a pair of variables must
be effectively preserved after substitution.

The {\tt \$d}\index{{\tt \$d} statement} statement does {\em not} mean ``the
two variables may not be substituted with the same thing,'' as you might think
at first.  For example, substituting each of {\tt A} and {\tt B} in the above
example with identical symbol sequences consisting only of constants does not
cause a disjoint variable conflict, because two symbol sequences have no
variables in common (since they have no variables, period).  Similarly, a
conflict will not occur by substituting the two variables in a {\tt \$d}
statement with the empty symbol sequence\index{empty substitution}.

The {\tt \$d} statement does not have a direct counterpart in ordinary
mathematics, partly because the variables\index{variable} of Metamath are not
really the same as the variables\index{variable!in ordinary mathematics} of
ordinary mathematics but rather are metavariables\index{metavariable} ranging
over them (as well as over other kinds of symbols and groups of symbols).
Depending on the situation, we may informally interpret the {\tt \$d} statement
in different ways.  Suppose, for example, that {\tt x} and {\tt y} are
variables ranging over numbers (more precisely, that {\tt x} and {\tt y} are
metavariables ranging over variables that range over numbers), and that {\tt
ph} ($\varphi$) and {\tt ps} ($\psi$) are variables (more precisely,
metavariables) ranging over formulas.  We can make the following
interpretations that correspond to the informal language of ordinary
mathematics:
\begin{quote} \begin{tabbing}
{\tt \$d x y \$.} means ``assume $x$ and $y$ are
distinct variables.''\\
{\tt \$d x ph \$.} means ``assume $x$ does not
occur in $\varphi$.''\\
{\tt \$d ph ps \$.} \=means ``assume $\varphi$ and
$\psi$ have no variables\\ \>in common.''
\end{tabbing}
\end{quote}\index{{\tt \$d} statement}

\subsubsection{Compound {\tt \$d} Statements}

The {\bf compound} version of the {\tt \$d} statement is a shorthand for
specifying several variables whose substitutions must be pairwise disjoint.
Its syntax is:
\begin{center}
  {\tt \$d} {\em variable}\ \,$\cdots$\ {\em variable} {\tt \$.}
\end{center}\index{{\tt \$d} statement}
Here, {\em variable} represents the token of a previously declared
variable (specifically, an active variable) and all {\em variable}\,s are
different.  The compound {\tt \$d}
statements is internally broken up by Metamath into one simple {\tt \$d}
statement for each possible pair of variables in the original {\tt \$d}
statement.  For example, \begin{center}
  {\tt \$d w x y z \$.}
\end{center}
is equivalent to
\begin{center}
  {\tt \$d w x \$.}\\
  {\tt \$d w y \$.}\\
  {\tt \$d w z \$.}\\
  {\tt \$d x y \$.}\\
  {\tt \$d x z \$.}\\
  {\tt \$d y z \$.}
\end{center}

Two or more simple {\tt \$d} statements specifying the same variable pair are
internally combined into a single {\tt \$d} statement.  Thus the set of three
statements
\begin{center}
  {\tt \$d x y \$.}
  {\tt \$d x y \$.}
  {\tt \$d y x \$.}
\end{center}
is equivalent to
\begin{center}
  {\tt \$d x y \$.}
\end{center}

Similarly, compound {\tt \$d} statements, after being internally broken up,
internally have their common variable pairs combined.  For example the
set of statements
\begin{center}
  {\tt \$d x y A \$.}
  {\tt \$d x y B \$.}
\end{center}
is equivalent to
\begin{center}
  {\tt \$d x y \$.}
  {\tt \$d x A \$.}
  {\tt \$d y A \$.}
  {\tt \$d x y \$.}
  {\tt \$d x B \$.}
  {\tt \$d y B \$.}
\end{center}
which is equivalent to
\begin{center}
  {\tt \$d x y \$.}
  {\tt \$d x A \$.}
  {\tt \$d y A \$.}
  {\tt \$d x B \$.}
  {\tt \$d y B \$.}
\end{center}

Metamath\index{Metamath} automatically verifies that all {\tt \$d}
restrictions are met whenever it verifies proofs.  {\tt \$d} statements are
never referenced directly in proofs (this is why they do not have
labels\index{label}), but Metamath is always aware of which ones must be
satisfied (i.e.\ are active) and will notify you with an error message if any
violation occurs.

To illustrate how Metamath detects a missing {\tt \$d}
statement, we will look at the following example from the
{\tt set.mm} database.

\begin{verbatim}
$d x z $.  $d y z $.
$( Theorem to add distinct quantifier to atomic formula. $)
ax17eq $p |- ( x = y -> A. z x = y ) $=...
\end{verbatim}

This statement has the obvious requirement that $z$ must be
distinct\index{distinct variables} from $x$ in theorem {\tt ax17eq} that
states $x=y \rightarrow \forall z \, x=y$ (well, obvious if you're a logician,
for otherwise we could conclude  $x=y \rightarrow \forall x \, x=y$, which is
false when free variables $x$ and $y$ are equal.).

Let's look at what happens if we edit the database to comment out this
requirement.

\begin{verbatim}
$( $d x z $. $) $d y z $.
$( Theorem to add distinct quantifier to atomic formula. $)
ax17eq $p |- ( x = y -> A. z x = y ) $=...
\end{verbatim}

When it tries to verify the proof, Metamath will tell you that {\tt x} and
{\tt z} must be disjoint, because one of its steps references an axiom or
theorem that has this requirement.

\begin{verbatim}
MM> verify proof ax17eq
ax17eq ?Error at statement 1918, label "ax17eq", type "$p":
      vz wal wi vx vy vz ax-12 vx vy weq vz vx ax-16 vx vy
                                               ^^^^^
There is a disjoint variable ($d) violation at proof step 29.
Assertion "ax-16" requires that variables "x" and "y" be
disjoint.  But "x" was substituted with "z" and "y" was
substituted with "x".  The assertion being proved, "ax17eq",
does not require that variables "z" and "x" be disjoint.
\end{verbatim}

We can see the substitutions into {\tt ax-16} with the following command.

\begin{verbatim}
MM> show proof ax17eq / detailed_step 29
Proof step 29:  pm2.61dd.2=ax-16 $a |- ( A. z z = x -> ( x =
  y -> A. z x = y ) )
This step assigns source "ax-16" ($a) to target "pm2.61dd.2"
($e).  The source assertion requires the hypotheses "wph"
($f, step 26), "vx" ($f, step 27), and "vy" ($f, step 28).
The parent assertion of the target hypothesis is "pm2.61dd"
($p, step 36).
The source assertion before substitution was:
    ax-16 $a |- ( A. x x = y -> ( ph -> A. x ph ) )
The following substitutions were made to the source
assertion:
    Variable  Substituted with
     x         z
     y         x
     ph        x = y
The target hypothesis before substitution was:
    pm2.61dd.2 $e |- ( ph -> ch )
The following substitutions were made to the target
hypothesis:
    Variable  Substituted with
     ph        A. z z = x
     ch        ( x = y -> A. z x = y )
\end{verbatim}

The disjoint variable restrictions of {\tt ax-16} can be seen from the
{\tt show statement} command.  The line that begins ``{\tt Its mandatory
dis\-joint var\-i\-able pairs are:}\ldots'' lists any {\tt \$d} variable
pairs in brackets.

\begin{verbatim}
MM> show statement ax-16
Statement 2030 is located on line 5262 of the file "set.mm".
"Axiom of Distinct Variables.
The only axiom of predicate calculus requiring the $d
statement."
  ax-16 $a |- ( A. x x = y -> ( ph -> A. x ph ) ) $.
Its mandatory hypotheses in RPN order are:
  wph $f wff ph $.
  vx $f var x $.
  vy $f var y $.
Its mandatory disjoint variable pairs are:  <x,y>
The statement and its hypotheses require the variables:  x y
      ph
The variables it contains are:  x y ph
\end{verbatim}

Since Metamath will always detect when {\tt \$d}\index{{\tt \$d} statement}
statements are needed for a proof, you don't have to worry too much about
forgetting to put one in; it can always be added if you see the error message
above.  If you put in unnecessary {\tt \$d} statements, the worse that will
happen is that your theorem might not be as general as it could be, and this
may limit its use later on.

On the other hand, when you introduce axioms ({\tt \$a}\index{{\tt \$a}
statement} statements), you must be very careful to properly specify the
necessary associated {\tt \$d} statements since Metamath has no way of knowing
whether your axioms are correct.  For example, Metamath would have no idea
that {\tt ax-16}, which we are telling it is an axiom of logic, would lead to
contradictions if we omitted its associated {\tt \$d} statement.

{\footnotesize\begin{quotation}\label{nodd}
{\em Comment.} You may wonder if it is possible to develop standard
mathematics in the Metamath language without the {\tt \$d}\index{{\tt \$d}
statement} statement, since it seems like a nuisance that complicates proof
verification. The {\tt \$d} statement is not needed in certain subsets of
mathematics such as propositional calculus.  However, dummy
variables\index{dummy variable!eliminating} and their associated {\tt \$d}
statements are impossible to avoid in proofs in standard first-order logic as
well as in the variant used in {\tt set.mm}.  In fact, there is no upper bound to
the number of dummy variables that might be needed in a proof of a theorem of
first-order logic containing 3 or more variables, as shown by H.\
Andr\'{e}ka\index{Andr{\'{e}}ka, H.} \cite{Nemeti}.  A first-order system that
avoids them entirely is given in \cite{Megill}\index{Megill, Norman}; the
trick there is simply to embed harmlessly the necessary dummy variables into a
theorem being proved so that they aren't ``dummy'' anymore, then interpret the
resulting longer theorem so as to ignore the embedded dummy variables.  If
this interests you, the system in {\tt set.mm} obtained from {\tt ax-1}
through {\tt ax-15} in {\tt set.mm}, and deleting {\tt ax-16} and {\tt ax-17},
requires no {\tt \$d} statements but is logically complete in the sense
described in \cite{Megill}.  This means it can prove any theorem of
first-order logic as long as we add to the theorem an antecedent that embeds
dummy and any other variables that must be distinct.  In a similar fashion,
axioms for set theory can be devised that do not require distinct variables
(contact me if interested).  Together, these in principle allow all of
mathematics to be developed under Metamath without a {\tt \$d} statement,
although the length of the resulting theorems will grow as more and
more dummy variables become required in their proofs.
\end{quotation}}

\subsection{The {\tt \$f}
and {\tt \$e} Statements}\label{dollaref}
\index{{\tt \$e} statement}
\index{{\tt \$f} statement}
\index{floating hypothesis}
\index{essential hypothesis}
\index{variable-type hypothesis}
\index{logical hypothesis}
\index{hypothesis}

Metamath has two kinds of hypo\-theses, the {\tt \$f}\index{{\tt \$f}
statement} or {\bf variable-type} hypothesis and the {\tt \$e} or {\bf logical}
hypo\-the\-sis.\index{{\tt \$d} statement}\footnote{Strictly speaking, the
{\tt \$d} statement is also a hypothesis, but it is never directly referenced
in a proof, so we call it a restriction rather than a hypothesis to lessen
confusion.  The checking for violations of {\tt \$d} restrictions is automatic
and built into Metamath's proof-checking algorithm.} The letters {\tt f} and
{\tt e} stand for ``floating''\index{floating hypothesis} (roughly meaning
used only if relevant) and ``essential''\index{essential hypothesis} (meaning
always used) respectively, for reasons that will become apparent
when we discuss frames in
Section~\ref{frames} and scoping in Section~\ref{scoping}. The syntax of these
are as follows:
\begin{center}
  {\em label} {\tt \$f} {\em constant} {\em variable} {\tt \$.}\\
  {\em label} {\tt \$e} {\em constant}
      {\em math-symbol}\ \,$\cdots$\ {\em math-symbol} {\tt \$.}\\
\end{center}
\index{{\tt \$e} statement}
\index{{\tt \$f} statement}
A hypothesis must have a {\em label}\index{label}.  The expression in a
{\tt \$e} hypothesis consists of a constant math symbol following by a sequence
of zero or more math symbols. Each math symbol (including {\em constant}
and {\em variable}) must be a previously declared constant or variable.  (In
addition, each math symbol must be active, which will be covered when we
discuss scoping statements in Section~\ref{scoping}.)  You use a {\tt \$f}
hypothesis to specify the
nature or {\bf type}\index{variable type}\index{type} of a variable (such as ``let $x$ be an
integer'') and use a {\tt \$e} hypothesis to express a logical truth (such as
``assume $x$ is prime'') that must be established in order for an assertion
requiring it to also be true.

A variable must have its type specified in a {\tt \$f} statement before
it may be used in a {\tt \$d}, {\tt \$e}, {\tt \$a}, or {\tt \$p}
statement.  There may be only one (active) {\tt \$f} statement for a
given variable.  (``Active'' is defined in Section~\ref{scoping}.)

In ordinary mathematics, theorems\index{theorem} are often expressed in the
form ``Assume $P$; then $Q$,'' where $Q$ is a statement that you can derive
if you start with statement $P$.\index{free variable}\footnote{A stronger
version of a theorem like this would be the {\em single} formula $P\rightarrow
Q$ ($P$ implies $Q$) from which the weaker version above follows by the rule
of modus ponens in logic.  We are not discussing this stronger form here.  In
the weaker form, we are saying only that if we can {\em prove} $P$, then we can
{\em prove} $Q$.  In a logician's language, if $x$ is the only free variable
in $P$ and $Q$, the stronger form is equivalent to $\forall x ( P \rightarrow
Q)$ (for all $x$, $P$ implies $Q$), whereas the weaker form is equivalent to
$\forall x P \rightarrow \forall x Q$. The stronger form implies the weaker,
but not vice-versa.  To be precise, the weaker form of the theorem is more
properly called an ``inference'' rather than a theorem.}\index{inference}
In the
Metamath\index{Metamath} language, you would express mathematical statement
$P$ as a hypothesis (a {\tt \$e} Metamath language statement in this case) and
statement $Q$ as a provable assertion (a {\tt \$p}\index{{\tt \$p} statement}
statement).

Some examples of hypotheses you might encounter in logic and set theory are
\begin{center}
  {\tt stmt1 \$f wff P \$.}\\
  {\tt stmt2 \$f var x \$.}\\
  {\tt stmt3 \$e |- ( P -> Q ) \$.}
\end{center}
\index{{\tt \$e} statement}
\index{{\tt \$f} statement}
Informally, these would be read, ``Let $P$ be a well-formed-formula,'' ``Let
$x$ be an (individual) variable,'' and ``Assume we have proved $P \rightarrow
Q$.''  The turnstile symbol \,$\vdash$\index{turnstile ({$\,\vdash$})} is
commonly used in logic texts to mean ``a proof exists for.''

To summarize:
\begin{itemize}
\item A {\tt \$f} hypothesis tells Metamath the type or kind of its variable.
It is analogous to a variable declaration in a computer language that
tells the compiler that a variable is an integer or a floating-point
number.
\item The {\tt \$e} hypothesis corresponds to what you would usually call a
``hypothesis'' in ordinary mathematics.
\end{itemize}

Before an assertion\index{assertion} ({\tt \$a} or {\tt \$p} statement) can be
referenced in a proof, all of its associated {\tt \$f} and {\tt \$e} hypotheses
(i.e.\ those {\tt \$e} hypotheses that are active) must be satisfied (i.e.
established by the proof).  The meaning of ``associated'' (which we will call
{\bf mandatory} in Section~\ref{frames}) will become clear when we discuss
scoping later.

\subsection{Assertions ({\tt \$a} and {\tt \$p} Statements)}
\index{{\tt \$a} statement}
\index{{\tt \$p} statement}\index{assertion}\index{axiomatic assertion}
\index{provable assertion}

There are two types of assertions, {\tt \$a}\index{{\tt \$a} statement}
statements ({\bf axiomatic assertions}) and {\tt \$p} statements ({\bf
provable assertions}).  Their syntax is as follows:
\begin{center}
  {\em label} {\tt \$a} {\em constant} {\em math-symbol} \ldots
         {\em math-symbol} {\tt \$.}\\
  {\em label} {\tt \$p} {\em constant} {\em math-symbol} \ldots
        {\em math-symbol} {\tt \$=} {\em proof} {\tt \$.}
\end{center}
\index{{\tt \$a} statement}
\index{{\tt \$p} statement}
\index{{\tt \$=} keyword}
An assertion always requires a {\em label}\index{label}. The expression in an
assertion consists of a constant following by a sequence of zero
or more math symbols.  Each math symbol, including {\em constant}, must be a
previously declared constant or variable.  (In addition, each math symbol
must be active, which will be covered when we discuss scoping statements in
Section~\ref{scoping}.)

A {\tt \$a} statement is usually a definition of syntax (for example, if $P$
and $Q$ are wffs then so is $(P\to Q)$), an axiom\index{axiom} of ordinary
mathematics (for example, $x=x$), or a definition\index{definition} of
ordinary mathematics (for example, $x\ne y$ means $\lnot x=y$). A {\tt \$p}
statement is a claim that a certain combination of math symbols follows from
previous assertions and is accompanied by a proof that demonstrates it.

Assertions can also be referenced in (later) proofs in order to derive new
assertions from them. The label of an assertion is used to refer to it in a
proof. Section~\ref{proof} will describe the proof in detail.

Assertions also provide the primary means for communicating the mathematical
results in the database to people.  Proofs (when conveniently displayed)
communicate to people how the results were arrived at.

\subsubsection{The {\tt \$a} Statement}
\index{{\tt \$a} statement}

Axiomatic assertions ({\tt \$a} statements) represent the starting points from
which other assertions ({\tt \$p}\index{{\tt \$p} statement} statements) are
derived.  Their most obvious use is for specifying ordinary mathematical
axioms\index{axiom}, but they are also used for two other purposes.

First, Metamath\index{Metamath} needs to know the syntax of symbol sequences
that constitute valid mathematical statements.  A Metamath proof must be
broken down into much more detail than ordinary mathematical proofs that you
may be used to thinking of (even the ``complete'' proofs of formal
logic\index{formal logic}).  This is one of the things that makes Metamath a
general-purpose language, independent of any system of logic or even syntax.
If you want to use a substitution instance of an assertion as a step in a
proof, you must first prove that the substitution is syntactically
correct (or if you prefer, you
must ``construct'' it), showing for example that the expression
you are substituting for a wff metavariable is a valid wff.  The {\tt
\$a}\index{{\tt \$a} statement} statement is used to specify those
combinations of symbols that are considered syntactically valid, such as the
legal forms of wffs.

Second, {\tt \$a} statements are used to specify what are ordinarily thought of
as definitions, i.e.\ new combinations of symbols that abbreviate other
combinations of symbols.  Metamath makes no distinction\index{axiom vs.\
definition} between axioms\index{axiom} and definitions\index{definition}.
Indeed, it has been argued that such distinction should not be made even in
ordinary mathematics; see Section~\ref{definitions}, which discusses the
philosophy of definitions.  Section~\ref{hierarchy} discusses some
technical requirements for definitions.  In {\tt set.mm} we adopt the
convention of prefixing axiom labels with {\tt ax-} and definition labels with
{\tt df-}\index{label}.

The results that can be derived with the Metamath language are only as good as
the {\tt \$a}\index{{\tt \$a} statement} statements used as their starting
point.  We cannot stress this too strongly.  For example, Metamath will
not prevent you from specifying $x\neq x$ as an axiom of logic.  It is
essential that you scrutinize all {\tt \$a} statements with great care.
Because they are a source of potential pitfalls, it is best not to add new
ones (usually new definitions) casually; rather you should carefully evaluate
each one's necessity and advantages.

Once you have in place all of the basic axioms\index{axiom} and
rules\index{rule} of a mathematical theory, the only {\tt \$a} statements that
you will be adding will be what are ordinarily called definitions.  In
principle, definitions should be in some sense eliminable from the language of
a theory according to some convention (usually involving logical equivalence
or equality).  The most common convention is that any formula that was
syntactically valid but not provable before the definition was introduced will
not become provable after the definition is introduced.  In an ideal world,
definitions should not be present at all if one is to have absolute confidence
in a mathematical result.  However, they are necessary to make
mathematics practical, for otherwise the resulting formulas would be
extremely long and incomprehensible.  Since the nature of definitions (in the
most general sense) does not permit them to automatically be verified as
``proper,''\index{proper definition}\index{definition!proper} the judgment of
the mathematician is required to ensure it.  (In {\tt set.mm} effort was made
to make almost all definitions directly eliminable and thus minimize the need
for such judgment.)

If you are not a mathematician, it may be best not to add or change any {\tt
\$a}\index{{\tt \$a} statement} statements but instead use the mathematical
language already provided in standard databases.  This way
Metamath will not allow you to make a mistake (i.e.\ prove a false result).


\subsection{Frames}\label{frames}

We now introduce the concept of a collection of related Metamath statements
called a frame.  Every assertion ({\tt \$a} or {\tt \$p} statement) in the database has
an associated frame.

A {\bf frame}\index{frame} is a sequence of {\tt \$d}, {\tt \$f}, and {\tt
\$e} statements (zero or more of each) followed by one {\tt \$a} or {\tt \$p}
statement, subject to certain conditions we will describe.  For simplicity we
will assume that all math symbol tokens used are declared at the beginning of
the database with {\tt \$c} and {\tt \$v} statements (which are not properly
part of a frame).  Also for simplicity we will assume there are only simple
{\tt \$d} statements (those with only two variables) and imagine any compound
{\tt \$d} statements (those with more than two variables) as broken up into
simple ones.

A frame groups together those hypotheses (and {\tt \$d} statements) relevant
to an assertion ({\tt \$a} or {\tt \$p} statement).  The statements in a frame
may or may not be physically adjacent in a database; we will cover
this in our discussion of scoping statements
in Section~\ref{scoping}.

A frame has the following properties:
\begin{enumerate}
  \item The set of variables contained in its {\tt \$f} statements must be
identical to the set of variables contained its {\tt \$e}, {\tt \$a}, and/or
{\tt \$p} statements.  In other words, each variable in a {\tt \$e}, {\tt
\$a}, or {\tt \$p} statement must have an associated ``variable type'' defined
for it in a {\tt \$f} statement.
  \item No two {\tt \$f} statements may contain the same variable.
  \item Each of the two variables in any {\tt \$d} statement must occur in a
{\tt \$f} statement.
  \item Any {\tt \$f} statement
must occur before a {\tt \$e} or {\tt \$d} statement in which its variable
occurs.
\end{enumerate}

The first property determines the set of variables occurring in a frame.
These are the {\bf mandatory
variables}\index{mandatory variable} of the frame.  The second property
tells us there must be only one type specified for a variable.  The
third property determines which {\tt \$d} statements belong to the
frame.  The last property is not a theoretical requirement but it
makes parsing of the database easier.

For our examples, we assume our database has the following declarations:

\begin{verbatim}
        $v P Q R $.
        $c -> ( ) |- wff $.
\end{verbatim}

The following sequence of statements, describing the modus ponens inference
rule, is an example of a frame:

\begin{verbatim}
        wp  $f wff P $.
        wq  $f wff Q $.
        maj $e |- ( P -> Q ) $.
        min $e |- P $.
        mp  $a |- Q $.
\end{verbatim}

The following sequence of statements is not a frame because {\tt R} does not
occur in the {\tt \$e}'s or the {\tt \$a}:

\begin{verbatim}
        wp  $f wff P $.
        wq  $f wff Q $.
        wr  $f wff R $.
        maj $e |- ( P -> Q ) $.
        min $e |- P $.
        mp  $a |- Q $.
\end{verbatim}

The following sequence of statements is not a frame because {\tt Q} does not
occur in a {\tt \$f}:

\begin{verbatim}
        wp  $f wff P $.
        maj $e |- ( P -> Q ) $.
        min $e |- P $.
        mp  $a |- Q $.
\end{verbatim}

The following sequence of statements is not a frame because the {\tt \$a} statement is
not the last one:

\begin{verbatim}
        wp  $f wff P $.
        wq  $f wff Q $.
        maj $e |- ( P -> Q ) $.
        mp  $a |- Q $.
        min $e |- P $.
\end{verbatim}

Associated with a frame is a sequence of {\bf mandatory
hypotheses}\index{mandatory hypothesis}. This is simply the set of all {\tt
\$f} and {\tt \$e} statements in the frame, in the order they appear.  A frame
can be referenced in a later proof using the label of the {\tt \$a} or {\tt
\$p} assertion statement, and the proof makes an assignment to each mandatory
hypothesis in the order in which it appears.  This means the order of the
hypotheses, once chosen, must not be changed so as not to affect later proofs
referencing the frame's assertion statement. (The Metamath proof verifier will,
of course, flag an error if a proof becomes incorrect by doing this.) Since
proofs make use of ``Reverse Polish notation,'' described in
Section~\ref{proof}, we call this order the {\bf RPN order}\index{RPN order} of
the hypotheses.

Note that {\tt \$d} statements are not part of the set of mandatory
hypotheses, and their order doesn't matter (as long as they satisfy the fourth
property for a frame described above).  The {\tt \$d} statements specify
restrictions on variables that must be satisfied (and are checked by the proof
verifier) when expressions are substituted for them in a proof, and the {\tt
\$d} statements themselves are never referenced directly in a proof.

A frame with a {\tt \$p} (provable) statement requires a proof as part of the
{\tt \$p} statement.  Sometimes in a proof we want to make use of temporary or
dummy variables\index{dummy variable} that do not occur in the {\tt \$p}
statement or its mandatory hypotheses.  To accommodate this we define an {\bf
extended frame}\index{extended frame} as a frame together with zero or more
{\tt \$d} and {\tt \$f} statements that reference variables not among the
mandatory variables of the frame.  Any new variables referenced are called the
{\bf optional variables}\index{optional variable} of the extended frame. If a
{\tt \$f} statement references an optional variable it is called an {\bf
optional hypothesis}\index{optional hypothesis}, and if one or both of the
variables in a {\tt \$d} statement are optional variables it is called an {\bf
optional disjoint-variable restriction}\index{optional disjoint-variable
restriction}.  Properties 2, 3, and 4 for a frame also apply to an extended
frame.

The concept of optional variables is not meaningful for frames with {\tt \$a}
statements, since those statements have no proofs that might make use of them.
There is no restriction on including optional hypotheses in the extended frame
for a {\tt \$a} statement, but they serve no purpose.

The following set of statements is an example of an extended frame, which
contains an optional variable {\tt R} and an optional hypothesis {\tt wr}.  In
this example, we suppose the rule of modus ponens is not an axiom but is
derived as a theorem from earlier statements (we omit its presumed proof).
Variable {\tt R} may be used in its proof if desired (although this would
probably have no advantage in propositional calculus).  Note that the sequence
of mandatory hypotheses in RPN order is still {\tt wp}, {\tt wq}, {\tt maj},
{\tt min} (i.e.\ {\tt wr} is omitted), and this sequence is still assumed
whenever assertion {\tt mp} is referenced in a subsequent proof.

\begin{verbatim}
        wp  $f wff P $.
        wq  $f wff Q $.
        wr  $f wff R $.
        maj $e |- ( P -> Q ) $.
        min $e |- P $.
        mp  $p |- Q $= ... $.
\end{verbatim}

Every frame is an extended frame, but not every extended frame is a frame, as
this example shows.  The underlying frame for an extended frame is
obtained by simply removing all statements containing optional variables.
Any proof referencing an assertion will ignore any extensions to its
frame, which means we may add or delete optional hypotheses at will without
affecting subsequent proofs.

The conceptually simplest way of organizing a Metamath database is as a
sequence of extended frames.  The scoping statements {\tt \$\char`\{}\index{{\tt
\$\char`\{} and {\tt \$\char`\}} keywords} and {\tt \$\char`\}} can be used to delimit the start
and end of a frame, leading to the following possible structure for a database.
\label{framelist}

\vskip 2ex
\setbox\startprefix=\hbox{\tt \ \ \ \ \ \ \ \ }
\setbox\contprefix=\hbox{}
\startm
\m{\mbox{({\tt \$v} {\em and} {\tt \$c}\,{\em statements})}}
\endm
\startm
\m{\mbox{{\tt \$\char`\{}}}
\endm
\startm
\m{\mbox{{\tt \ \ } {\em extended frame}}}
\endm
\startm
\m{\mbox{{\tt \$\char`\}}}}
\endm
\startm
\m{\mbox{{\tt \$\char`\{}}}
\endm
\startm
\m{\mbox{{\tt \ \ } {\em extended frame}}}
\endm
\startm
\m{\mbox{{\tt \$\char`\}}}}
\endm
\startm
\m{\mbox{{\tt \ \ \ \ \ \ \ \ \ }}\vdots}
\endm
\vskip 2ex

In practice, this structure is inconvenient because we have to repeat any {\tt
\$f}, {\tt \$e}, and {\tt \$d} statements over and over again rather than
stating them once for use by several assertions.  The scoping statements,
which we will discuss next, allow this to be done.  In principle, any Metamath
database can be converted to the above format, and the above format is the
most convenient to use when studying a Metamath database as a formal system
(Appendix \ref{formalspec}).  In fact, Metamath internally converts the
database to the above format.  The command {\tt show statement} in the
Metamath program will show you the contents of the frame for any {\tt \$a} or
{\tt \$p} statement, as well as its extension in the case of a {\tt \$p}
statement.

%c%(provided that all ``local'' variables and constants with limited scope have
%c%unique names),

During our discussion of scoping statements, it may be helpful to
think in terms of the equivalent sequence of frames that will result when
the database is parsed.  Scoping (other than the limited
use above to delimit frames) is not a theoretical requirement for
Metamath but makes it more convenient.


\subsection{Scoping Statements ({\tt \$\{} and {\tt \$\}})}\label{scoping}
\index{{\tt \$\char`\{} and {\tt \$\char`\}} keywords}\index{scoping statement}

%c%Some Metamath statements may be needed only temporarily to
%c%serve a specific purpose, and after we're done with them we would like to
%c%disregard or ignore them.  For example, when we're finished using a variable,
%c%we might want to
%c%we might want to free up the token\index{token} used to name it so that the
%c%token can be used for other purposes later on, such as a different kind of
%c%variable or even a constant.  In the terminology of computer programming, we
%c%might want to let some symbol declarations be ``local'' rather than ``global.''
%c%\index{local symbol}\index{global symbol}

The {\bf scoping} statements, {\tt \$\char`\{} ({\bf start of block}) and {\tt \$\char`\}}
({\bf end of block})\index{block}, provide a means for controlling the portion
of a database over which certain statement types are recognized.  The
syntax of a scoping statement is very simple; it just consists of the
statement's keyword:
\begin{center}
{\tt \$\char`\{}\\
{\tt \$\char`\}}
\end{center}
\index{{\tt \$\char`\{} and {\tt \$\char`\}} keywords}

For example, consider the following database where we have stripped out
all tokens except the scoping statement keywords.  For the purpose of the
discussion, we have added subscripts to the scoping statements; these subscripts
do not appear in the actual database.
\[
 \mbox{\tt \ \$\char`\{}_1
 \mbox{\tt \ \$\char`\{}_2
 \mbox{\tt \ \$\char`\}}_2
 \mbox{\tt \ \$\char`\{}_3
 \mbox{\tt \ \$\char`\{}_4
 \mbox{\tt \ \$\char`\}}_4
 \mbox{\tt \ \$\char`\}}_3
 \mbox{\tt \ \$\char`\}}_1
\]
Each {\tt \$\char`\{} statement in this example is said to be {\bf matched} with the
{\tt \$\char`\}} statement that has the same subscript.  Each pair of matched
scoping statements defines a region of the database called a {\bf
block}.\index{block}  Blocks can be {\bf nested}\index{nested block} inside of
other blocks; in the example, the block defined by $\mbox{\tt \$\char`\{}_4$ and
$\mbox{\tt \$\char`\}}_4$ is nested inside the block defined by $\mbox{\tt \$\char`\{}_3$
and $\mbox{\tt \$\char`\}}_3$ as well as inside the block defined by $\mbox{\tt
\$\char`\{}_1$ and $\mbox{\tt \$\char`\}}_1$.  In general, a block may be empty, it may
contain only non-scoping statements,\footnote{Those statements other than {\tt
\$\char`\{} and {\tt \$\char`\}}.}\index{non-scoping statement} or it may contain any
mixture of other blocks and non-scoping statements. (This is called a
``recursive'' definition\index{recursive definition} of a block.)

Associated with each block is a number called its {\bf nesting
level}\index{nesting level} that indicates how deeply the block is nested.
The nesting levels of the blocks in our example are as follows:
\[
  \underbrace{
    \mbox{\tt \ }
    \underbrace{
     \mbox{\tt \$\char`\{\ }
     \underbrace{
       \mbox{\tt \$\char`\{\ }
       \mbox{\tt \$\char`\}}
     }_{2}
     \mbox{\tt \ }
     \underbrace{
       \mbox{\tt \$\char`\{\ }
       \underbrace{
         \mbox{\tt \$\char`\{\ }
         \mbox{\tt \$\char`\}}
       }_{3}
       \mbox{\tt \ \$\char`\}}
     }_{2}
     \mbox{\tt \ \$\char`\}}
   }_{1}
   \mbox{\tt \ }
 }_{0}
\]
\index{{\tt \$\char`\{} and {\tt \$\char`\}} keywords}
The entire database is considered to be one big block (the {\bf outermost}
block) with a nesting level of 0.  The outermost block is {\em not} bracketed
by scoping statements.\footnote{The language was designed this way so that
several source files can be joined together more easily.}\index{outermost
block}

All non-scoping Metamath statements become recognized or {\bf
active}\index{active statement} at the place where they appear.\footnote{To
keep things slightly simpler, we do not bother to define the concept of
``active'' for the scoping statements.}  Certain of these statement types
become inactive at the end of the block in which they appear; these statement
types are:
\begin{center}
  {\tt \$c}, {\tt \$v}, {\tt \$d}, {\tt \$e}, and {\tt \$f}.
%  {\tt \$v}, {\tt \$f}, {\tt \$e}, and {\tt \$d}.
\end{center}
\index{{\tt \$c} statement}
\index{{\tt \$d} statement}
\index{{\tt \$e} statement}
\index{{\tt \$f} statement}
\index{{\tt \$v} statement}
The other statement types remain active forever (i.e.\ through the end of the
database); they are:
\begin{center}
  {\tt \$a} and {\tt \$p}.
%  {\tt \$c}, {\tt \$a}, and {\tt \$p}.
\end{center}
\index{{\tt \$a} statement}
\index{{\tt \$p} statement}
Any statement (of these 7 types) located in the outermost
block\index{outermost block} will remain active through the end of the
database and thus are effectively ``global'' statements.\index{global
statement}

All {\tt \$c} statements must be placed in the outermost block.  Since they are
therefore always global, they could be considered as belonging to both of the
above categories.

The {\bf scope}\index{scope} of a statement is the set of statements that
recognize it as active.

%c%The concept of ``active'' is also defined for math symbols\index{math
%c%symbol}.  Math symbols (constants\index{constant} and
%c%variables\index{variable}) become {\bf active}\index{active
%c%math symbol} in the {\tt \$c}\index{{\tt
%c%\$c} statement} and {\tt \$v}\index{{\tt \$v} statement} statements that
%c%declare them.  They become inactive when their declaration statements become
%c%inactive.

The concept of ``active'' is also defined for math symbols\index{math
symbol}.  Math symbols (constants\index{constant} and
variables\index{variable}) become {\bf active}\index{active
math symbol} in the {\tt \$c}\index{{\tt
\$c} statement} and {\tt \$v}\index{{\tt \$v} statement} statements that
declare them.  A variable becomes inactive when its declaration statement
becomes
inactive.  Because all {\tt \$c} statements must be in the outermost
block, a constant will never become inactive after it is declared.

\subsubsection{Redeclaration of Math Symbols}
\index{redeclaration of symbols}\label{redeclaration}

%c%A math symbol may not be declared a second time while it is active, but it may
%c%be declared again after it becomes inactive.

A variable may not be declared a second time while it is active, but it may be
declared again after it becomes inactive.  This provides a convenient way to
introduce ``local'' variables,\index{local variable} i.e.\ temporary variables
for use in the frame of an assertion or in a proof without keeping them around
forever.  A previously declared variable may not be redeclared as a constant.

A constant may not be redeclared.  And, as mentioned above, constants must be
declared in the outermost block.

The reason variables may have limited scope but not constants is that an
assertion ({\tt \$a} or {\tt \$p} statement) remains available for use in
proofs through the end of the database.  Variables in an assertion's frame may
be substituted with whatever is needed in a proof step that references the
assertion, whereas constants remain fixed and may not be substituted with
anything.  The particular token used for a variable in an assertion's frame is
irrelevant when the assertion is referenced in a proof, and it doesn't matter
if that token is not available outside of the referenced assertion's frame.
Constants, however, must be globally fixed.

In the present version of the Metamath language, there is no theoretical
benefit for the feature allowing variables to be active for limited scopes
rather than global. It is just a convenience that allows them, for example, to
be locally grouped together with their corresponding {\tt \$f} variable-type
declarations.\footnote{A future version\label{redeclarationf} of the Metamath
language may extend the language to include true local variables as well as
local constants.  I have not decided upon the best way to do this or even if
it should be done at all; the main issue is whether the benefits offset
greater confusion in learning the language.  In any case, the rules for
the present language were chosen to let existing databases be compatible with
any future language extensions.}

%c%If you declare a math symbol more than once, internally Metamath considers it a
%c%new distinct symbol, even though it has the same name.  If you are unaware of
%c%this, you may find that what you think are correct proofs are incorrectly
%c%rejected as invalid, because Metamath may tell you that a constant you
%c%previously declared does not match a newly declared math symbol with the same
%c%name.  For details on this subtle point, see the Comment on
%c%p.~\pageref{spec4comment}.  This is done purposely to allow temporary
%c%constants to be introduced while developing a subtheory, then allow their math
%c%symbol tokens to be reused later on; in general they will not refer to the
%c%same thing.  In practice, you would not ordinarily reuse the names of
%c%constants because it would tend to be confusing to the reader.  The reuse of
%c%names of variables, on the other hand, is something that is often useful to do
%c%(for example it is done frequently in {\tt set.mm}).  Since variables in an
%c%assertion referenced in a proof can be substituted as needed to achieve a
%c%symbol match, this is not an issue.

% (This section covers a somewhat advanced topic you may want to skip
% at first reading.)
%
% Under certain circumstances, math symbol\index{math symbol}
% tokens\index{token} may be redeclared (i.e.\ the token
% may appear in more than
% one {\tt \$c}\index{{\tt \$c} statement} or {\tt \$v}\index{{\tt \$v}
% statement} statement).  You might want to do this say, to make temporary use
% of a variable name without having to worry about its affect elsewhere,
% somewhat analogous to declaring a local variable in a standard computer
% language.  Understanding what goes on when math symbol tokens are redeclared
% is a little tricky to understand at first, since it requires that we
% distinguish the token itself from the math symbol that it names.  It will help
% if we first take a peek at the internal workings of the
% Metamath\index{Metamath} program.
%
% Metamath reserves a memory location for each occurrence of a
% token\index{token} in a declaration statement ({\tt \$c}\index{{\tt \$c}
% statement} or {\tt \$v}\index{{\tt \$v} statement}).  If a given token appears
% in more than one declaration statement, it will refer to more than one memory
% locations.  A math symbol\index{math symbol} may be thought of as being one of
% these memory locations rather than as the token itself.  Only one of the
% memory locations associated with a given token may be active at any one time.
% The math symbol (memory location) that gets looked up when the token appears
% in a non-declaration statement is the one that happens to be active at that
% time.
%
% We now look at the rules for the redeclaration\index{redeclaration of symbols}
% of math symbol tokens.
% \begin{itemize}
% \item A math symbol token may not be declared twice in the
% same block.\footnote{While there is no theoretical reason for disallowing
% this, it was decided in the design of Metamath that allowing it would offer no
% advantage and might cause confusion.}
% \item An inactive math symbol may always be
% redeclared.
% \item  An active math symbol may be redeclared in a different (i.e.\
% inner) block\index{block} from the one it became active in.
% \end{itemize}
%
% When a math symbol token is redeclared, it conceptually refers to a different
% math symbol, just as it would be if it were called a different name.  In
% addition, the original math symbol that it referred to, if it was active,
% temporarily becomes inactive.  At the end of the block in which the
% redeclaration occurred, the new math symbol\index{math symbol} becomes
% inactive and the original symbol becomes active again.  This concept is
% illustrated in the following example, where the symbol {\tt e} is
% ordinarily a constant (say Euler's constant, 2.71828...) but
% temporarily we want to use it as a ``local'' variable, say as a coefficient
% in the equation $a x^4 + b x^3 + c x^2 + d x + e$:
% \[
%   \mbox{\tt \$\char`\{\ \$c e \$.}
%   \underbrace{
%     \ \ldots\ %
%     \mbox{\tt \$\char`\{}\ \ldots\ %
%   }_{\mbox{\rm region A}}
%   \mbox{\tt \$v e \$.}
%   \underbrace{
%     \mbox{\ \ \ \ldots\ \ \ }
%   }_{\mbox{\rm region B}}
%   \mbox{\tt \$\char`\}}
%   \underbrace{
%     \mbox{\ \ \ \ldots\ \ \ }
%   }_{\mbox{\rm region C}}
%   \mbox{\tt \$\char`\}}
% \]
% \index{{\tt \$\char`\{} and {\tt \$\char`\}} keywords}
% In region A, the token {\tt e} refers to a constant.  It is redeclared as a
% variable in region B, and any reference to it in this region will refer to this
% variable.  In region C, the redeclaration becomes inactive, and the original
% declaration becomes active again.  In region C, the token {\tt x} refers to the
% original constant.
%
% As a practical matter, overuse of math symbol\index{math symbol}
% redeclarations\index{redeclaration of symbols} can be confusing (even though
% it is well-defined) and is best avoided when possible.  Here are some good
% general guidelines you can follow.  Usually, you should declare all
% constants\index{constant} in the outermost block\index{outermost block},
% especially if they are general-purpose (such as the token \verb$A.$, meaning
% $\forall$ or ``for all'').  This will make them ``globally'' active (although
% as in the example above local redeclarations will temporarily make them
% inactive.)  Most or all variables\index{variable}, on the other hand, could be
% declared in inner blocks, so that the token for them can be used later for a
% different type of variable or a constant.  (The names of the variables you
% choose are not used when you refer to an assertion\index{assertion} in a
% proof, whereas constants must match exactly.  A locally declared constant will
% not match a globally declared constant in a proof, even if they use the same
% token, because Metamath internally considers them to be different math
% symbols.)  To avoid confusion, you should generally avoid redeclaring active
% variables.  If you must redeclare them, do so at the beginning of a block.
% The temporary declaration of constants in inner blocks might be occasionally
% appropriate when you make use of a temporary definition to prove lemmas
% leading to a main result that does not make direct use of the definition.
% This way, you will not clutter up your database with a large number of
% seldom-used global constant symbols.  You might want to note that while
% inactive constants may not appear directly in an assertion (a {\tt
% \$a}\index{{\tt \$a} statement} or {\tt \$p}\index{{\tt \$p} statement}
% statement), they may be indirectly used in the proof of a {\tt \$p} statement
% so long as they do not appear in the final math symbol sequence constructed by
% the proof.  In the end, you will have to use your best judgment, taking into
% account standard mathematical usage of the symbols as well as consideration
% for the reader of your work.
%
% \subsubsection{Reuse of Labels}\index{reuse of labels}\index{label}
%
% The {\tt \$e}\index{{\tt \$e} statement}, {\tt \$f}\index{{\tt \$f}
% statement}, {\tt \$a}\index{{\tt \$a} statement}, and {\tt \$p}\index{{\tt
% \$p} statement} statement types require labels, which allow them to be
% referenced later inside of proofs.  A label is considered {\bf
% active}\index{active label} when the statement it is associated with is
% active.  The token\index{token} for a label may be reused
% (redeclared)\index{redeclaration of labels} provided that it is not being used
% for a currently active label.  (Unlike the tokens for math symbols, active
% label tokens may not be redeclared in an inner scope.)  Note that the labels
% of {\tt \$a} and {\tt \$p} statements can never be reused after these
% statements appear, because these statements remain active through the end of
% the database.
%
% You might find the reuse of labels a convenient way to have standard names for
% temporary hypotheses, such as {\tt h1}, {\tt h2}, etc.  This way you don't have
% to invent unique names for each of them, and in some cases it may be less
% confusing to the reader (although in other cases it might be more confusing, if
% the hypothesis is located far away from the assertion that uses
% it).\footnote{The current implementation requires that all labels, even
% inactive ones, be unique.}

\subsubsection{Frames Revisited}\index{frames and scoping statements}

Now that we have covered scoping, we will look at how an arbitrary Metamath
database can be converted to the simple sequence of extended frames described
on p.~\pageref{framelist}.  This is also how Metamath stores the database
internally when it reads in the database source.\label{frameconvert} The
method is simple.  First, we collect all constant and variable ({\tt \$c} and
{\tt \$v}) declarations in the database, ignoring duplicate declarations of
the same variable in different scopes.  We then put our collected {\tt \$c}
and {\tt \$v} declarations at the beginning of the database, so that their
scope is the entire database. Next, for each assertion in the database, we
determine its frame and extended frame.  The extended frame is simply the {\tt
\$f}, {\tt \$e}, and {\tt \$d} statements that are active.  The frame is the
extended frame with all optional hypotheses removed.

An equivalent way of saying this is that the extended frame of an assertion
is the collection of all {\tt \$f}, {\tt \$e}, and {\tt \$d} statements
whose scope includes the assertion, in the order they appear.

%c%, renaming any
%c%redeclared variables as needed so that all of them have unique names.  (The
%c%exact renaming convention is unimportant.  You might imagine renaming
%c%different declarations of math symbol {\tt a} as {\tt a\$1}, {\tt a\$2}, etc.\
%c%which would prevent any conflicts since {\tt \$} is not a legal character in a
%c%math symbol token.)

\section{The Anatomy of a Proof} \label{proof}
\index{proof!Metamath, description of}

Each provable assertion ({\tt \$p}\index{{\tt \$p} statement} statement) in a
database must include a {\bf proof}\index{proof}.  The proof is located
between the {\tt \$=}\index{{\tt \$=} keyword} and {\tt \$.}\ keywords in the
{\tt \$p} statement.

In the basic Metamath language\index{basic language}, a proof is a sequence of
statement labels.  This label sequence\index{label sequence} serves as a set
of instructions that the Metamath program uses to construct a series of math
symbol sequences. The construction must ultimately result in the math symbol
sequence contained between the {\tt \$p}\index{{\tt \$p} statement} and {\tt
\$=}\index{{\tt \$=} keyword} keywords of the {\tt \$p} statement. Otherwise,
the Metamath program will consider the proof incorrect, and it will notify you
with an appropriate error message when you ask it to verify the
proof.\footnote{To make the loading faster, the Metamath program does not
automatically verify proofs when you {\tt read} in a database unless you use
the {\tt /verify} qualifier.  After a database has been read in, you may use
the {\tt verify proof *} command to verify proofs.}\index{{\tt verify proof}
command}  Each label in a proof is said to {\bf reference}\index{label
reference} its corresponding statement.

Associated with any assertion\index{assertion} ({\tt \$p} or {\tt
\$a}\index{{\tt \$a} statement} statement) is a set of hypotheses ({\tt
\$f}\index{{\tt \$f} statement} or {\tt \$e}\index{{\tt \$e} statement}
statements) that are active with respect to that assertion.  Some are
mandatory and the others are optional.  You should review these concepts if
necessary.

Each label\index{label} in a proof must be either the label of a previous
assertion ({\tt \$a}\index{{\tt \$a} statement} or {\tt \$p}\index{{\tt \$p}
statement} statement) or the label of an active hypothesis ({\tt \$e} or {\tt
\$f}\index{{\tt \$f} statement} statement) of the {\tt \$p} statement
containing the proof.  Hypothesis labels may reference both the
mandatory\index{mandatory hypothesis} and the optional hypotheses of the {\tt
\$p} statement.

The label sequence in a proof specifies a construction in {\bf reverse Polish
notation}\index{reverse Polish notation (RPN)} (RPN).  You may be familiar
with RPN if you have used Hewlett-Packard or similar hand-held calculators.
In the calculator analogy, a hypothesis label\index{hypothesis label} is like
a number and an assertion label\index{assertion label} is like an operation.
On an RPN calculator, an operation takes one or more previous numbers in an
input sequence, performs a calculation on them, and replaces those numbers and
itself with the result of the calculation.  For example, the input sequence
$2,2,+$ on an RPN calculator results in $4$, and the input sequence
$1,2,2,+,+$ results in $1,4,+$ which results in $5$.

Understanding how RPN is processed involves the concept of a {\bf
stack}\index{stack}\index{RPN stack}, which can be thought of as a set of
temporary memory locations that hold intermediate results.  When Metamath
encounters a hypothesis label it places or {\bf pushes}\index{push} the math
symbol sequence of the hypothesis onto the stack.  When Metamath encounters an
assertion label, it associates the most recent stack entries with the {\em
mandatory} hypotheses\index{mandatory hypothesis} of the assertion, in the
order where the most recent stack entry is associated with the last mandatory
hypothesis of the assertion.  It then determines what
substitutions\index{substitution!variable}\index{variable substitution} have
to be made into the variables of the assertion's mandatory hypotheses to make
them identical to the associated stack entries.  It then makes those same
substitutions into the assertion itself.  Finally, Metamath removes or {\bf
pops}\index{pop} the matched hypotheses from the stack and pushes the
substituted assertion onto the stack.

For the purpose of matching the mandatory hypothesis to the most recent stack
entries, whether a hypothesis is a {\tt \$e} or {\tt \$f} statement is
irrelevant.  The only important thing is that a set of
substitutions\footnote{In the Metamath spec (Section~\ref{spec}), we use the
singular term ``substitution'' to refer to the set of substitutions we talk
about here.} exist that allow a match (and if they don't, the proof verifier
will let you know with an error message).  The Metamath language is specified
in such a way that if a set of substitutions exists, it will be unique.
Specifically, the requirement that each variable have a type specified for it
with a {\tt \$f} statement ensures the uniqueness.

We will illustrate this with an example.
Consider the following Metamath source file:
\begin{verbatim}
        $c ( ) -> wff $.
        $v p q r s $.
        wp $f wff p $.
        wq $f wff q $.
        wr $f wff r $.
        ws $f wff s $.
        w2 $a wff ( p -> q ) $.
        wnew $p wff ( s -> ( r -> p ) ) $= ws wr wp w2 w2 $.
\end{verbatim}
This Metamath source example shows the definition and ``proof'' (i.e.,
construction) of a well-formed formula (wff)\index{well-formed formula (wff)}
in propositional calculus.  (You may wish to type this example into a file to
experiment with the Metamath program.)  The first two statements declare
(introduce the names of) four constants and four variables.  The next four
statements specify the variable types, namely that
each variable is assumed to be a wff.  Statement {\tt w2} defines (postulates)
a way to produce a new wff, {\tt ( p -> q )}, from two given wffs {\tt p} and
{\tt q}. The mandatory hypotheses of {\tt w2} are {\tt wp} and {\tt wq}.
Statement {\tt wnew} claims that {\tt ( s -> ( r -> p ) )} is a wff given
three wffs {\tt s}, {\tt r}, and {\tt p}.  More precisely, {\tt wnew} claims
that the sequence of ten symbols {\tt wff ( s -> ( r -> p ) )} is provable from
previous assertions and the hypotheses of {\tt wnew}.  Metamath does not know
or care what a wff is, and as far as it is concerned {\tt wff} is just an
arbitrary constant symbol in a math symbol sequence.  The mandatory hypotheses
of {\tt wnew} are {\tt wp}, {\tt wr}, and {\tt ws}; {\tt wq} is an optional
hypothesis.  In our particular proof, the optional hypothesis is not
referenced, but in general, any combination of active (i.e.\ optional and
mandatory) hypotheses could be referenced.  The proof of statement {\tt wnew}
is the sequence of five labels starting with {\tt ws} (step~1) and ending with
{\tt w2} (step~5).

When Metamath verifies the proof, it scans the proof from left to right.  We
will examine what happens at each step of the proof.  The stack starts off
empty.  At step 1, Metamath looks up label {\tt ws} and determines that it is a
hypothesis, so it pushes the symbol sequence of statement {\tt ws} onto the
stack:

\begin{center}\begin{tabular}{|l|l|}\hline
{Stack location} & {Contents} \\ \hline \hline
1 & {\tt wff s} \\ \hline
\end{tabular}\end{center}

Metamath sees that the labels {\tt wr} and {\tt wp} in steps~2 and 3 are also
hypotheses, so it pushes them onto the stack.  After step~3, the stack looks
like
this:

\begin{center}\begin{tabular}{|l|l|}\hline
{Stack location} & {Contents} \\ \hline \hline
3 & {\tt wff p} \\ \hline
2 & {\tt wff r} \\ \hline
1 & {\tt wff s} \\ \hline
\end{tabular}\end{center}

At step 4, Metamath sees that label {\tt w2} is an assertion, so it must do
some processing.  First, it associates the mandatory hypotheses of {\tt w2},
which are {\tt wp} and {\tt wq}, with stack locations~2 and 3, {\em in that
order}. Metamath determines that the only possible way
to make hypothesis {\tt wp} match (become identical to) stack location~2 and
{\tt wq} match stack location 3 is to substitute variable {\tt p} with {\tt r}
and {\tt q} with {\tt p}.  Metamath makes these substitutions into {\tt w2} and
obtains the symbol sequence {\tt wff ( r -> p )}.  It removes the hypotheses
from stack locations~2 and 3, then places the result into stack location~2:

\begin{center}\begin{tabular}{|l|l|}\hline
{Stack location} & {Contents} \\ \hline \hline
2 & {\tt wff ( r -> p )} \\ \hline
1 & {\tt wff s} \\ \hline
\end{tabular}\end{center}

At step 5, Metamath sees that label {\tt w2} is an assertion, so it must again
do some processing.  First, it matches the mandatory hypotheses of {\tt w2},
which are {\tt wp} and {\tt wq}, to stack locations 1 and 2.
Metamath determines that the only possible way to make the
hypotheses match is to substitute variable {\tt p} with {\tt s} and {\tt q} with
{\tt ( r -> p )}.  Metamath makes these substitutions into {\tt w2} and obtains
the symbol
sequence {\tt wff ( s -> ( r -> p ) )}.  It removes stack
locations 1 and 2, then places the result into stack location~1:

\begin{center}\begin{tabular}{|l|l|}\hline
{Stack location} & {Contents} \\ \hline \hline
1 & {\tt wff ( s -> ( r -> p ) )} \\ \hline
\end{tabular}\end{center}

After Metamath finishes processing the proof, it checks to see that the
contents of stack location 1 is the same as the math symbol sequence in the
{\tt \$p}\index{{\tt \$p} statement} statement.  This is the case for our
proof of {\tt wnew}, so we have proved {\tt wnew} successfully.  If the result
differs, Metamath will notify you with an error message.  An error message
will also result if the stack contains more than one entry at the end of the
proof, or if the stack did not contain enough entries at any point in the
proof to match all of the mandatory hypotheses\index{mandatory hypothesis} of
an assertion.  Finally, Metamath will notify you with an error message if no
substitution is possible that will make a referenced assertion's hypothesis
match the
stack entries.  You may want to experiment with the different kinds of errors
that Metamath will detect by making some small changes in the proof of our
example.

Metamath's proof notation was designed primarily to express proofs in a
relatively compact manner, not for readability by humans.  Metamath can display
proofs in a number of different ways with the {\tt show proof}\index{{\tt show
proof} command} command.  The
{\tt /lemmon} qualifier displays it in a format that is easier to read when the
proofs are short, and you saw examples of its use in Chapter~\ref{using}.  For
longer proofs, it is useful to see the tree structure of the proof.  A tree
structure is displayed when the {\tt /lemmon} qualifier is omitted.  You will
probably find this display more convenient as you get used to it. The tree
display of the proof in our example looks like
this:\label{treeproof}\index{tree-style proof}\index{proof!tree-style}
\begin{verbatim}
        1     wp=ws    $f wff s
        2        wp=wr    $f wff r
        3        wq=wp    $f wff p
        4     wq=w2    $a wff ( r -> p )
        5  wnew=w2  $a wff ( s -> ( r -> p ) )
\end{verbatim}
The number to the left of each line is the step number.  Following it is a
{\bf hypothesis association}\index{hypothesis association}, consisting of two
labels\index{label} separated by {\tt =}.  To the left of the {\tt =} (except
in the last step) is the label of a hypothesis of an assertion referenced
later in the proof; here, steps 1 and 4 are the hypothesis associations for
the assertion {\tt w2} that is referenced in step 5.  A hypothesis association
is indented one level more than the assertion that uses it, so it is easy to
find the corresponding assertion by moving directly down until the indentation
level decreases to one less than where you started from.  To the right of each
{\tt =} is the proof step label for that proof step.  The statement keyword of
the proof step label is listed next, followed by the content of the top of the
stack (the most recent stack entry) as it exists after that proof step is
processed.  With a little practice, you should have no trouble reading proofs
displayed in this format.

Our simple example shows the syntax construction of a formula that might be
used as part of the construction of a ``real'' proof step that deduces
theorems from other theorems.  In standard mathematics, this kind of
construction is not considered a proper part of the proof at all, and it
certainly becomes rather boring after a while.  To filter out syntax
constructions in the proof display, the {\tt show proof}\index{{\tt show proof}
command} command has the qualifier {\tt /essential} which you will probably
use quite often in order to see just the ``real'' steps of
the proof.

When verifying a proof, Metamath will check that no mandatory {\tt
\$d}\index{{\tt \$d} statement}\index{mandatory {\tt \$d} statement} statement
of an assertion referenced in a proof is violated when
substitutions\index{substitution!variable}\index{variable substitution} are
made to the variables in the assertion.  For details see Section~\ref{spec4}
or \ref{dollard}.

\subsection{The Concept of Unification} \label{unify}

During the course of verifying a proof, when Metamath\index{Metamath}
encounters an assertion label\index{assertion label}, it associates the
mandatory hypotheses\index{mandatory hypothesis} of the assertion with the top
entries of the RPN stack\index{stack}\index{RPN stack}.  Metamath then
determines what substitutions\index{substitution!variable}\index{variable
substitution} it must make to the variables in the assertion's mandatory
hypotheses in order for these hypotheses to become identical to their
corresponding stack entries.  This process is called {\bf
unification}\index{unification}.  (We also informally use the term
``unification'' to refer to a set of substitutions that results from the
process, as in ``two unifications are possible.'')  After the substitutions
are made, the hypotheses are said the be {\bf unified}.

If no such substitutions are possible, Metamath will consider the proof
incorrect and notify you with an error message.  The syntax of the
Metamath language ensures that if a set of substitutions exists, it
will be unique.

The general algorithm for unification described in the literature is somewhat
complex.  However, in the case of Metamath it is trivial because of the
requirement that each variable have its type
specified with a {\tt \$f} hypothesis and that each {\tt
\$f} hypothesis have the restricted syntax of a constant followed by a
variable.  The constant in the {\tt \$f} hypothesis must match the first
symbol of the corresponding RPN stack entry (which will be also be a constant),
so only possible match for the variable in the {\tt \$f} hypothesis is the
sequence of symbols in the stack entry after the initial constant.

In the Proof Assistant\index{Proof Assistant}, a more general unification
algorithm is used.  While a proof is being developed, sometimes not enough
information is available to determine a unique unification.  In this case
Metamath will ask you to pick the correct one.\index{ambiguous
unification}\index{unification!ambiguous}

\section{Extensions to the Basic Metamath Language}\index{extended
language}

\subsection{Comments in the Metamath Language}\label{comments}

The commenting feature allows you to annotate the contents of
a database.  Just as with most
computer languages, comments are ignored for the purpose of interpreting the
contents of the database. Comments effectively act as
additional white space\index{white
space} between tokens
when a database is parsed.

A comment may be placed between any two tokens\index{token} in a source
file.

Comments have the following syntax:
\begin{center}
 {\tt \$(} {\em text} {\tt \$)}
\end{center}
\index{{\tt \$(} and {\tt \$)} auxiliary keywords}\index{comment}
Here, {\em text} is a string, possibly empty, of any characters in Metamath's
character set (p.~\pageref{spec1chars}), except that the character strings
{\tt \$(} and {\tt \$)} may not appear in {\em text}.  Thus nested comments
are not permitted:\footnote{Computer languages have differing standards for
nested comments, and rather than picking one it was felt simplest not to allow
them at all, at least in the current version of Metamath
(0.06)\index{Metamath!limitations of version 0.06}.}  Metamath will complain
if you give it
\begin{center}
 {\tt \$( This is a \$( nested \$) comment.\ \$)}
\end{center}

\subsubsection{Math Symbols and Labels Inside Comments}
\label{mathcomments}
\index{{\tt `} inside comments}
\index{{\tt \char`\~} inside comments}

Inside of comments, a string of tokens\index{token} enclosed in grave
accents\index{grave accent ({\tt `})} ({\tt `}) will be converted to  standard
mathematical symbols during \LaTeX\ output typesetting,\index{latex@{\LaTeX}}
according to the information in your {\tt latex.def} file, as described in
Appendix~\ref{ASCII}. The first {\tt `} causes the output processor to enter
{\bf math mode}\index{math mode} and the second one exits it. Two consecutive
grave accents {\tt ``} are treated as a single actual grave accent (both
inside and outside of math mode) and will not cause the output processor to
enter or exit math mode.

Outside of math mode, any token preceded by a tilde\index{tilde ({\tt
\char`\~})} (\verb/~/) will be formatted in {\tt typewriter} font, and the
tilde removed, to make them stand it from the rest of the text.  This
formatting will be applied from all characters after the tilde up to the first
white space\index{white space}.  This formatting mode is called {\bf label
mode}\index{label mode}.  If a literal tilde is desired (outside of math
mode), use two tildes in a row to represent it.

These commenting features have to do only with how the comments are typeset,
and have no effect on how Metamath verifies the database.  The improper use of
them may result in incorrectly typeset output, but no Metamath error messages
will result.

The Metamath program has two commands,\footnote{Not implemented in the current
version (0.06)\index{Metamath!limitations of version 0.06}.} {\tt substitute
symbol}\index{{\tt substitute symbol} command} and {\tt substitute
label}\index{{\tt substitute label} command}, that make token\index{token}
substitutions throughout a database. These commands will simultaneously make
the same substitutions to tokens located in comment text that is in the math
and label modes whenever there is a match.

\subsubsection{Math Symbols In Comments}\index{math symbol}\index{math mode}

The grave accent\index{grave accent ({\tt `})} {\tt `} tells
Metamath\index{Metamath} to switch a comment to math mode.  In this mode,
the characters following the {\tt `} are interpreted as a sequence of math
symbol tokens separated by white space\index{white space}.  The tokens are
looked up in the {\tt latex.def} file and if found, they will be replaced by
the standard mathematical symbols that they correspond to before being placed
in the typeset output file.  If not found, the symbol will be output as is and
a warning will be issued.  The tokens do not have to be active or even
declared in the database.

The comment will stay in math mode until a second {\tt `} is found or the end
of the comment is reached.  Here is an example of its use\index{Pierce's
axiom}:
\begin{center}
{\tt \$( Pierce's axiom, ` ( ( ph -> ps ) -> ph ) -> ph ` ,\\
         is not very intuitive. \$)}
\end{center}
becomes
\begin{center}
   {\tt \$(} Pierce's axiom, $((\varphi \rightarrow \psi)\rightarrow
\varphi)\rightarrow \varphi$, is not very intuitive. {\tt \$)}
\end{center}

Note that the math symbol tokens\index{token} must be surrounded by white
space\index{white space}.
%, since there is no context that allows ambiguity to be
%resolved, as is the case with math symbol sequences in some of the Metamath
%statements.
White space should also surround the {\tt `}
delimiters.

The math mode feature also gives you a quick and easy way to generate text
containing mathematical symbols, independently of the intended purpose of
Metamath.\index{Metamath!using as a math editor}  To do this, simply create
your text with grave accents surrounding your formulas, using the notation
described in Appendix~\ref{ASCII}. Surround the entire text with {\tt \$(} and
{\tt \$)}, making it one big comment.  You will also need to
add a dummy Metamath language statement; consult the {\tt help tex} command
for information on how to do this and how to create the
\LaTeX\index{latex@{\LaTeX}}\ output.  You will then probably want to edit the
resulting file with a text editor to fine tune it to your exact needs.

\subsubsection{Label References in Comments}\index{label mode}

Outside of math mode, a tilde\index{tilde ({\tt \char`\~})} \verb/~/ indicates
to Metamath's\index{Metamath} output processor that the token\index{token}
that follows (i.e.\ the characters up to the next white space\index{white
space}) represents a statement label.  Whether or not the token is an actual
statement label is not checked except during the {\tt substitute
label}\index{{\tt substitute label} command} command.\footnote{This command
has not yet been implemented in the current version of Metamath
(0.06)\index{Metamath!limitations of version 0.06}.}  The token does not have
to have the correct syntax for a label; no error messages will be produced,
although the {\tt substitute label} command will issue a
warning.  The only effect of the label
mode on the output is that typewriter font will be used for the tokens that
are placed in the word processor output file.  An advantage of using tilde
label references is that any label changes made with the {\tt substitute
label} command will automatically propagate to
comments.


\subsection{Including Other Files in a Metamath Source File} \label{include}
\index{{\tt \$[} and {\tt \$]} auxiliary keywords}

The keywords {\tt \$[} and {\tt \$]} specify a file to be
included\index{included file}\index{file inclusion} at that point in a
Metamath\index{Metamath} source file\index{source file}.  The syntax for
including a file is as follows:
\begin{center}
{\tt \$[} {\em file-name} {\tt \$]}
\end{center}

The {\em file-name} should be a single token\index{token} with the same syntax
as a math symbol (i.e., all 93 printable characters other than {\tt \$} are
allowed, subject to the file-naming limitations of your operating system).
Comments may appear between the {\tt \$[} and {\tt \$]} keywords.  Included
files may include other files, which may in turn include other files, and so
on.

For example, suppose you want to use the set theory database as the starting
point for your own theory.  The first line in your file could be \begin{center}
{\tt \$[ set.mm \$]} \end{center} All of the information (axioms, theorems,
etc.) in {\tt set.mm} and any files that {\em it} includes will become
available for you to reference in your file. This can help make your work more
modular. A drawback to including files is that if you change the name of a
symbol or the label of a statement, you must also remember to update any
references in any file that includes it.


The naming conventions for included files are the same as those of your
operating system.\footnote{On the Macintosh, a colon is used to separate disk
and folder names from your file name.  For example, {\em volume}{\tt :}{\em
file-name} refers to the root directory, {\em volume}{\tt :}{\em
folder-name}{\tt :}{\em file-name} refers to a folder in root, and {\em
volume}{\tt :}{\em folder-name}{\tt :}\ldots{\tt :}{\em file-name} refers to a
deeper folder.  A simple {\em file-name} refers to a file in the folder from
which you launch the Metamath application.}\index{Macintosh file
names}\index{file names!Macintosh}\label{includef} For compatibility among
operating systems, you should keep the file names as simple as possible.  A
good convention to use is {\em file}{\tt .mm} where {\em file} is eight
characters or less, in lower case.

There is no limit to the nesting depth of included files.  One thing that you
should be aware of is that if two included files themselves include a common
third file, only the {\em first} reference to this common file will be read
in.  This allows you to include two or more files that build on a common
starting file without having to worry about label and symbol conflicts that
would occur if the common file were read in more than once.  (In fact, if a
file includes itself, the self reference will be ignored, although of course
it would not make any sense to do that.)  This feature also means, however,
that if you try to include a common file in several inner blocks, the result
might not be what you expect, since only the first reference will be replaced
with the included file (unlike the include statement in most other computer
languages).  Thus you would normally include common files only in the
outermost block\index{outermost block}.

\subsection{Compressed Proof Format}\label{compressed1}\index{compressed
proof}\index{proof!compressed}

The proof notation presented in Section~\ref{proof} is called a
{\bf normal proof}\index{normal proof}\index{proof!normal} and in principle is
sufficient to express any proof.  However, proofs often contain steps and
subproofs that are identical.  This is particularly true in typical
Metamath\index{Metamath} applications, because Metamath requires that the math
symbol sequence (usually containing a formula) at each step be separately
constructed, that is, built up piece by piece. As a result, a lot of
repetition often results.  The {\bf compressed proof} format allows Metamath
to take advantage of this redundancy to shorten proofs.

The specification for the compressed proof format is given in
Appen\-dix~\ref{compressed}.

Normally you need not concern yourself with the details of the compressed
proof format, since the Metamath program will allow you to convert from
the normal format to the compressed format with ease, and will also
automatically convert from the compressed format when proofs are displayed.
The overall structure of the compressed format is as follows:
\begin{center}
  {\tt \$= ( } {\em label-list} {\tt ) } {\em compressed-proof\ }\ {\tt \$.}
\end{center}
\index{{\tt \$=} keyword}
The first {\tt (} serves as a flag to Metamath that a compressed proof
follows.  The {\em label-list} includes all statements referred to by the
proof except the mandatory hypotheses\index{mandatory hypothesis}.  The {\em
compressed-proof} is a compact encoding of the proof, using upper case
letters, and can be thought of as a large integer in base 26.  White
space\index{white space} inside of {\em compressed-proof} is
optional and is ignored.

It is important to note that the order of the mandatory hypotheses of the
statement being proved must not be changed if the compressed proof format is
used, otherwise the proof will become incorrect.  The reason for this is that
the mandatory hypotheses are not mentioned explicitly in the compressed proof
in order to make the compression more efficient.  If you wish to change the
order of mandatory hypotheses, you must first convert the proof back to normal
format using the {\tt save proof {\em statement} /normal}\index{{\tt save
proof} command} command.  Later, you can go back to compressed format with
{\tt save proof {\em statement} /compressed}.

During error-checking with the {\tt verify proof} command, an error found
in the a compressed proof may point to a character in {\em compressed-proof},
which may not be very meaningful to you.  In this case, try to {\tt save
proof /normal} first, then do the {\tt verify proof} again.  In general, it
is best to make sure a proof is correct before saving it in compressed
format, because severe errors are less likely to be recoverable
than in normal format.

\subsection{Specifying Unknown Proofs or Subproofs}\label{unknown}

In a proof under development, any step or subproof that is not yet known may
be represented with a single {\tt ?}.  For the purposes of parsing the proof,
the {\tt ?}\ \index{{\tt ]}@{\tt ?}\ inside proofs} will push a single entry
onto the RPN stack just as if it were a hypothesis.  While developing a proof
with the Proof Assistant\index{Proof Assistant}, a partially developed proof
may be saved with the {\tt save new{\char`\_}proof}\index{{\tt save
new{\char`\_}proof} command} command, and {\tt ?}s will be placed at the
appropriate places.

All {\tt \$p}\index{{\tt \$p} statement} statements must have proofs, even if
they are entirely unknown.  Before creating a proof with the Proof Assistant,
you should specify a completely unknown proof as follows:
\begin{center}
  {\em label} {\tt \$p} {\em statement} {\tt \$= ?\ \$.}
\end{center}
\index{{\tt \$=} keyword}
\index{{\tt ]}@{\tt ?}\ inside proofs}

The {\tt verify proof}\index{{\tt verify proof} command} command will check
the known portions of a partial proof for errors, but will warn you that the
statement has not been proved.

Note that partially developed proofs may be saved in compressed format if
desired.  In this case, you will see one or more {\tt ?}s in the {\em
compressed-proof} part.\index{compressed proof}\index{proof!compressed}

\section{Appendix:  Axioms vs.\ Definitions}\label{definitions}

Metamath\index{Metamath} makes no distinction\index{axiom vs.\ definition}
between axioms\index{axiom} and definitions.\index{definition}  The {\tt
\$a}\index{{\tt \$a} statement} statement is used for both.  At first, this
may seem puzzling.  In the minds of many mathematicians, the distinction is
clear, even obvious, and hardly worth discussing.  A definition is considered
to be merely an abbreviation that can be replaced by the expression for which
it stands; although unless one actually does this, to be
precise that one should say that a theorem\index{theorem} is a consequence
of the axioms {\em and} the definitions that are used in the formulation of
the theorem \cite[p.~20]{Behnke}.\index{Behnke, H.}

What is a definition?  In its simplest form, a definition introduces a new
symbol and provides an unambiguous rule to transform an expression containing
the new symbol to one without it.  The concept of a ``proper
definition''\index{proper definition}\index{definition!proper} (as opposed to
a creative definition)\index{creative definition}\index{definition!creative}
that is usually agreed upon is (1) the definition should not strengthen the
language and (2) any symbols introduced by the definition should be eliminable
from the language \cite{Nemesszeghy}\index{Nemesszeghy, E. Z.}.  In other
words, they are mere typographical conveniences that do not belong to the
system and are theoretically superfluous.  This may seem obvious, but in fact
the nature of definitions can be subtle, sometimes requiring difficult
metatheorems to establish that they are not creative.

A more conservative stance was taken by logician S.
Le\'{s}niewski.\index{Le\'{s}niewski, S.} \begin{quote} Le\'{s}niewski regards
definitions as theses of the system.  In this respect they do not differ
either from the axioms or from theorems, i.e.\ from the theses added to the
system on the basis of the rule of substitution or the rule of detachment
[modus ponens].  Once definitions have been accepted as theses of the system,
it becomes necessary to consider them as true propositions in the same sense
in which axioms are true \cite{Lejewski}. \end{quote}\index{Lejewski, Czeslaw}

Let us look at some simple examples of definitions in propositional calculus.
Consider the definition of logical {\sc or} (disjunction):\index{disjunction
($\vee$)}  ``$P\vee Q$ denotes $\neg P \rightarrow Q$ (not $P$ implies
$Q$).''  It is very easy to recognize a statement making use of this
definition, because it introduces the new symbol $\vee$ that did not
previously exist in the language.  It is easy to see that no new theorems of
the original language will result from this definition.

Next, consider a definition that eliminates parentheses: ``$P
\rightarrow Q\rightarrow R$ denotes $P\rightarrow (Q \rightarrow R)$.''  This
is more subtle, because no new symbols are introduced.  The reason this
definition is considered proper is that no new symbol sequences that are valid
wffs (well-formed formulas)\index{well-formed formula (wff)} in the original
language will result from the definition, since ``$P \rightarrow Q\rightarrow
R$'' is not a wff in the original language.  Here, we implicitly make use of
the fact that there is a decision procedure that allows us to determine
whether or not a symbol sequence is a wff, and this fact allows us to use
symbol sequences that are not wffs to represent other things (such as wffs) by
means of the definition.  However, to justify the definition as not being
creative we need to prove that ``$P \rightarrow Q\rightarrow
R$'' is in fact not a wff in the original language, and this is more
difficult than in the case where we simply introduce a new symbol.

%Now let's take this reasoning to an extreme.  Propositional calculus is a
%decidable theory,\footnote{This means that a mechanical algorithm exists to
%determine whether or not a wff is a theorem.} so in principle we could make use
%of symbol sequences that are not theorems to represent other things (say, to
%encode actual theorems in a more compact way).  For example, let us extend the
%language by defining a wff ``$P$'' in the extended language as the theorem
%``$P\rightarrow P$''\footnote{This is one of the first theorems proved in the
%Metamath database {\tt set.mm}.}\index{set
%theory database ({\tt set.mm})} in the original language whenever ``$P$'' is
%not a theorem in the original language.  In the extended language, any wff
%``$Q$'' thus represents a theorem; to find out what theorem (in the original
%language) ``$Q$'' represents, we determine whether ``$Q$'' is a theorem in the
%original language (before the definition was introduced).  If so, we're done; if
%not, we replace ``$Q$'' by ``$Q\rightarrow Q$'' to eliminate the definition.
%This definition is therefore eliminable, and it does not ``strengthen'' the
%language because any wff that is not a theorem is not in the set of statements
%provable in the original language and thus is available for use by definitions.
%
%Of course, a definition such as this would render practically useless the
%communication of theorems of propositional calculus; but
%this is just a human shortcoming, since we can't always easily discern what is
%and is not a theorem by inspection.  In fact, the extended theory with this
%definition has no more and no less information than the original theory; it just
%expresses certain theorems of the form ``$P\rightarrow P$''
%in a more compact way.
%
%The point here is that what constitutes a proper definition is a matter of
%judgment about whether a symbol sequence can easily be recognized by a human
%as invalid in some sense (for example, not a wff); if so, the symbol sequence
%can be appropriated for use by a definition in order to make the extended
%language more compact.  Metamath\index{Metamath} lacks the ability to make this
%judgment, since as far as Metamath is concerned the definition of a wff, for
%example, is arbitrary.  You define for Metamath how wffs\index{well-formed
%formula (wff)} are constructed according to your own preferred style.  The
%concept of a wff may not even exist in a given formal system\index{formal
%system}.  Metamath treats all definitions as if they were new axioms, and it
%is up to the human mathematician to judge whether the definition is ``proper''
%'\index{proper definition}\index{definition!proper} in some agreed-upon way.

What constitutes a definition\index{definition}
versus\index{axiom vs.\ definition} an axiom\index{axiom} is sometimes
arbitrary in mathematical literature.  For example, the connectives
$\vee$ ({\sc or}), $\wedge$ ({\sc and}), and $\leftrightarrow$ (equivalent to) in
propositional calculus are usually considered defined symbols that can be
used as abbreviations for expressions containing the ``primitive'' connectives
$\rightarrow$ and $\neg$.  This is the way we treat them in the standard logic
and set theory database {\tt set.mm}\index{set theory database ({\tt set.mm})}.
However, the first three connectives can also be considered ``primitive,'' and
axiom systems have been devised that treat all of them as such.  For example,
\cite[p.~35]{Goodstein}\index{Goodstein, R. L.} presents one with 15 axioms,
some of which in fact coincide with what we have chosen to call definitions in
{\tt set.mm}.  In certain subsets of classical propositional calculus, such as
the intuitionist fragment\index{intuitionism}, it can be shown that one cannot
make do with just $\rightarrow$ and $\neg$ but must treat additional
connectives as primitive in order for the system to make sense.\footnote{Two
nice systems that make the transition from intuitionistic and other weak
fragments to classical logic just by adding axioms are given in
\cite{Robinsont}\index{Robinson, T. Thacher}.}

In set theory, recursive definitions define a newly introduced symbol
in terms of itself.  The justification of recursive definitions,
using several ``recursion theorems,''  is the usually one of the first
sophisticated proofs a student encounters when learning set
theory, and there is a significant amount of implicit metalogic behind
a recursive definition even though the definition itself is typically
simple to state.  It is, however, possible to
substitute one kind of complexity for another.  We can eliminate the need for
metalogical justification by defining the operation directly with an explicit
(but complicated) expression, then deriving the recursive definition
directly as a theorem, using a recursion theorem ``in reverse.''  We do
this in {\tt set.mm}, as follows.

In {\tt set.mm} our goal was to introduce almost
all definitions in the form of
two expressions connected by either $\leftrightarrow$ or $=$, where the thing
being defined does not appear on the right hand side.  Quine calls this form
``a genuine or direct definition'' \cite[p. 171]{Quine}\index{Quine, Willard
Van Orman}, which makes the definitions very easy to eliminate and the
metalogic\index{metalogic} needed to justify them as simple as possible.  We
achieved this goal in almost all cases. Sometimes this makes the definitions
more complex and less intuitive.  For example, the traditional way to define
addition of natural numbers is to define an operation called {\em
successor}\index{successor} (which means ``plus one'' and is denoted by
``${\rm suc}$''), then define addition recursively\index{recursive definition}
with the two definitions $n + 0 = n$ and $m + {\rm suc}\,n = {\rm suc} (m +
n)$.  Although this definition seems simple and obvious, the method to
eliminate the definition is not obvious: in the second part of the definition,
addition is defined in terms of itself.  By eliminating the definition, we
don't mean repeatedly applying it to specific $m$ and $n$ but rather showing
the explicit, closed-form set-theoretical expression that $m + n$ represents,
that will work for any $m$ and $n$ and that does not have a $+$ sign on its
right-hand side. For a recursive definition like this not to be circular
(creative), there are some hidden, underlying assumptions we must make, for
example that the natural numbers have a certain kind of order. In {\tt set.mm}
we chose to start with the direct (though complex and nonintuitive) definition
then derive from it the standard recursive definition.\footnote{The
closed-form definition used in {\tt set.mm} for the addition operation on
ordinals\index{ordinal addition}\index{addition!of ordinals} (of which natural
numbers are a subset) is

\setbox\startprefix=\hbox{\tt \ \ df-oadd\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{+_o}\m{=}\m{\{}\m{\langle}\m{\langle}\m{x}\m{,}\m{y}\m{\rangle}%
\m{,}\m{z}\m{\rangle}\m{|}\m{(}\m{(}\m{x}\m{\in}\m{{\rm On}}\m{\wedge}\m{y}\m{%
\in}\m{{\rm On}}\m{)}\m{\wedge}\m{z}\m{=}\m{(}\m{{\rm rec}}\m{(}\m{\{}\m{%
\langle}\m{w}\m{,}\m{v}\m{\rangle}\m{|}\m{v}\m{=}\m{{\rm suc}}\m{w}\m{\}}\m{,}%
\m{x}\m{)}\m{`}\m{y}\m{)}\m{)}\m{\}}
\endm

\noindent Here, the abstraction class of nested ordered pairs\index{abstraction
class!of nested ordered pairs} is defined by {\tt df-oprab} in {\tt set.mm},
and ${\rm rec}$ is a ``recursion operator''\index{recursion operator} with
the definition

\setbox\startprefix=\hbox{\tt \ \ df-rfg\ \$a\ }
\setbox\contprefix=\hbox{\tt \ \ \ \ \ \ \ \ \ \ \ \ }
\startm
\m{\vdash}\m{{\rm rec}}\m{(}\m{F}\m{,}\m{A}\m{)}\m{=}\m{\bigcup}\m{\{}\m{f}%
\m{|}\m{\exists}\m{x}\m{(}\m{x}\m{\in}\m{{\rm On}}\m{\wedge}\m{(}\m{f}\m{{%
\rm Fn}}\m{x}\m{\wedge}\m{\forall}\m{y}\m{(}\m{y}\m{\in}\m{x}\m{\rightarrow}%
\m{(}\m{f}\m{`}\m{y}\m{)}\m{=}\m{(}\m{\{}\m{\langle}\m{g}\m{,}\m{z}\m{\rangle}%
\m{|}\m{(}\m{(}\m{g}\m{=}\m{\varnothing}\m{\wedge}\m{z}\m{=}\m{A}\m{)}\m{\vee}%
\m{(}\m{\lnot}\m{(}\m{g}\m{=}\m{\varnothing}\m{\vee}\m{{\rm Lim}}\m{{\rm dom}}%
\m{g}\m{)}\m{\wedge}\m{z}\m{=}\m{(}\m{F}\m{`}\m{(}\m{g}\m{`}\m{\bigcup}\m{{%
\rm dom}}\m{g}\m{)}\m{)}\m{)}\m{\vee}\m{(}\m{{\rm Lim}}\m{{\rm dom}}\m{g}\m{%
\wedge}\m{z}\m{=}\m{\bigcup}\m{{\rm ran}}\m{g}\m{)}\m{)}\m{\}}\m{`}\m{(}\m{f}%
\m{\restriction}\m{y}\m{)}\m{)}\m{)}\m{)}\m{)}\m{\}}
\endm

\noindent which can be further broken down with definitions shown in
Section~\ref{setdefinitions}.  You may be surprised at the complexity of what
seems like such a simple notion.  From these definitions the simpler, more
intuitive recursive definition is derived as a set of theorems.}\index{natural
number}\index{addition}\index{recursive definition}\index{ordinal addition}
The end result is the same, but we completely eliminate the rather complex
metalogic that justifies the recursive definition.  (For a mathematician,
recursive definitions are more efficient and intuitive than
direct ones once the metalogic has been learned or possibly just accepted as
correct.  However, it was felt that direct definition in {\tt set.mm}
maximizes rigor by minimizing metalogic.  It can be eliminated effortlessly,
something difficult to do with a recursive definition.)


\chapter{The Metamath Program}\label{commands}

This chapter describes the commands that are available in the Metamath
program.\index{Metamath!commands}

In the syntax description, fields enclosed in square brackets [\ ] are
optional. File names may be optionally enclosed in quotes.  This is useful if
the file name contains slashes ({\tt /}), such as in Unix path names,
\index{Unix file names}\index{file names!Unix} that might be confused with
Metamath command qualifiers.

\section{Controlling Metamath}

\subsection{{\tt exit} Command}\index{{\tt exit} command}

Syntax:  {\tt exit}

This command exits from Metamath.  If there have been changes to the source
with the {\tt save proof} or {\tt save new{\char`\_}proof} commands, you will be
given an opportunity to {\tt write source} to permanently save the changes.

In Proof Assistant\index{Proof Assistant} mode, the {\tt exit} command will
return to the \verb/MM>/ prompt. If there were changes to the proof, you will
be given an opportunity to {\tt save new{\char`\_}proof}.



\subsection{{\tt open log} Command}\index{{\tt open log} command}
Syntax:  {\tt open log} {\em file-name}

This command will open a log file that will store everything you see on
the screen.  It is useful to help recovery from a mistake in a long Proof
Assistant session, or to document bugs.\index{Metamath!bugs}

The log file can be closed with {\tt close log}.  It will automatically be
closed upon exiting Metamath.



\subsection{{\tt close log} Command}\index{{\tt close log} command}
Syntax:  {\tt close log}

The {\tt close log} command closes a log file if one is open.  See also {\tt
open log}.



\subsection{{\tt open tex} Command}\index{{\tt open tex} command}
Syntax:  {\tt open tex} {\em file-name} [{\tt /no{\char`\_}header}]

This command opens a file for writing \LaTeX\ source\index{latex@{\LaTeX}} and
writes a \LaTeX\ header to the file.  \LaTeX\ source can be written with the
{\tt show proof}, {\tt show new{\char`\_}proof}, and {\tt show statement}
commands using the {\tt /tex} qualifier.  The mapping to \LaTeX\ symbols is
defined in a file normally called {\tt latex.def}, described in
Appendix~\ref{ASCII}, and you will be prompted for the name of this file if it
has not been read in yet.

To format and print the \LaTeX\ source, you will need the \LaTeX\ program with
the AMSFonts installed.

Optional command qualifier:

    {\tt /no{\char`\_}header} - This qualifier prevents a standard
        \LaTeX\ header and trailer
        from being included with the output \LaTeX\ code.

See also {\tt close tex}.


\subsection{{\tt close tex} Command}\index{{\tt close tex} command}
Syntax:  {\tt close tex}

This command writes a trailer to any \LaTeX\ file\index{latex@{\LaTeX}} that
was opened with  {\tt open tex} (unless {\tt /no{\char`\_}header} was used with
{\tt open tex}) and closes the \LaTeX\ file.

See also {\tt open tex}.



\subsection{{\tt submit} Command}\index{{\tt submit} command}
Syntax:  {\tt submit} {\em filename}

This command causes further command lines to be taken from the specified
file.  Note that any line beginning with an exclamation point ({\tt !})
is treated as a comment (i.e.\ ignored).  Also note that the scrolling of
the screen output is continuous, so you may wish to open a log file
to record the results.




\subsection{{\tt erase} Command}\index{{\tt erase} command}
Syntax:  {\tt erase}

This command will reset Metamath to its starting state, deleting any
database that was {\tt read} in.


\subsection{Operating System Commands}\index{operating system command}

A line enclosed in single or double quotes will be executed by your computer's
operating system if it has a command line interface.  For example, on a {\sc
vax/vms} system,
    \verb/MM> 'dir'/
will print disk directory contents.  Note that this feature will not work
on the Macintosh, which does not have a command line interface.

For your convenience, the trailing quote is optional.



\subsection{{\tt set echo} Command}\index{{\tt set echo} command}
Syntax:  {\tt set echo on} or {\tt set echo off}

The {\tt set echo on} command will cause command lines to be echoed with any
abbreviations expanded.  While learning the Metamath commands, this
feature will show you the exact command that your abbreviated input
corresponds to.



\subsection{{\tt set scroll} Command}\index{{\tt set scroll} command}
Syntax:  {\tt set scroll prompted} or {\tt set scroll continuous}

The Metamath command line interface starts off in the {\tt prompted} mode,
which means that you will prompted to continue or quit after each
full screen in a long listing.  In {\tt continuous} mode, long listings will be
scrolled without pausing.

% LaTeX bug? (1) {\tt \_} puts out different character than {\tt {\char`\_}}
%  = \verb$_$  (2) {\tt {\char`\_}} puts out garbage in \subsection
%  argument
\subsection{{\tt set screen\_width} Command}\index{{\tt set
screen{\char`\_}width} command}
Syntax:  {\tt set screen{\char`\_}width} {\em number}

Metamath assumes the width of your screen is 79 characters.  If your
screen is wider or narrower, this command allows you to change the screen
width.  A larger width is advantageous for logging proofs to an output
file to be printed on a wide printer.  A smaller width may be necessary
on some terminals; in this case, the wrapping of the information
messages may sometimes seem somewhat unnatural, however.  In
LaTeX\index{latex@{\LaTeX}!characters per line}, there
is normally a maximum of 61 characters per line with typewriter font.

\subsection{{\tt beep} Command}\index{{\tt beep} command}

Syntax:  {\tt beep}

This command will produce a beep.  By typing it ahead after a long-
running command has started, it will alert you that the command is
finished.


\section{Reading and Writing Files}

\subsection{{\tt read} Command}\index{{\tt read} command}
Syntax:  {\tt read} {\em file-name} [{\tt /verify}]

This command will read in a Metamath language database, including any included
files in main file specified.\index{database} \footnote{The syntax for
specifying a Macintosh a Macintosh file name path is given in a footnote on
p.~\pageref{includef}.}\index{Macintosh file names}\index{file
names!Macintosh} Normally it will be the first thing you do when entering
Metamath. Statement syntax is checked, but proof syntax is not checked.

Optional command qualifier:

    {\tt /verify} - Verify all proofs as the database is read in.  This
         qualifier will slow down reading in the file.

See also {\tt erase}.



\subsection{{\tt write source} Command}\index{{\tt write source} command}
Syntax:  {\tt write source} {\em filename}

This command will write the contents of a Metamath\index{database} database
into a file.\index{source file} Note:  The present version of Metamath
(0.06)\index{Metamath!limitations of version 0.06} will not split the database
into its constituent source files included with {\tt \$[}\index{{\tt \$[} and
{\tt \$]} auxiliary keywords} and {\tt \$]} keywords.  A future version is
planned to properly separate all constituent files.



\section{Showing Status and Statements}



\subsection{{\tt show settings} Command}\index{{\tt show settings} command}
Syntax:  {\tt show settings}

This command shows the state of various parameters.

\subsection{{\tt show memory} Command}\index{{\tt show memory} command}
Syntax:  {\tt show memory}

This command shows the available memory left.  It may not be meaningful
on machines with virtual memory.\index{Metamath!memory usage}


\subsection{{\tt show labels} Command}\index{{\tt show labels} command}
Syntax:  {\tt show labels} {\em label-match} [{\tt /all}]

This command shows the labels of {\tt \$a} and {\tt \$p} statements that match
{\em label-match}.  A \verb$*$ in {label-match} matches any characters.  For
example, \verb$*abc*def$ will match all labels containing \verb$abc$ and ending
with \verb$def$.

Optional command qualifier:

    {\tt /all} - Include matches for {\tt \$e} and {\tt \$f} statement labels.



\subsection{{\tt show statement} Command}\index{{\tt show statement} command}
Syntax:  {\tt show statement} {\em label} [{\tt /tex}] [{\tt
  /comment{\char`\_}only}]

This command provides information about a statement.  Only statements that
have labels ({\tt \$f}\index{{\tt \$f} statement}, {\tt \$e}\index{{\tt \$e}
statement}, {\tt \$a}\index{{\tt \$a} statement}, and {\tt \$p}\index{{\tt
\$p} statement}) may be specified.

Optional command qualifiers:

    {\tt /tex} - This qualifier will write the statement
        information to the \LaTeX\
        file\index{latex@{\LaTeX}} previously opened with {\tt open tex}.

    {\tt /comment{\char`\_}only} - This qualifier will show only the comment
        that
        immediately precedes the statement.  This is useful when you are
        using Metamath to preprocess \LaTeX\ source you have created (see
        {\tt help tex} in the Meta\-math program)

    {\tt /brief} - This qualifier shows the statement and its {\tt \$e}
        hypotheses only.


\subsection{{\tt search} Command}\index{{\tt search} command}
Syntax:  search {\em label-match}
{\tt "}{\em symbol-match}{\tt}" [{\tt / all}] [{\tt / comments}]

This command searches all {\tt \$a} and {\tt \$p} statements matching {\em
label-match} for occurrences of {\em symbol-match}.  A \verb@*@ in {\em
label-match} matches any label character.  A \verb@$*@ in {\em symbol-match}
matches any sequence of symbols.  The symbols in {\em symbol-match} must be
separated by white space.  The quotes surrounding {\em symbol-match} may be
single or double quotes.  For example, {\tt search b}\verb@* "-> $* ch"@ will
list all statements whose labels begin with {\tt b} and contain the symbols
\verb@->@ and {\tt ch} surrounding any symbol sequence (including no symbol
sequence).

Optional command qualifiers:

    {\tt / all} - Also search {\tt \$e} and {\tt \$f} statements.

    {\tt / comments} - Search the comment that immediately precedes each
        label-matched statement for {\em symbol-match}.  In this case
        {\em symbol-match} is an arbitrary, non-case-sensitive character
        string.  Quotes around {\em symbol-match} are optional if there
        is no ambiguity.



\section{Displaying and Verifying Proofs}


\subsection{{\tt show proof} Command}\index{{\tt show proof} command}
Syntax:  {\tt show proof} {\em label} [{\em qualifiers} (see below)]

This command displays the proof of the specified {\tt \$p}\index{{\tt \$p}
statement} statement in various formats.  Without any qualifiers, all steps
will be shown in indented (tree) format.

Most of the time, you will use
    {\tt show proof} {\em label} {\tt /essential}
to see just the proof steps corresponding to logical inferences.

Optional command qualifiers:

    {\tt /essential} - the proof tree is trimmed of all
        {\tt \$f}\index{{\tt \$f} statement} hypotheses before
        being displayed.

    {\tt /from{\char`\_}step} {\em step} - the display starts at the specified
        step.  If
        this qualifier is omitted, the display starts at the first step.

    {\tt /to{\char`\_}step} {\em step} - the display ends at the specified
        step.  If this
        qualifier is omitted, the display ends at the last step.

    {\tt /depth} {\em number} - Only steps at less than the specified proof
        tree depth are displayed.  Useful for obtaining an overview of
        the proof.

    {\tt /reverse} - the steps are displayed in reverse order.

    {\tt /renumber} - when used with {\tt /essential}, the steps are renumbered
        to correspond only to the essential steps.

    {\tt /tex} - the proof is converted to \LaTeX\ \index{latex@{\LaTeX}} and
        stored in the file opened
        with {\tt open tex}.

    {\tt /lemmon} - The proof is displayed in a non-indented format known
        as Lemmon style, with explicit previous step number references.
        If this qualifier is omitted, steps are indented in a tree format.

    {\tt /column} {\em number} - Overrides the default column at which
        the formula display starts in a Lemmon-style display.  May be
        used only in conjunction with {\tt /lemmon}.

    {\tt /normal} - The proof is displayed in normal format suitable for
        inclusion in a Metamath source file.  May not be used with any other
        qualifier.

    {\tt /compressed} - The proof is displayed in compressed format
        suitable for inclusion in a Metamath source file.  May not be used with
        any other qualifier.

    {\tt /summary} - Summarizes all statements (like a
        brief {\tt show statement})
        used by the proof.  It may not be used with any other qualifier
        except {\tt /essential}.

    {\tt /detailed{\char`\_}step} {\em step} - Shows the details of what is
        happening at
        a specific proof step.  May not be used with any other qualifier.
        The {\em step} is the step number shown when displaying a
        proof without the {\tt /renumber} qualifier.


\subsection{{\tt show usage} Command}\index{{\tt show usage} command}
Syntax:  {\tt show usage} {\em label} [{\tt /recursive}]

This command lists the statements whose proofs make direct reference to
the statement specified.

Optional command qualifier:

    {\tt /recursive} - Also include statements whose proof ultimately
        depend on the statement specified.



\subsection{{\tt show trace\_back} Command}\index{{\tt show
       trace{\char`\_}back} command}
Syntax:  {\tt show trace{\char`\_}back} [{\tt /essential}] [{\tt /axioms}]
    [{\tt /tree}] [{\tt /depth} {\em number}]

This command lists all statements that the proof of the specified {\tt
\$p}\index{{\tt \$p} statement} statement depends on.

Optional command qualifiers:

    {\tt /essential} - Restrict the trace-back to {\tt \$e}
        \index{{\tt \$e} statement} hypotheses of proof trees.

    {\tt /axioms} - List only the axioms that the proof ultimately depends on.

    {\tt /tree} - Display the trace-back in an indented tree format.

    {\tt /depth} {\em number} - Restrict the {\tt /tree} trace-back to the
        specified indentation depth.

    {\tt /count{\char`\_}steps} - Counts the number of steps the proof would
       have if fully expanded back to axioms.  If {\tt /essential} is specified,
       expansions of variable-type hypotheses are not counted.

\subsection{{\tt verify proof} Command}\index{{\tt verify proof} command}
Syntax:  {\tt verify proof} {\em label-match} [{\tt /syntax{\char`\_}only}]

This command verifies the proofs of the specified statements.
{\em label-match} may contain wild card characters ({\tt *}) to verify more than one
proof; for example \verb/*abc*def/ will match all labels containing
{\tt abc}
and ending with {\tt def}. {\tt verify proof *} will verify all proofs in the
database.

Optional command qualifier:

    {\tt /syntax{\char`\_}only} - This qualifier will perform a check of syntax
        and RPN
        stack violations only.  It will not verify that the proof is
        correct.  This qualifier is useful for quickly determining which
        proofs are incomplete (i.e.\ are under development and have {\tt ?}s
        in them).

\subsection{{\tt save proof} Command}\index{{\tt save proof} command}
Syntax:  {\tt save proof} {\em label} [{\tt /normal}]
   [{\tt /compressed}]

The {\tt save proof} command will reformat a proof in one of two formats and
replace the existing proof in the source buffer\index{source
buffer}.  It is useful for
converting between proof formats.  Note that a proof will not be
permanently saved until a {\tt write source} command is issued.

Optional command qualifiers:

    {\tt /normal} - The proof is saved in the normal format (i.e., as a
        sequence
        of labels, which is the defined format of the basic Metamath
        language).\index{basic language}  This is the default format that
        is used if a qualifier
        is omitted.

    {\tt /compressed} - The proof is saved in the compressed format which
        reduces storage requirements for a database.




\section{Changing Label and Symbol Names}

%??
[Not implemented in the current version of Metamath
(0.06)\index{Metamath!limitations of version 0.06}.]

\section{Creating Proofs}\label{pfcommands}



\subsection{{\tt prove} Command}\index{{\tt prove} command}
Syntax:  {\tt prove} {\em label}

This command will enter the Proof Assistant\index{Proof Assistant}, which will
allow you to create or edit the proof of the specified statement.  Note:  When
creating very large proofs, a substantial amount of memory may be
needed.\index{Metamath!memory usage}  Use the {\tt show memory}
command\index{{\tt show memory} command} periodically to monitor the memory
you have available.  Some computers (e.g.\ Macintosh) allow you to increase
Metamath's application size and you may want to do this.  Also, the C
compilers on some computers do not always properly free up temporary memory
usage, and the memory pool available may get smaller and smaller as you work
with the proof.  In this case, periodically save your work with {\tt save
new{\char`\_}proof} and {\tt write source} then {\tt exit} and re-enter Metamath.

Note:  In the present version of Metamath (0.06)\index{Metamath!limitations of
version 0.06}, the Proof Assistant does not verify that {\tt \$d} restrictions
are met as a proof is being built.  After you have completed a proof, you
should type {\tt save new{\char`\_}proof} followed by  {\tt verify proof} {\em
label} (where {\em label} is the statement you are proving with the {\tt
prove} command) to verify the {\tt \$d} restrictions.

See also: {\tt exit}

\subsection{{\tt set unification\_timeout} Command}\index{{\tt set
unification{\char`\_}timeout} command}
Syntax:  {\tt set unification{\char`\_}timeout} {\em number}

(This command is available outside the Proof Assistant but affects the
Proof Assistant\index{Proof Assistant} only.)

Sometimes the Proof Assistant will inform you that a unification time-out
occurred.  This may happen when you try to {\tt unify} formulas with many
temporary variables\index{temporary
variable}, since the time to compute unifications may grow
exponentially with the number of variables.  If you want Metamath to try
harder (and you're willing to wait longer) you may increase this
parameter.  {\tt show settings} will show you the current value.



\subsection{{\tt set empty\_substitution} Command}\index{{\tt set
empty{\char`\_}substitution} command}
Syntax:  {\tt set empty{\char`\_}substitution on} or {\tt set
empty{\char`\_}substitution off}

(This command is available outside the Proof Assistant but affects the
Proof Assistant\index{Proof Assistant} only.)

The Metamath language allows variables to be
substituted\index{substitution!variable}\index{variable substitution} with
empty symbol sequences\index{empty substitution}.  However, in many formal
systems\index{formal system} this will never happen in a valid proof.
Allowing for this possibility increases the likelihood of ambiguous
unifications\index{ambiguous
unification}\index{unification!ambiguous} during proof creation, and you may
want to {\tt set empty{\char`\_}substitution off} to help make the process
more efficient.  With this mode set, you may not be able to create some proofs
in formal systems that allow empty substitutions.  (An example would be a
system that implements a Deduction Rule and in which deductions from empty
assumption lists would be permissible.  The MIU-system\index{MIU-system}
described in Appendix~\ref{MIU} is another example.)



\subsection{{\tt set search\_limit} Command}\index{{\tt set
search{\char`\_}limit} command} Syntax:  {\tt set search{\char`\_}limit} {\em
number}

(This command is available outside the Proof Assistant but affects the
Proof Assistant\index{Proof Assistant} only.)

This command sets a parameter that determines when the {\tt improve} command
in Proof Assistant mode gives up.  If you want {\tt improve} to search harder,
you may increase it.  The {\tt show settings} command tells you its current
value.


\subsection{{\tt show new\_proof} Command}\index{{\tt show
new{\char`\_}proof} command}
Syntax:  {\tt show new{\char`\_}proof} [{\em
qualifiers} (see below)]

This command (available only in Proof Assistant mode) displays the proof
in progress.  It is identical to the {\tt show proof} command, except that the
statement is not specified (since it is the statement being proved) and
following qualifiers are not available:

    {\tt /statement{\char`\_}summary}

    {\tt /detailed{\char`\_}step}

Also, the following additional qualifiers are available:

    {\tt /unknown} - Shows only steps that have no statement assigned.

    {\tt /not{\char`\_}unified} - Shows only steps that have not been unified.

Note that {\tt /essential}, {\tt /depth}, {\tt /unknown}, and
{\tt /not{\char`\_}unified} may be
used in any combination; each of them effectively filters out additional
steps from the proof display.

See also:  {\tt show proof}





\subsection{{\tt assign} Command}\index{{\tt assign} command}
Syntax:   {\tt assign} {\em step} {\em label}

This command, available in the Proof Assistant\index{Proof Assistant} only,
assigns an unknown step (one with {\tt ?}\index{{\tt ]}@{\tt ?}\ inside
proofs}\ in the {\tt show new{\char`\_}proof} listing) with the statement
specified by {\em label}.  The assignment will not be allowed if the statement
cannot be unified with the step.  To see what statements may be unified with
the step, you may use the {\tt match} command.



\subsection{{\tt match} Command}\index{{\tt match} command}
Syntax:  {\tt match step} {\em step} [{\tt /max{\char`\_}essential{\char`\_}hyp}
{\em number}]

    and:  {\tt match all} [{\tt /essential}]
          [{\tt /max{\char`\_}essential{\char`\_}hyp} {\em number}]

This command, available in the Proof Assistant only, shows what
statements can be unified with the specified step(s).

Optional command qualifiers:

    [{\tt /max{\char`\_}essential{\char`\_}hyp} {\em number}] - filters out
        of the list any statements
        with more than the specified number of
        {\tt \$e}\index{{\tt \$e} statement} hypotheses

    {\tt /essential{\char`\_}only} - in the {\tt match all} statement, only
        the steps that
        would be listed in {\tt show new{\char`\_}proof /essential} display are
        matched.



\subsection{{\tt let} Command}\index{{\tt let} command}
Syntax: {\tt let variable} {\em variable} = \verb/"/{\em symbol-sequence}\verb/"/

      and:   {\tt let step} {\em step} = \verb/"/{\em symbol-sequence}\verb/"/

These commands, available in the Proof Assistant\index{Proof Assistant} only,
assign a temporary variable\index{temporary variable} or unknown step with a
specific symbol sequence.  They are useful in the middle of creating a proof,
when you know what should be in the proof step but the unification algorithm
doesn't yet have enough information to completely specify the temporary
variables.  An ``temporary'' variable is one that has the form {\tt \$}{\em
nn} in the proof display, such as {\tt \$1}, {\tt \$2}, etc. The {\em
symbol-sequence} may contain other unknown variables if desired. Examples:

    \verb/let variable $32 = "A = B"/

    \verb/let variable $32 = "A = $35"/

    \verb/let step 10 = "|- x = x"/

Any symbol sequence will be accepted for the {\tt let variable} command.  The
step in {\tt let step} must be an unknown step, and only symbol sequences
that can be unified with the step will be accepted.

The {\tt let} commands are somewhat dangerous in that they ``zap'' the proof
with information that can only be verified when the proof is built up
further. If you make an error, the {\tt initialize} commands can help undo what
you did.

\subsection{{\tt unify} Command}\index{{\tt unify} command}
Syntax:  {\tt unify step} {\em step}

      and:   {\tt unify all} [{\tt /interactive}]

These commands, available in the Proof Assistant only, unify the source
and target of the specified step(s). If you specify a specific step, you
will be prompted to select among the unifications that are possible.  If
you specify {\tt all}, only those steps with unique unifications will be
unified.

Optional command qualifier for {\tt unify all}:

    {\tt /interactive} - You will be prompted to select among the unifications
        that are possible for any steps that do not have unique
        unifications.  (Otherwise {\tt unify all} will bypass these.)

See also {\tt set unification{\char`\_}timeout}.



\subsection{{\tt initialize} Command}\index{{\tt initialize} command}
Syntax:  {\tt initialize step} {\em step}

    and: {\tt initialize all}

These commands, available in the Proof Assistant\index{Proof Assistant} only,
``de-unify'' the target and source of a step (or all steps), as well as the
hypotheses of the source, and makes all variables in the source and the
source's hypotheses unknown.  This command is useful to help recover when a
mistake resulted in incorrect unifications.

See also:  {\tt unify} and {\tt delete}



\subsection{{\tt delete} Command}\index{{\tt delete} command}
Syntax:  {\tt delete step} {\em step}

   and:      {\tt delete all}

   and:      {\tt delete variable-type{\char`\_}hypotheses}

These commands are available in the Proof Assistant only. The {\tt delete step}
command deletes the proof tree section that branches off of the specified step
and makes the step become unknown.  {\tt delete all} is equivalent to {\tt
delete step} {\em step} where {\em step} is the last step in the proof
(i.e.\ the beginning of the proof tree).

{\tt delete variable-type{\char`\_}hypotheses} will delete all sections of the
proof that branch off of {\tt \$f}\index{{\tt \$f} statement} statements.  It
is sometimes useful to do this before an {\tt initialize} command to recover
from an error.  Note that once a proof step with a {\tt \$f} hypothesis as the
target is completely known, the {\tt improve} command can usually fill in the
proof for that step.



\subsection{{\tt improve} Command}\index{{\tt improve} command}
\label{improve}
Syntax:  {\tt improve step} {\em step} [{\tt /depth} {\em number}]

   and:   {\tt improve all} [{\tt /depth} {\em number}]

These commands, available in the Proof Assistant\index{Proof Assistant} only,
try to automatically find proofs for unknown steps whose symbol sequences are
completely known.  It is primarily useful for filling in proofs of {\tt
\$f}\index{{\tt \$f} statement} hypotheses.  The search will be restricted to
statements having no {\tt \$e}\index{{\tt \$e} statement} hypotheses.
{\em Warning:}  The {\tt improve} command may require a lot of memory.  In the
current version of Metamath (0.06) there is no recovery if memory overflows,
so it is recommended that you {\tt save new{\char`\_}proof} and
{\tt write source} before invoking the {\tt improve} command.

Optional command qualifier:

    {\tt /depth} {\em number} - This qualifier will cause the search to include
        assertions with up to and
        including {\em number} {\tt \$e}\index{{\tt \$e} statement}
        hypotheses (but not any that have variables in their {\tt \$e}
        hypotheses that aren't contained in the assertion). If this
        qualifier is omitted, the search
        will not look at any statements with {\tt \$e} hypotheses.
{\em Warning:}  A depth greater than 1
can cause an exponential increase in search time. In the current version of
Metamath (0.06) there is no way to abort an {\tt improve} command run and
return to the command line prompt, so recovery is not possible if the {\tt
improve} command never completes within the time you are willing to wait.
Make sure the proof is saved before experimenting with depths greater than 1.

\subsection{{\tt save new\_proof} Command}\index{{\tt save
new{\char`\_}proof} command}
Syntax:  {\tt save new{\char`\_}proof} {\em label} [{\tt /normal}]
   [{\tt /compressed}]

The {\tt save new{\char`\_}proof} command is available in the Proof Assistant
only. It saves the proof in progress in the source buffer\index{source
buffer}.  {\tt save new{\char`\_}proof} may be used to save a completed proof,
or it may be used to save a proof in progress in order to work on it later.
If an incomplete proof is saved, any user assignments with {\tt let step} or
{\tt let variable} will be lost, as will any ambiguous
unifications\index{ambiguous
unification}\index{unification!ambiguous} that were resolved manually. To help
make recovery easier, it can be helpful to {\tt improve all} before {\tt save
new{\char`\_}proof} so that the incomplete proof will have as much information
as possible (heeding, however, the memory limitation
warning in Section~\ref{improve}).

Note that the proof will not be permanently saved until a {\tt write source}
command is issued.

Optional command qualifiers:

    {\tt /normal} - The proof is saved in the normal format (i.e., as a
        sequence of labels, which is the defined format of the basic Metamath
        language).\index{basic language}  This is the default format that
        is used if a qualifier is omitted.

    {\tt /compressed} - The proof is saved in the compressed format which
        reduces storage requirements for a database.



\section{File Utilities}

\subsection{{\tt file type} Command}\index{{\tt file type} command}
Syntax:  {\tt file type} {\em file-name} [{\tt /from{\char`\_}line} {\em number}]
 [{\tt /to{\char`\_}line} {\em number}]

This command will type the contents of an {\sc ascii} file on your screen,
with an optional range of line numbers.  This command is useful primarily
on systems such as the Macintosh that do not have this ability.  On other
systems it is better to use your operating system's commands.

See also:  Operating system commands



\subsection{{\tt file search} Command}\index{{\tt file type} command}
Syntax:  {\tt file search} {\em filename} \verb/"/{\em search-string}\verb/"/
       [{\tt /from{\char`\_}line} {\em number}]

       [{\tt /to{\char`\_}line} {\em number}]

This command will search an {\sc ascii} file for the specified string in
quotes, within an optional range of line numbers.  This command is useful
primarily
on systems such as the Macintosh that do not have this ability.  On other
systems it is better to use your operating system's commands.

See also:  Operating system commands



\section{Size Limitations in Metamath}

In general, there are no fixed, predefined limits\index{Metamath!memory
limits} on how many labels,
tokens\index{token}, statements, etc.\ that you may have in a database
file.  The Metamath program uses 32-bit variables as indices for almost all
internal arrays, and arrays are allocated dynamically as needed.  Metamath
works best on a machine with virtual memory.  On a fixed-memory machine such
as the Macintosh, a minimum of 8 megabytes (in addition to the operating
system size) is recommended, and more is desirable.  You should be aware that
Metamath keeps the entire database (with all included files) in memory, along
with a compiled representation of the database, so that it can run faster.
Building long proofs with the Proof Assistant\index{Proof Assistant}, and
verifying very long proofs, tends to use a lot of memory.  The {\tt show
memory} command will tell you how much memory you have available at any time,
although it may not be meaningful on systems with virtual memory.
The {\tt improve} command, in particular, can use a lot of memory,
and it is recommended you save your work before invoking it
(Section~\ref{improve}).

\appendix
\chapter{Math Symbol Tokens for Set Theory}
\label{ASCII}

This Appendix lists the tokens (math symbols) that were
chosen for use in the set theory database, {\tt set.mm}, in order of appearance,
along with the mathematical symbol that corresponds to it.  The
{\tt set.mm} file has an explanation of the meaning of each symbol.

The file {\tt latex.def} contains the \LaTeX\ definitions for these symbols
and is used by the {\tt write tex} command.  If you add a new token to the set
theory database (or your own database), you should also update the {\tt
latex.def} file if you want to create a \LaTeX\ output file.  The
{\tt latex.def} file is not needed for normal operation of the Metamath
program, but is requested only when you open a \LaTeX\ output file
with the {\tt open tex} command.  The
{\tt latex.def} file consists of a series of \LaTeX\ definitions with
the following syntax:
\begin{center}
 {\tt define} {\em token-string} {\tt as} {\em latex-string} {\tt ;}
\end{center}
\index{latex definitions@\LaTeX\ definitions}
The fields are separated by white space (blanks, carriage returns, etc.),
although white space is not needed before the {\tt ;} terminator.  Each
definition should start on a new line.\footnote{This restriction of the current
version of Metamath (0.06)\index{Metamath!limitations of version 0.06}
may be removed in a future version, but you should do it anyway for
readability.}  For example,
\begin{center}
 \verb$define "(_" as "\subseteq";$
\end{center}
defines the token \verb$(_$ as the \LaTeX\ symbol $\subseteq$ (which means
``subset'').

The {\em token-string} and {\em latex-string} are the character strings for
the token and the \LaTeX\ definition of the token, respectively, enclosed in
either double ({\tt \char`\"}) or single ({\tt '}) quotation
marks.  {\em The string enclosed in quotation marks may not include
line breaks.}  A {\em token-string} or {\em latex-string}
may include a quotation mark that matches the enclosing quotes by repeating
the quotation mark twice; for example the {\em token-string}\,s
\begin{center}
 {\tt \char`\"a\char`\"\char`\"b\char`\"}\\
 {\tt 'c''d'}\\
 {\tt \char`\"e''f\char`\"}\\
 {\tt 'g\char`\"\char`\"h'}
\end{center}
specify the tokens {\tt a\char`\"b}, {\tt c'd}, {\tt e''f}, and
{\tt g\char`\"\char`\"h} respectively.  Finally, a
long {\em latex-string} may
be broken up into  multiple quote-enclosed strings joined by {\tt \char`\+} in
order to fit them on several lines; thus
\begin{center}
 {\tt \char`\"ab\char`\"\ \char`\ \+\ \char`\"cd\char`\"
    \char`\+\ 'ef'}
\end{center}
is the same as
\begin{center}
 {\tt \char`\"abcdef\char`\"}
\end{center}

%\begin{quote}
%  {\em
%As you crack your eyes one morning your reason is assaulted by
%a strange sight.  Over your head, humming quietly, there floats
%a monitor, an ethereal otherworldly screen on which is written a
%curious message.  ``I am the Screen of ultimate Truth.  I am bulging
%with information and ask nothing better than to be allowed to impart
%it.''
%}
%  \flushright\sc  John Baez\footnote{John Baez ({\em baez@guitar.ucr.edu}),
%Internet newsgroup {\em sci.math}, 1995}\\
%\end{quote}\index{Baez, John}



%\input{metamaths.tex}
% Start of metamaths.tex
\newpage
{\samepage
\begin{center}
\begin{tabular}
{|l|lr||l|lr||l|lr|}
\hline
{\small Token}&\multicolumn{2}{l||}{\small Symbol}&
{\small Token}&\multicolumn{2}{l||}{\small Symbol}&
{\small Token}&\multicolumn{2}{l|}{\small Symbol}\\
 \hline \hline
\verb$($&\multicolumn{2}{l||}{$($}&
\verb$B$&\multicolumn{2}{l||}{$B$}&
\verb$dom$&\multicolumn{2}{l|}{${\rm dom}$}\\ \hline
\verb$)$&\multicolumn{2}{l||}{$)$}&
\verb$C$&\multicolumn{2}{l||}{$C$}&
\verb$ran$&\multicolumn{2}{l|}{${\rm ran}$}\\ \hline
\verb$->$&\multicolumn{2}{l||}{$\rightarrow$}&
\verb$D$&\multicolumn{2}{l||}{$D$}&
\verb$|`$&\multicolumn{2}{l|}{$\restriction$}\\ \hline
\verb$-.$&\multicolumn{2}{l||}{$\lnot$}&
\verb$R$&\multicolumn{2}{l||}{$R$}&
\verb$"$&\multicolumn{2}{l|}{$``$}\\ \hline
\verb$wff$&\multicolumn{2}{l||}{${\rm wff}$}&
\verb$S$&\multicolumn{2}{l||}{$S$}&
\verb$o.$&\multicolumn{2}{l|}{$\circ$}\\ \hline
\verb$|-$&\multicolumn{2}{l||}{$\vdash$}&
\verb$=/=$&\multicolumn{2}{l||}{$\ne$}&
\verb$Rel$&\multicolumn{2}{l|}{${\rm Rel}$}\\ \hline
\verb$ph$&\multicolumn{2}{l||}{$\varphi$}&
\verb$e/$&\multicolumn{2}{l||}{$\notin$}&
\verb/Fun/&\multicolumn{2}{l|}{${\rm Fun}$}\\ \hline
\verb$ps$&\multicolumn{2}{l||}{$\psi$}&
\verb$V$&\multicolumn{2}{l||}{$V$}&
\verb/Fn/&\multicolumn{2}{l|}{${\rm Fn}$}\\ \hline
\verb$ch$&\multicolumn{2}{l||}{$\chi$}&
\verb/F/&\multicolumn{2}{l||}{$ F$}&
\verb$:$&\multicolumn{2}{l|}{$:$}\\ \hline
\verb/th/&\multicolumn{2}{l||}{$\theta$}&
\verb$G$&\multicolumn{2}{l||}{$G$}&
\verb$-->$&\multicolumn{2}{l|}{$\longrightarrow$}\\ \hline
\verb/ta/&\multicolumn{2}{l||}{$\tau$}&
\verb$(_$&\multicolumn{2}{l||}{$\subseteq$}&
\verb$-1-1->$&\multicolumn{2}{l|}{$
  \raisebox{.5ex}{${\textstyle{\:}_{\mbox{\footnotesize\rm 1
  \tt -\rm 1}}}\atop{\textstyle{
  \longrightarrow}\atop{\textstyle{}^{\mbox{\footnotesize\rm {\ }}}}}$}
  $}\\ \hline
\verb$<->$&\multicolumn{2}{l||}{$\leftrightarrow$}&
\verb$(.$&\multicolumn{2}{l||}{$\subset$}&
\verb$-onto->$&\multicolumn{2}{l|}{$
  \raisebox{.5ex}{${\textstyle{\:}_{\mbox{\footnotesize\rm {\ }}}}
  \atop{\textstyle{
  \longrightarrow}\atop{\textstyle{}^{\mbox{\footnotesize\rm onto}}}}$}
  $}\\ \hline
\verb$\/$&\multicolumn{2}{l||}{$\vee$}&
\verb$\$&\multicolumn{2}{l||}{$\setminus$}&
\verb$-1-1-onto->$&\multicolumn{2}{l|}{$
  \raisebox{.5ex}{${\textstyle{\:}_{\mbox{\footnotesize\rm 1
  \tt -\rm 1}}}\atop{\textstyle{
  \longrightarrow}\atop{\textstyle{}^{\mbox{\footnotesize\rm onto}}}}$}
  $}\\ \hline
\verb$/\$&\multicolumn{2}{l||}{$\wedge$}&
\verb$u.$&\multicolumn{2}{l||}{$\cup$}&
\verb$`$&\multicolumn{2}{l|}{$`$}\\ \hline
\verb$et$&\multicolumn{2}{l||}{$\eta$}&
\verb$i^i$&\multicolumn{2}{l||}{$\cap$}&
\verb/h/&\multicolumn{2}{l|}{$ h$}\\ \hline
\verb$ze$&\multicolumn{2}{l||}{$\zeta$}&
\verb$(/)$&\multicolumn{2}{l||}{$\varnothing$}&
\verb/H/&\multicolumn{2}{l|}{$ H$}\\ \hline
\verb$A.$&\multicolumn{2}{l||}{$\forall$}&
\verb$P~$&\multicolumn{2}{l||}{${\cal P}$}&
\verb$rec$&\multicolumn{2}{l|}{${\rm rec}$}\\ \hline
\verb$var$&\multicolumn{2}{l||}{${\rm var}$}&
\verb$,$&\multicolumn{2}{l||}{$,$}&
\verb$+_o$&\multicolumn{2}{l|}{$+_o$}\\ \hline
\verb$x$&\multicolumn{2}{l||}{$x$}&
\verb$<.$&\multicolumn{2}{l||}{$\langle$}&
\verb$._o$&\multicolumn{2}{l|}{$\cdot_o$}\\ \hline
\verb$y$&\multicolumn{2}{l||}{$y$}&
\verb$>.$&\multicolumn{2}{l||}{$\rangle$}&
\verb$^_o$&\multicolumn{2}{l|}{$\hat{\ }_o$}\\ \hline
\verb$z$&\multicolumn{2}{l||}{$z$}&
\verb$U.$&\multicolumn{2}{l||}{$\bigcup$}&
\verb$1_o$&\multicolumn{2}{l|}{$1_o$}\\ \hline
\verb$w$&\multicolumn{2}{l||}{$w$}&
\verb$|^|$&\multicolumn{2}{l||}{$\bigcap$}&
\verb$Er$&\multicolumn{2}{l|}{${\rm Er}$}\\ \hline
\verb$v$&\multicolumn{2}{l||}{$v$}&
\verb/Tr/&\multicolumn{2}{l||}{${\rm Tr}$}&
\verb$[$&\multicolumn{2}{l|}{$[$}\\ \hline
\verb$E.$&\multicolumn{2}{l||}{$\exists$}&
\verb$E$&\multicolumn{2}{l||}{$E$}&
\verb$]$&\multicolumn{2}{l|}{$]$}\\ \hline
\verb$=$&\multicolumn{2}{l||}{$=$}&
\verb$I$&\multicolumn{2}{l||}{$I$}&
\verb$/.$&\multicolumn{2}{l|}{$\diagup$}\\ \hline
\verb$e.$&\multicolumn{2}{l||}{$\in$}&
\verb$Po$&\multicolumn{2}{l||}{${\rm Po}$}&
\verb$Q$&\multicolumn{2}{l|}{$Q$}\\ \hline
\verb$|$&\multicolumn{2}{l||}{$|$}&
\verb$Or$&\multicolumn{2}{l||}{${\rm Or}$}&
\verb/t/&\multicolumn{2}{l|}{$ t$}\\ \hline
\verb$u$&\multicolumn{2}{l||}{$u$}&
\verb/Fr/&\multicolumn{2}{l||}{${\rm Fr}$}&
\verb$s$&\multicolumn{2}{l|}{$s$}\\ \hline
\verb/f/&\multicolumn{2}{l||}{$ f$}&
\verb$We$&\multicolumn{2}{l||}{${\rm We}$}&
\verb$r$&\multicolumn{2}{l|}{$r$}\\ \hline
\verb$g$&\multicolumn{2}{l||}{$g$}&
\verb$Ord$&\multicolumn{2}{l||}{${\rm Ord}$}&
\verb$a$&\multicolumn{2}{l|}{$a$}\\ \hline
\verb$E!$&\multicolumn{2}{l||}{$\exists{!}$}&
\verb$On$&\multicolumn{2}{l||}{${\rm On}$}&
\verb$b$&\multicolumn{2}{l|}{$b$}\\ \hline
\verb$E*$&\multicolumn{2}{l||}{$\exists^\ast$}&
\verb$Lim$&\multicolumn{2}{l||}{${\rm Lim}$}&
\verb$c$&\multicolumn{2}{l|}{$c$}\\ \hline
\verb${$&\multicolumn{2}{l||}{$\{$}&
\verb$suc$&\multicolumn{2}{l||}{${\rm suc}$}&
\verb$d$&\multicolumn{2}{l|}{$d$}\\ \hline
\verb$}$&\multicolumn{2}{l||}{$\}$}&
\verb$om$&\multicolumn{2}{l||}{$\omega$}&
\verb$j$&\multicolumn{2}{l|}{$j$}\\ \hline
\verb$class$&\multicolumn{2}{l||}{${\rm class}$}&
\verb$X.$&\multicolumn{2}{l||}{$\times$}&
\verb$k$&\multicolumn{2}{l|}{$k$}\\ \hline
\verb$A$&\multicolumn{2}{l||}{$A$}&
\verb$`'$&\multicolumn{2}{l||}{$\breve{\ }$}&
\verb$m$&\multicolumn{2}{l|}{$m$}\\ \hline
\end{tabular}
\end{center}
}% End of \samepage
\newpage
{\samepage
\begin{center}
\begin{tabular}
{|l|lr||l|lr||l|lr|}
\hline
{\small Token}&\multicolumn{2}{l||}{\small Symbol}&
{\small Token}&\multicolumn{2}{l||}{\small Symbol}&
{\small Token}&\multicolumn{2}{l|}{\small Symbol}\\
 \hline \hline
\verb$n$&\multicolumn{2}{l||}{$n$}&
\verb$+_r$&\multicolumn{2}{l||}{$+_r$}&
 & &\\ \hline
\verb$q$&\multicolumn{2}{l||}{$q$}&
\verb$._r$&\multicolumn{2}{l||}{$\cdot_r$}&
 & &\\ \hline
\verb$J$&\multicolumn{2}{l||}{$J$}&
\verb$<_r$&\multicolumn{2}{l||}{$<_r$}&
 & &\\ \hline
\verb$K$&\multicolumn{2}{l||}{$K$}&
\verb$CC$&\multicolumn{2}{l||}{${\Bbb C}$}&
 & &\\ \hline
\verb$L$&\multicolumn{2}{l||}{$L$}&
\verb$RR$&\multicolumn{2}{l||}{${\Bbb R}$}&
 & &\\ \hline
\verb$M$&\multicolumn{2}{l||}{$M$}&
\verb$_10$&\multicolumn{2}{l||}{$_{10}$}&
 & &\\ \hline
\verb$N$&\multicolumn{2}{l||}{$N$}&
\verb$0$&\multicolumn{2}{l||}{$0$}&
 & &\\ \hline
\verb$W$&\multicolumn{2}{l||}{$W$}&
\verb$1$&\multicolumn{2}{l||}{$1$}&
 & &\\ \hline
\verb$X$&\multicolumn{2}{l||}{$X$}&
\verb$i$&\multicolumn{2}{l||}{$i$}&
 & &\\ \hline
\verb$Y$&\multicolumn{2}{l||}{$Y$}&
\verb$+$&\multicolumn{2}{l||}{$+$}&
 & &\\ \hline
\verb$Z$&\multicolumn{2}{l||}{$Z$}&
\verb$-$&\multicolumn{2}{l||}{$-$}&
 & &\\ \hline
\verb$N_i$&\multicolumn{2}{l||}{$N_i$}&
\verb$x.$&\multicolumn{2}{l||}{$\cdot$}&
 & &\\ \hline
\verb$+_i$&\multicolumn{2}{l||}{$+_i$}&
\verb$<$&\multicolumn{2}{l||}{$<$}&
 & &\\ \hline
\verb$._i$&\multicolumn{2}{l||}{$\cdot_i$}&
\verb$/$&\multicolumn{2}{l||}{$/$}&
 & &\\ \hline
\verb$<_i$&\multicolumn{2}{l||}{$<_i$}&
\verb$>$&\multicolumn{2}{l||}{$>$}&
 & &\\ \hline
\verb$+_pq$&\multicolumn{2}{l||}{$+_{pq}$}&
\verb$<_$&\multicolumn{2}{l||}{$\le$}&
 & &\\ \hline
\verb$._pq$&\multicolumn{2}{l||}{$\cdot_{pq}$}&
\verb$>_$&\multicolumn{2}{l||}{$\ge$}&
 & &\\ \hline
\verb$~_q$&\multicolumn{2}{l||}{$\sim_q$}&
\verb$NN$&\multicolumn{2}{l||}{${\Bbb N}$}&
 & &\\ \hline
\verb$N_q$&\multicolumn{2}{l||}{$N_q$}&
\verb$ZZ$&\multicolumn{2}{l||}{${\Bbb Z}$}&
 & &\\ \hline
\verb$1_q$&\multicolumn{2}{l||}{$1_q$}&
\verb$QQ$&\multicolumn{2}{l||}{${\Bbb Q}$}&
 & &\\ \hline
\verb$+_q$&\multicolumn{2}{l||}{$+_q$}&
\verb$2$&\multicolumn{2}{l||}{$2$}&
 & &\\ \hline
\verb$._q$&\multicolumn{2}{l||}{$\cdot_q$}&
\verb$3$&\multicolumn{2}{l||}{$3$}&
 & &\\ \hline
\verb$*_q$&\multicolumn{2}{l||}{$\ast_q$}&
\verb$4$&\multicolumn{2}{l||}{$4$}&
 & &\\ \hline
\verb$<_q$&\multicolumn{2}{l||}{$<_q$}&
\verb$5$&\multicolumn{2}{l||}{$5$}&
 & &\\ \hline
\verb$N_p$&\multicolumn{2}{l||}{$N_p$}&
\verb$6$&\multicolumn{2}{l||}{$6$}&
 & &\\ \hline
\verb$1_p$&\multicolumn{2}{l||}{$1_p$}&
\verb$7$&\multicolumn{2}{l||}{$7$}&
 & &\\ \hline
\verb$+_p$&\multicolumn{2}{l||}{$+_p$}&
\verb$8$&\multicolumn{2}{l||}{$8$}&
 & &\\ \hline
\verb$._p$&\multicolumn{2}{l||}{$\cdot_p$}&
\verb$9$&\multicolumn{2}{l||}{$9$}&
 & &\\ \hline
\verb$<_p$&\multicolumn{2}{l||}{$<_p$}&
\verb$.$&\multicolumn{2}{l||}{$.$}&
 & &\\ \hline
\verb$+_pr$&\multicolumn{2}{l||}{$+_{pr}$}&
\verb$digit$&\multicolumn{2}{l||}{${\rm digit}$}&
 & &\\ \hline
\verb$._pr$&\multicolumn{2}{l||}{$._{pr}$}&
\verb$digit-string$&\multicolumn{2}{l||}{$\mbox{\rm digit-string}$}&
 & &\\ \hline
\verb$~_r$&\multicolumn{2}{l||}{$\sim_r$}&
 & &&
 & &\\ \hline
\verb$N_r$&\multicolumn{2}{l||}{$N_r$}&
 & &&
 & &\\ \hline
\verb$0_r$&\multicolumn{2}{l||}{$0_r$}&
 & &&
 & &\\ \hline
\verb$1_r$&\multicolumn{2}{l||}{$1_r$}&
 & &&
 & &\\ \hline
\verb$-1_r$&\multicolumn{2}{l||}{$-1_r$}&
 & &&
 & &\\ \hline
\end{tabular}
\end{center}
}% End of \samepage
% End of metamathl.tex

\chapter{Compressed Proofs}
\label{compressed}\index{compressed proof}\index{proof!compressed}

The proofs in the {\tt set.mm} set theory database are stored in compressed
format for efficiency.  Normally you needn't concern yourself with the
compressed format, since you can display it with the usual proof display tools
in the Metamath program ({\tt show proof}\ldots) or convert it to the normal
RPN proof format described in the Section~\ref{proof} (with {\tt save proof}
{\em label} {\tt /normal}).  However for sake of completeness we describe the
format here and show how it maps to the normal RPN proof format.

A compressed proof, located between {\tt \$=} and {\tt \$.} keywords, consists
of a left parenthesis, a sequence of statement labels, a right parenthesis,
and a sequence of upper-case letters {\tt A} through {\tt Z} (with optional
white space between them).  White space must surround the parenthesis
and the labels.  The left parenthesis tells Metamath that a
compressed proof follows.  (A normal RPN proof consists of just a sequence of
labels, and a parenthesis is not a legal character in a label.)

The sequence of upper-case letters corresponds to a sequence of integers
with the following mapping.  Each integer corresponds to a proof step as
described later.
\begin{center}
  {\tt A} = 1 \\
  {\tt B} = 2 \\
   \ldots \\
  {\tt T} = 20 \\
  {\tt UA} = 21 \\
  {\tt UB} = 22 \\
   \ldots \\
  {\tt UT} = 40 \\
  {\tt VA} = 41 \\
  {\tt VB} = 42 \\
   \ldots \\
  {\tt YT} = 120 \\
  {\tt UUA} = 121 \\
   \ldots \\
  {\tt YYT} = 620 \\
  {\tt UUUA} = 621 \\
   etc.
\end{center}

In other words, {\tt A} through {\tt T} represent a least-significant digit
in base 20, and {\tt U} through {\tt Y} represent zero or more
most-significant digits in base 5.  By using a separate set of letters for
the least significant digit, the letter representation of numbers can be
concatenated unambiguously.

(In the design of the compressed proof format, only upper case letters,
as opposed to say all printable {\sc ascii} characters other than {\tt \$}, was
chosen to make the compressed proof a little less displeasing to the
eye, at the expense of a typical 20\% compression loss.  The base 20/base
5 grouping, as opposed to say base 19/base 6, was chosen by
experimentally determining the grouping that resulted in best typical
compression.)

The letter {\tt Z} identifies (tags) a proof step that is identical to one
that occurs later on in the proof; it helps shorten the proof by not requiring
that identical proof steps be proved over and over again (which happens often
when building wff's).  The {\tt Z} is placed immediately after the
least-significant digit (letters {\tt A} through {\tt T}) that ends the integer
corresponding to the step to later be referenced.

The integers that the upper-case letters correspond to are mapped to labels as
follows.  If the statement being proved has $m$ mandatory hypotheses, integers
1 through $m$ correspond to the labels of these hypotheses in the order shown
by the {\tt show statement} command, i.e., the RPN order\index{RPN
order} of the mandatory
hypotheses.  Integers $m+1$ through $m+n$ correspond to the labels enclosed in
the parentheses of the compressed proof, in the order that they appear, where
$n$ is the number of those labels.  Integers $m+n+1$ on up don't directly
correspond to statement labels but point to proof steps identified with the
letter {\tt Z}, so that these proof steps can be referenced later in the
proof.  Integer $m+n+1$ corresponds to the first step tagged with a {\tt Z},
$m+n+2$ to the second step tagged with a {\tt Z}, etc.  When the compressed
proof is converted to a normal proof, the entire subproof of a step tagged
with {\tt Z} replaces the reference to that step.

For efficiency, Metamath works with compressed proofs directly, without
converting them internally to normal proofs.  In addition to the usual
error-checking, an error message is given if (1) a label in the label list in
parentheses does not refer to a previous {\tt \$p} or {\tt \$a} statement or a
non-mandatory hypothesis of the statement being proved and (2) a proof step
tagged with {\tt Z} is referenced before the step tagged with the {\tt Z}.

Just as in a normal proof under development (Section~\ref{unknown}), any step
or subproof that is not yet known may be represented with a single {\tt ?}.
White space does not have to appear between the {\tt ?}\ and the upper-case
letters (or other {\tt ?}s) representing the remainder of the proof.


\chapter{Metamath's Formal System}\label{formalspec}\index{Metamath!as a formal
system}

\section{Introduction}

\begin{quote}
  {\em Perfection is when there is no longer anything more to take away.}
    \flushright\sc Antoine de
     Saint-Exupery\footnote{\cite[p.~3-25]{Campbell}}\\
\end{quote}\index{de Saint-Exupery, Antoine}

This appendix describes the theory behind the Metamath language in an abstract
way intended for mathematicians.  Specifically, we construct two
set-theo\-ret\-i\-cal objects:  a ``formal system'' (roughly, a set of syntax
rules, axioms, and logical rules) and its ``universe'' (roughly, the set of
theorems derivable in the formal system).  The Metamath computer language
provides us with a way to describe specific formal systems and, with the aid of
a proof provided by the user, to verify that given theorems
belong to their universes.

To understand this appendix, you need a basic knowledge of informal set theory.
It should be sufficient to understand, for example, Ch.\ 1 of Munkres' {\em
Topology} \cite{Munkres}\index{Munkres, James R.} or the
introductory set theory chapter
in many textbooks that introduce abstract mathematics. (Note that there are
minor notational differences among authors; e.g.\ Munkres uses $\subset$ instead
of our $\subseteq$ for ``subset.''  We use ``included in'' to mean ``a subset
of,'' and ``belongs to'' or ``is contained in'' to mean ``is an element of.'')
What we call a ``formal'' description here, unlike earlier, is actually an
informal description in the ordinary language of mathematicians.  However we
provide sufficient detail so that a mathematician could easily formalize it,
even in the language of Metamath itself if desired.  To understand the logic
examples at the end of this appendix, familiarity with an introductory book on
mathematical logic would be helpful.

\section{The Formal Description}

\subsection[Preliminaries]{Preliminaries\protect\footnotemark}%
\footnotetext{This section is taken mostly verbatim
from Tarski \cite[p.~63]{Tarski1965}\index{Tarski, Alfred}.}

By $\omega$ we denote the set of all natural numbers (non-negative integers).
Each natural number $n$ is identified with the set of all smaller numbers: $n =
\{ m | m < n \}$.  The formula $m < n$ is thus equivalent to the condition: $m
\in n$ and $m,n \in \omega$. In particular, 0 is the number zero and at the
same time the empty set $\varnothing$, $1=\{0\}$, $2=\{0,1\}$, etc. ${}^B A$
denotes the set of all functions on $B$ to $A$ (i.e.\ with domain $B$ and range
included in $A$).  The members of ${}^\omega A$ are what are called {\em simple
infinite sequences},\index{simple infinite sequence}
with all {\em terms}\index{term} in $A$.  In case $n \in \omega$, the
members of ${}^n A$ are referred to as {\em finite $n$-termed
sequences},\index{finite $n$-termed
sequence} again
with terms in $A$.  The consecutive terms (function values) of a finite or
infinite sequence $f$ are denoted by $f_0, f_1, \ldots ,f_n,\ldots$.  Every
finite sequence $f \in \bigcup _{n \in \omega} {}^n A$ uniquely determines the
number $n$ such that $f \in {}^n A$; $n$ is called the {\em
length}\index{length of a sequence ($"|\ "|$)} of $f$ and
is denoted by $|f|$.  $\langle a \rangle$ is the sequence $f$ with $|f|=1$ and
$f_0=a$; $\langle a,b \rangle$ is the sequence $f$ with $|f|=2$, $f_0=a$,
$f_1=b$; etc.  Given two finite sequences $f$ and $g$, we denote by $f\frown g$
their {\em concatenation},\index{concatenation} i.e., the
finite sequence $h$ determined by the
conditions:
\begin{eqnarray*}
& |h| = |f|+|g|;&  \\
& h_n = f_n & \mbox{\ for\ } n < |f|;  \\
& h_{|f|+n} = g_n & \mbox{\ for\ } n < |g|.
\end{eqnarray*}

\subsection{Constants, Variables, and Expressions}

A formal system has a set of {\em symbols}\index{symbol!in
a formal system} denoted
by $\mbox{\em SM}$.  A
precise set-theo\-ret\-i\-cal definition of this set is unimportant; a symbol
could be considered a primitive or atomic element if we wish.  We assume this
set is divided into two disjoint subsets:  a set $\mbox{\em CN}$ of {\em
constants}\index{constant!in a formal system} and a set $\mbox{\em VR}$ of
{\em variables}.\index{variable!in a formal system}  $\mbox{\em CN}$ and
$\mbox{\em VR}$ are each assumed to consist of countably many symbols which
may be arranged in finite or simple infinite sequences $c_0, c_1, \ldots$ and
$v_0, v_1, \ldots$ respectively, without repeating terms.  We will represent
arbitrary symbols by metavariables $\alpha$, $\beta$, etc.

{\footnotesize\begin{quotation}
{\em Comment.} The variables of our formal system usually correspond to what
are considered ``metavariables'' in descriptions of specific formal systems in
the literature.  Typically, when describing a specific formal system a book
will postulate a set of primitive objects called variables, then procede to
describe their properties using metavariables that range over them, never
mentioning again the actual variables themselves.  Our formal system does not
mention these primitive variable objects at all but deals directly with
metavariables from the start.  This is a subtle but key distinction you should
keep in mind, and it makes our definition of ``formal system'' somewhat
different from that typically found in the literature.
\end{quotation}}

Finite sequences all terms of which are symbols are called {\em
expressions}.\index{expression!in a formal system}  $\mbox{\em EX}$ is
the set of all expressions; thus
\begin{displaymath}
\mbox{\em EX} = \bigcup _{n \in \omega} {}^n \mbox{\em SM}.
\end{displaymath}

A {\em constant-prefixed expression}\index{constant-prefixed expression}
is a an expression of non-zero length
whose first term is a constant.  We denote the set of all constant-prefixed
expressions by $\mbox{\em EX}_C = \{ e \in \mbox{\em EX} | ( |e| > 0 \wedge
e_0 \in \mbox{\em CN} ) \}$.

A {\em constant-variable pair}\index{constant-variable pair}
is an expression of length 2 whose first term
is a constant and whose second term is a variable.  We denote the set of all
constant-variable pairs by $\mbox{\em EX}_2 = \{ e \in \mbox{\em EX}_C | ( |e|
= 2 \wedge e_1 \in \mbox{\em VR} ) \}$.


{\footnotesize\begin{quotation}
{\em Relationship to Metamath.} In general, the set $\mbox{\em SM}$
corresponds to the set of declared math symbols in a Metamath database, the
set $\mbox{\em CN}$ to those declared with {\tt \$c} statements, and the set
$\mbox{\em VR}$ to those declared with {\tt \$v} statements.  Of course a
Metamath database can only have a finite number of math symbols, whereas
formal systems in general can have an infinite number, although the number of
Metamath math symbols available is in principle unlimited.

The set $\mbox{\em EX}_C$ corresponds to the set of permissible expressions
for {\tt \$e}, {\tt \$a}, and {\tt \$p} statements.  The set $\mbox{\em EX}_2$
corresponds to the set of permissible expressions for {\tt \$f} statements.
\end{quotation}}

We denote by ${\cal V}(e)$ the set of all variables in an expression $e \in
\mbox{\em EX}$, i.e.\ the set of all $\alpha \in \mbox{\em VR}$ such that
$\alpha = e_n$ for some $n < |e|$.  We also denote (with abuse of notation) by
${\cal V}(E)$ the set of all variables in a collection of expressions $E
\subseteq \mbox{\em EX}$, i.e.\ $\bigcup _{e \in E} {\cal V}(e)$.


\subsection{Substitution}

Given a function $F$ from $\mbox{\em VR}$ to
$\mbox{\em EX}$, we
denote by $\sigma_{F}$ or just $\sigma$ the function from $\mbox{\em EX}$ to
$\mbox{\em EX}$ defined recursively for nonempty sequences by
\begin{eqnarray*}
& \sigma(<\alpha>) = F(\alpha) & \mbox{for\ } \alpha \in \mbox{\em VR}; \\
& \sigma(<\alpha>) = <\alpha> & \mbox{for\ } \alpha \not\in \mbox{\em VR}; \\
& \sigma(g \frown h) = \sigma(g) \frown
    \sigma(h) & \mbox{for\ } g,h \in \mbox{\em EX}.
\end{eqnarray*}
We also define $\sigma(\varnothing)=\varnothing$.  We call $\sigma$ a {\em
simultaneous substitution}\index{substitution!variable}\index{variable
substitution} (or just {\em substitution}) with {\em substitution
map}\index{substitution map} $F$.

We also denote (with abuse of notation) by $\sigma(E)$ a substitution on a
collection of expressions $E \subseteq \mbox{\em EX}$, i.e.\ the set $\{
\sigma(e) | e \in E \}$.  The collection $\sigma(E)$ may of course contain
fewer expressions than $E$ because duplicate expressions could result from the
substitution.

\subsection{Statements}

We denote by $\mbox{\em DV}$ (for ``distinct variables'') the set of all
unordered pairs $\{\alpha, \beta \} \subseteq \mbox{\em VR}$ such that $\alpha
\neq \beta$.

A {\em statement}\index{statement!in a formal system} is a
quadruple $\langle D,T,H,A \rangle$ such that
$D\subseteq \mbox{\em DV}$, $T\subseteq \mbox{\em EX}_2$, $H\subseteq
\mbox{\em EX}_C$, $A\in \mbox{\em EX}_C$, ${\cal V}(H\cup\{A\}) \subseteq
{\cal V}(T)$, and $\forall e,f\in T {\ } {\cal V}(e) \neq {\cal V}(f)$ (or
equivalently, $e_1 \ne f_1$). The terms of the quadruple are called {\em
distinct-variable restrictions},\index{disjoint-variable restriction!in a
formal system} {\em variable-type hypotheses},\index{variable-type
hypothesis!in a formal system} {\em logical hypotheses},\index{logical
hypothesis!in a formal system} and the {\em assertion}\index{assertion!in a
formal system} respectively.  We denote by $T_M$ ({\em mandatory variable-type
hypotheses}\index{mandatory variable-type hypothesis!in a formal system}) the
subset of $T$ such that ${\cal V}(T_M) ={\cal V}(H \cup \{A\})$.  We denote by
$D_M=\{\{\alpha,\beta\}\in D|\{\alpha,\beta\}\subseteq {\cal V}(T_M)\}$ the
{\em mandatory distinct-variable restrictions}\index{mandatory
disjoint-variable restriction!in a formal system} of the statement.  The set
of {\em mandatory hypotheses}\index{mandatory hypothesis!in a formal system}
is $T_M\cup H$.

{\footnotesize\begin{quotation}
{\em Comment.}  $T$ is a set of expressions, each of length 2, that associate
a set of constants (``variable types'') with a set of variables.  The
condition ${\cal V}(H\cup\{A\}) \subseteq {\cal V}(T) $
means that each variable occurring in a statement's logical
hypotheses or assertion must have an associated variable-type hypothesis or
``type declaration,'' in  analogy to a computer programming language, where a
variable must be declared to be say, a string or an integer.  The requirement
that $\forall e,f\in T \, e_1 \ne f_1$) means that each variable must be
associated with a unique constant designating its variable type; e.g., a
variable might be a ``wff'' or a ``set'' but not both.

Distinct-variable restrictions are used to specify what variable substitutions
are permissible to make for the statement to remain valid.  For example, in
the theorem scheme of set theory $\lnot\forall x\,x=y$ we may not substitute
the same variable for both $x$ and $y$.  On the other hand, the theorem scheme
$x=y\to y=x$ does not require that $x$ and $y$ be distinct, so we do not
require a distinct-variable restriction, although having one
would cause no harm other than making the scheme less general.

A mandatory variable-type hypothesis is one whose variable exists in a logical
hypothesis or the assertion.  A provable statement (defined below) may require
non-mandatory variable-type hypotheses that effectively introduce ``dummy''
variables for use in its proof.  Any number of dummy variables might
be required by a specific proof; indeed, it has shown by H.\
Andr\'{e}ka\index{Andr{\'{e}}ka, H.} \cite{Nemeti} that there is no finite
upper bound to the number of dummy variables needed to prove an arbitrary
theorem in first-order logic (with equality) having a fixed number $n>2$ of
individual variables.  (See also the Comment on p.~\pageref{nodd}.)
Axiomatic statements never need non-mandatory
variable-type hypotheses, since their assertions are given rather than proved,
but we allow them for convenience.
\end{quotation}}

{\footnotesize\begin{quotation}
{\em Relationship to Metamath.} A statement of a formal system corresponds to
an extended frame in a Metamath database (Section~\ref{frames}).  The
collections $D$, $T$, and $H$ correspond respectively to the {\tt \$d}, {\tt
\$f}, and {\tt \$e} statement collections in an extended frame.  The
expression $A$ corresponds to the {\tt \$a} (or {\tt \$p}) statement in an
extended frame.
\end{quotation}}

\subsection{Formal Systems}

A {\em formal system}\index{formal system} is a
triple $\langle \mbox{\em CN},\mbox{\em
VR},\Gamma\rangle$ where $\Gamma$ is a set of statements.  The members of
$\Gamma$ are called {\em axiomatic statements}.\index{axiomatic
statement!in a formal system}  Sometimes we will refer to a
formal system by just $\Gamma$ when $\mbox{\em CN}$ and $\mbox{\em VR}$ are
understood.

Given a formal system $\Gamma$, the {\em closure}\index{closure} of a statement
$\langle D,T,H,A \rangle$ is the smallest set $C$ of expressions
such that:
%\begin{enumerate}
%  \item $T\cup H\subseteq C$; and
%  \item If for some axiomatic statement
%    $\langle D',T',H',A' \rangle \in \Gamma_A$, for
%    some $E \subseteq C$, some $F \subseteq C-T$ (where ``-'' denotes
%    set difference), and some substitution
%    $\sigma$ we have
%    \begin{enumerate}
%       \item $\sigma(T'_M) = E$ (where, as above, the $M$ denotes the
%           mandatory variable-type hypotheses of $T^A$);
%       \item $\sigma(H') = F$;
%       \item for all $\{\alpha,\beta\}\in D^A$ and $\subseteq
%         {\cal V}(T'_M)$, for all $\gamma\in {\cal V}(\sigma(\langle \alpha
%         \rangle))$, and for all $\delta\in  {\cal V}(\sigma(\langle \beta
%         \rangle))$, we have $\{\gamma, \delta\} \in D$;
%   \end{enumerate}
%   then $\sigma(A') \in C$.
%\end{enumerate}
\begin{list}{}{\itemsep 0.0pt}
  \item[1.] $T\cup H\subseteq C$; and
  \item[2.] If for some axiomatic statement
    $\langle D',T',H',A' \rangle \in
       \Gamma$, for
    some $E \subseteq C$, and for some substitution
    $\sigma$ we have
    \begin{enumerate}
       \item[a.] $\sigma(T'_M \cup H') = E$ (where, as defined above, the
           subscript $M$ means mandatory); and
       \item[b.] for all $\{\alpha,\beta\}\in D_M'$, for all $\gamma\in
         {\cal V}(\sigma(\langle \alpha
         \rangle))$, and for all $\delta\in  {\cal V}(\sigma(\langle \beta
         \rangle))$, we have $\{\gamma, \delta\} \in D$;
   \end{enumerate}
   then $\sigma(A') \in C$.
\end{list}
The statement $\langle D,T,H,A
\rangle$ is {\em provable}\index{provable statement!in a formal
system} if $A\in C$ i.e.\ if its assertion belongs to its
closure.  The {\em universe}\index{universe of a formal system}
of a formal system is
the collection of all of its provable statements.  Note that the
set of axiomatic statements $\Gamma$ in a formal system is a subset of its
universe.

{\footnotesize\begin{quotation}
{\em Comment.} The first condition in the definition of closure simply says
that the hypotheses of the statement are in its closure.

Condition 2(a) says that a substitution exists that makes the
mandatory hypotheses of an axiomatic statement exactly match some members of
the closure.  This is what we explicitly demonstrate in a Metamath language
proof.

%Conditions 2(a) and 2(b) say that a substitution exists that makes the
%(mandatory) hypotheses of an axiomatic statement exactly match some members of
%the closure.  This is what we explicitly demonstrate with a Metamath language
%proof.
%
%The set of expressions $F$ in condition 2(b) excludes the variable-type
%hypotheses; this is done because non-mandatory variable-type hypotheses are
%effectively ``dropped'' as irrelevant whereas logical hypotheses must be
%retained to achieve a consistent logical system.

Condition 2(b) describes how distinct-variable restrictions in the axiomatic
statement must be met.  It means that after a substitution for two variables
that must be distinct, the resulting two expressions must either contain no
variables, or if they do, they may not have variables in common, and each pair
of any variables they do have, with one variable from each expression, must be
specified as distinct in the original statement.
\end{quotation}}

{\footnotesize\begin{quotation}
{\em Relationship to Metamath.} Axiomatic and provable statements in a formal
system correspond to the extended frames for {\tt \$a} and {\tt \$p} statements
respectively in a Metamath database.  The set of axiomatic statements are a
subset of the set of provable statements in a formal system, although in a
Metamath database a {\tt \$a} statement is distinguished by not having a
proof.  A Metamath language proof for a {\tt \$p} statement tells the computer
how to explicitly construct a series of members of the closure ultimately
leading to a demonstration that the assertion
being proved is in the closure.  The actual closure typically contains
an infinite number of expressions.  A formal system itself does not have
an explicit object called a ``proof'' but rather the existence of a proof
is indicated indirectly by membership of an assertion in a provable
statement's closure.  We do this to make the formal system easier
to describe in the language of set theory.

We also note that once established as provable, a statement may be considered
to acquire the same status as an axiomatic statement, because if the set of
axiomatic statements is extended with a provable statement, the universe of
the formal system remains unchanged (provided that $\mbox{\em VR}$ is infinite and that
we regard as equivalent those provable statements differing only in their
non-mandatory hypotheses and non-mandatory distinct-variable restrictions).
In practice, this means we can build a hierarchy of provable statements to
more efficiently establish additional provable statements.  This is
what we do in Metamath when we allow proofs to reference previous
{\tt \$p} statements as well as previous {\tt \$a} statements.
\end{quotation}}

\section{Examples of Formal Systems}

{\footnotesize\begin{quotation}
{\em Relationship to Metamath.} The examples in this section, except Example~2,
are for the most part exact equivalents of the development in the set
theory database {\tt set.mm}.  You may want to compare Examples~1, 3, and 5
to Section~\ref{metaaxioms}, Example 4 to Sections~\ref{metadefprop} and
\ref{metadefpred}, and Example 6 to
Section~\ref{setdefinitions}.\label{exampleref}
\end{quotation}}

\subsection{Example~1---Propositional Calculus}\index{propositional calculus}

Classical propositional calculus can be described by the following formal
system.  We assume the set of variables is infinite.  Rather than denoting the
constants and variables by $c_0, c_1, \ldots$ and $v_0, v_1, \ldots$, for
readability we will instead use more conventional symbols, with the
understanding of course that they denote distinct primitive objects.
Also for readability we may omit commas between successive terms of a
sequence; thus $\langle \mbox{wff\ } \varphi\rangle$ denotes
$\langle \mbox{wff}, \varphi\rangle$.

Let
\begin{itemize}
  \item[] $\mbox{\em CN}=\{\mbox{wff}, \vdash, \to, \lnot, (,)\}$
  \item[] $\mbox{\em VR}=\{\varphi,\psi,\chi,\ldots\}$
  \item[] $T = \{\langle \mbox{wff\ } \varphi\rangle,
             \langle \mbox{wff\ } \psi\rangle,
             \langle \mbox{wff\ } \chi\rangle,\ldots\}$, i.e.\ all
             expressions of length 2 whose first member is $\mbox{\rm wff}$
             and whose second member belongs to $\mbox{\em VR}$.\footnote{For
convenience we let $T$ be an infinite set; the definition of a statement
permits this in principle.  Since a Metamath source file has a finite size, in
practice we must of course use appropriate finite subsets of this $T$,
specifically ones containing at least the mandatory variable-type
hypotheses.  Similarly, in the source file we introduce new variables as
required, with the understanding that a potentially infinite number of
them are available.}
\noindent Then $\Gamma$ consists of the following statements:
    \begin{itemize}
      \item[] $\langle\varnothing,T,\varnothing,
               \langle \mbox{wff\ }(\varphi\to\psi)\rangle\rangle$
      \item[] $\langle\varnothing,T,\varnothing,
               \langle \mbox{wff\ }\lnot\varphi\rangle\rangle$
      \item[] $\langle\varnothing,T,\varnothing,
               \langle \vdash(\varphi\to(\psi\to\varphi))
               \rangle\rangle$
      \item[] $\langle\varnothing,T,
               \varnothing,
               \langle \vdash((\varphi\to(\psi\to\chi))\to
               ((\varphi\to\psi)\to(\varphi\to\chi)))
               \rangle\rangle$
      \item[] $\langle\varnothing,T,
               \varnothing,
               \langle \vdash((\lnot\varphi\to\lnot\psi)\to
               (\psi\to\varphi))\rangle\rangle$
      \item[] $\langle\varnothing,T,
               \{\langle\vdash(\varphi\to\psi)\rangle,
                 \langle\vdash\varphi\rangle\},
               \langle\vdash\psi\rangle\rangle$
    \end{itemize}
\end{itemize}

We call the members of $\mbox{\em VR}$ {\em wff variables} or (in the context
of first-order logic which we will describe shortly) {\em wff metavariables}.
Note that the symbols $\phi$, $\psi$, etc.\ denote actual specific members of
$\mbox{\em VR}$; they are not metavariables of our expository language (which
we denote with $\alpha$, $\beta$, etc.) but are instead (meta)constant symbols
(members of $\mbox{\em SM}$) from the point of view of our expository
language.  The equivalent system of propositional calculus described in
\cite{Tarski1965} also uses the symbols $\phi$, $\psi$, etc.\ to denote wff
metavariables, but in \cite{Tarski1965} unlike here those are metavariables of
the expository language and not primitive symbols of the formal system.

The first two statements define wffs: if $\varphi$ and $\psi$ are wffs, so is
$(\varphi \to \psi)$; if $\varphi$ is a wff, so is $\lnot\varphi$. The next
three are the axioms of propositional calculus: if $\varphi$ and $\psi$ are
wffs, then $\vdash (\varphi \to (\psi \to \varphi))$ is an (axiomatic)
theorem; etc. The
last is the rule of modus ponens: if $\varphi$ and $\psi$ are wffs, and
$\vdash (\varphi\to\psi)$ and $\vdash \varphi$ are theorems, then $\vdash
\psi$ is a theorem.

The correspondence to ordinary propositional calculus is as follows.  We
consider only provable statements of the form $\langle\varnothing,
T,\varnothing,A\rangle$ with $T$ defined as above.  The first term of the
assertion $A$ of any such statement is either ``wff'' or ``$\vdash$''.  A
statement for which first term is ``wff'' is a {\em wff} of propositional
calculus, and one where the first term is ``$\vdash$'' is a {\em
theorem (scheme)} of propositional calculus.

The universe of this formal system also contains many other provable
statements.  Those with distinct-variable restrictions are irrelevant because
propositional calculus has no constraints on substitutions.  Those that have
logical hypotheses we call {\em inferences}\index{inference} when
the logical hypotheses are of the form
$\langle\vdash\rangle\frown w$ where $w$ is a wff (with the leading constant
term ``wff'' removed).  Inferences (other than the modus ponens rule) are not a
proper part of propositional calculus but are convenient to use when building a
hierarchy of provable statements.  A provable statement with a nonsense
hypothesis such as $\langle \to,\vdash,\lnot\rangle$, and this same expression
as its assertion, we consider irrelevant; no use can be made of it in
proving theorems, since there is no way to eliminate the nonsense hypothesis.

{\footnotesize\begin{quotation}
{\em Comment.} Our use of parentheses in the definition of a wff illustrates
how axiomatic statements should be carefully stated in a way that
ties in unambiguously with the substitutions allowed by the formal system.
There are many ways we could have defined wffs---for example, Polish
prefix notation would have allowed us to omit parentheses entirely, at
the expense of readability---but we must define them in a way that is
unambiguous.  For example, if we had omitted parentheses from the
definition of $(\varphi\to \psi)$, the wff $\lnot\varphi\to \psi$ could
be interpreted as either $\lnot(\varphi\to\psi)$ or $(\lnot\varphi\to\psi)$
and would have allowed us to prove nonsense.  Note that there is no
concept of operator binding precedence built into our formal system.
\end{quotation}}

\subsection{Example~2---Predicate Calculus with Equality}\index{predicate
calculus}

Here we extend Example~1 to include predicate calculus with equality,
illustrating the use of distinct-variable restrictions.  This system is the
same as Tarski's system ${\frak S}_2$ in \cite{Tarski1965} (except that the
axioms of propositional calculus are different but equivalent, and a redundant
axiom is omitted).  We extend $\mbox{\em CN}$ with the constants
$\{\mbox{var},\forall,=\}$.  We extend $\mbox{\em VR}$ with an infinite set of
{\em individual metavariables}\index{individual
metavariable} $\{x,y,z,\ldots\}$ and denote this subset
$\mbox{\em Vr}$.

We also join to $\mbox{\em CN}$ a possibly infinite set $\mbox{\em Pr}$ of {\em
predicates} $\{R,S,\ldots\}$.  We associate with $\mbox{\em Pr}$ a function
$\mbox{rnk}$ from $\mbox{\em Pr}$ to $\omega$, and for $\alpha\in \mbox{\em
Pr}$ we call $\mbox{rnk}(\alpha)$ the {\em rank} of the predicate $\alpha$,
which is simply the number of ``arguments'' that the predicate has.  (Most
applications of predicate calculus will have a finite number of predicates;
for example, set theory has the single two-argument or binary predicate $\in$,
which is usually written with its arguments surrounding the predicate symbol
rather than with the prefix notation we will use for the general case.)  As a
device to facilitate our discussion, we will let $\mbox{\em Vs}$ be any fixed
one-to-one function from $\omega$ to $\mbox{\em Vr}$; thus $\mbox{\em Vs}$ is
any simple infinite sequence of individual metavariables with no repeating
terms.

In this example we will not include the function symbols that are often part of
formalizations of predicate calculus.  Using metalogical arguments that are
beyond the scope of our discussion, it can be shown that our formalization is
equivalent when functions are introduced via appropriate definitions.

We extend the set $T$ defined in Example~1 with the expressions
$\{\langle \mbox{var\ } x\rangle,$ $ \langle \mbox{var\ } y\rangle, \langle
\mbox{var\ } z\rangle,\ldots\}$.  We extend the $\Gamma$ above with this
extended $T$ and also with the following axiomatic statements:
\begin{list}{}{\itemsep 0.0pt}
      \item[] $\langle\varnothing,T,\varnothing,
               \langle \mbox{wff\ }\forall x\,\varphi\rangle\rangle$
      \item[] $\langle\varnothing,T,\varnothing,
               \langle \mbox{wff\ }x=y\rangle\rangle$
      \item[] $\langle\varnothing,T,
               \{\langle\vdash\varphi\rangle\},
               \langle\vdash\forall x\,\varphi\rangle\rangle$
      \item[] $\langle\varnothing,T,\varnothing,
               \langle \vdash((\forall x(\varphi\to\psi)
                  \to(\forall x\,\varphi\to\forall x\,\psi))
               \rangle\rangle$
      \item[] $\langle\{\{x,\varphi\}\},T,\varnothing,
               \langle \vdash(\varphi\to\forall x\,\varphi)
               \rangle\rangle$
      \item[] $\langle\{\{x,y\}\},T,\varnothing,
               \langle \vdash\lnot\forall x\lnot x=y
               \rangle\rangle$
      \item[] $\langle\varnothing,T,\varnothing,
               \langle \vdash(x=z
                  \to(x=y\to z=y))
               \rangle\rangle$
      \item[] $\langle\varnothing,T,\varnothing,
               \langle \vdash(y=z
                  \to(x=y\to x=z))
               \rangle\rangle$
\end{list}
These are the axioms not involving predicate symbols. The first two statements
extend the definition of a wff.  The third is the rule of generalization.  The
fifth states, in effect, ``For a wff $\varphi$ and variable $x$,
$\vdash(\varphi\to\forall x\,\varphi)$, provided that $x$ does not occur in
$\varphi$.''  The sixth states ``For a variables $x$ and $y$,
$\vdash\lnot\forall x\lnot x = y$, provided that $x$ and $y$ are distinct.''
(This proviso is not necessary but was included by Tarski to
weaken the axiom and still show that the system is logically complete.)

Finally, for each predicate symbol $\alpha\in \mbox{\em Pr}$, we add to
$\Gamma$ the following axiomatic statement that extends the definition of wff:
\begin{displaymath}
    \langle\varnothing,T,\varnothing,
            \langle \mbox{wff},\alpha\rangle\
            \frown \mbox{\em Vs}\restriction\mbox{rnk}(\alpha)\rangle
\end{displaymath}
and for each $\alpha\in \mbox{\em Pr}$ and each $n < \mbox{rnk}(\alpha)$
we add to $\Gamma$ the following equality axiom:
\begin{eqnarray*}
    \lefteqn{\langle\varnothing,T,\varnothing,
            \langle
      \vdash,(,\mbox{\em Vs}_n,=,\mbox{\em Vs}_{\mbox{rnk}(\alpha)},\to,
            (,\alpha\rangle\frown \mbox{\em Vs}\restriction\mbox{rnk}(\alpha)} \\
  & & \frown
            \langle\to,\alpha\rangle\frown \mbox{\em Vs}\restriction n\frown
            \langle \mbox{\em Vs}_{\mbox{rnk}(\alpha)}\rangle \\
 & & \frown
            \mbox{\em Vs}\restriction(\mbox{rnk}(\alpha)\setminus(n+1))\frown
            \langle),)\rangle\rangle
\end{eqnarray*}
where $\restriction$ denotes function domain restriction and $\setminus$
denotes set difference.  Recall that a subscript on $\mbox{\em Vs}$
denotes one of its terms.  (In the above two axiom sets commas are placed
between successive terms of sequences to prevent ambiguity, and if you examine
them with care you will be able to distinguish those parentheses that denote
constant symbols from those of our expository language that delimit function
arguments.  Although it might have been better to use boldface for our
primitive symbols, unfortunately boldface was not available for all characters
on the \LaTeX\ system used to typeset this text.)  These seemingly forbidding
axioms can be understood by analogy to concatenation of substrings in a
computer language.  They are actually relatively simple for each specific case
and will become clearer by looking at the special case of a binary predicate
$\alpha = R$ where $\mbox{rnk}(R)=2$.  Letting $\mbox{\em Vs}$ be the sequence
$\langle x,y,z,\ldots\rangle$, the axioms we would add to $\Gamma$ for this
case would be the wff extension and two equality axioms:
\begin{list}{}{\itemsep 0.0pt}
      \item[] $\langle\varnothing,T,\varnothing,
               \langle \mbox{wff\ }R x y\rangle\rangle$
      \item[] $\langle\varnothing,T,\varnothing,
               \langle \vdash(x=z
                  \to(R x y \to R z y))
               \rangle\rangle$
      \item[] $\langle\varnothing,T,\varnothing,
               \langle \vdash(y=z
                  \to(R x y \to R x z))
               \rangle\rangle$
\end{list}
Study these carefully to see how the general axioms above evaluate to
them.  In practice, typically only a few special cases such as this would be
needed, and in any case the Metamath language will only permit us to describe
a finite number of predicates, as opposed to the infinite number permitted by
the formal system.  (If an infinite number should be needed for some reason,
we could not define the formal system directly in the Metamath language but
could instead define it metalogically under set theory as we
do in this appendix, and only the underlying set theory, with its single
binary predicate, would be defined directly in the Metamath language.)


{\footnotesize\begin{quotation}
{\em Comment.}  As we noted earlier, the specific variables denoted by the
symbols $x,y,z,\ldots\in \mbox{\em Vr}\subseteq \mbox{\em VR}\subseteq
\mbox{\em SM}$ in Example~2 are not the actual variables of ordinary predicate
calculus but should be thought of as metavariables ranging over them.  For
example, a distinct-variable restriction would be meaningless for actual
variables of ordinary predicate calculus since two different actual variables
are by definition distinct.  And when we talk about an arbitrary
representative $\alpha\in \mbox{\em Vr}$, $\alpha$ is a metavariable (in our
expository language) that ranges over metavariables (which are primitives of
our formal system) each of which ranges over the actual individual variables
of predicate calculus (which are never mentioned in our formal system).
\end{quotation}}

\subsection{Free Variables and Proper Substitution}\index{free variable}
\index{proper substitution}\index{substitution!proper}

In the system of Example~2, there are no primitive notions of free variable
and proper substitution.  Tarski \cite{Tarski1965} shows that this system is
logically equivalent to the more typical textbook systems that do have these
primitive notions, if we introduce these notions with appropriate definitions
and metalogic.  We could also define axioms for such systems directly,
although the recursive definitions of free variable and proper substitution
would be messy and awkward to work with.  Instead, we mention two devices that
can be used in practice to mimic these notions.  (1) Instead of introducing
special notation to express (as a logical hypothesis) ``where $x$ is not free
in $\varphi$'' we can use the logical hypothesis $\vdash(\varphi\to\forall
x\,\varphi)$.\label{effectivelybound}\index{effectively
not free}\footnote{This is a slightly weaker requirement than ``where $x$ is
not free in $\varphi$.''  If we let $\varphi$ be $x=x$, we have the theorem
$(x=x\to\forall x\,x=x)$ which satisfies the hypothesis, even though $x$ is
free in $x=x$ .  In a case like this we say that $x$ is {\em effectively not
free}\index{effectively not free} in $x=x$, since $x=x$ is logically
equivalent to $\forall x\,x=x$ in which $x$ is bound.} (2) It can be shown
that the wff $((x=y\to\varphi)\wedge\exists x(x=y\wedge\varphi))$ (with the
usual definitions of $\wedge$ and $\exists$; see Example~4 below) is logically
equivalent to ``the wff that results from proper substitution of $y$ for $x$
in $\varphi$.''  This works whether or not $x$ and $y$ are distinct.

\subsection{Metalogical Completeness}\index{metalogical completeness}

In the system of Example~2, the
following are provable statements:
\begin{eqnarray*}
      & \langle\{\{x,y\}\},T,\varnothing,
               \langle \vdash\lnot\forall x\lnot x=y
               \rangle\rangle & \\
     &  \langle\varnothing,T,\varnothing,
               \langle \vdash\lnot\forall x\lnot x=x
               \rangle\rangle &
\end{eqnarray*}
whereas the following statement is not to my knowledge provable (but
in any case we will pretend it's not for sake of illustration) :
\begin{eqnarray*}
     &  \langle\varnothing,T,\varnothing,
               \langle \vdash\lnot\forall x\lnot x=y
               \rangle\rangle &
\end{eqnarray*}
In other words, we can prove ``$\lnot\forall x\lnot x=y$ where $x$ and $y$ are
distinct'' and separately prove ``$\lnot\forall x\lnot x=x$'', but we can't
prove the combined general case ``$\lnot\forall x\lnot x=y$'' that has no
proviso.  Now this does not compromise logical completeness, because the
variables are really metavariables and the two provable cases together cover
all possible cases.  The third case can be considered a metatheorem whose
direct proof, using the system of Example~2, lies outside the capability of the
formal system.

Also, in the system of Example~2 the following statement is not to my
knowledge provable (again, a conjecture that we will pretend to be the case):
\begin{eqnarray*}
     & \langle\varnothing,T,\varnothing,
               \langle \vdash(\forall x\, \varphi\to\varphi)
               \rangle\rangle &
\end{eqnarray*}
Instead, we can only prove specific cases of $\varphi$ involving individual
metavariables, and by induction on formula length, prove as a metatheorem
outside of our formal system the general statement above.  The details of this
proof are found in \cite{Kalish}.

There does, however, exist a system of predicate calculus in which all such
``simple metatheorems'' as those above can be proved directly, and we present
it in Example~3. A {\em simple metatheorem}\index{simple metatheorem}
is any statement of the formal
system of Example~2 where all distinct variable restrictions consist of either
two individual metavariables or an individual metavariable and a wff
metavariable, and which is provable by combining cases outside the system as
above.  A system is {\em metalogically complete}\index{metalogical
completeness} if all of its simple
metatheorems are (directly) provable statements. The precise definition of
``simple metatheorem'' and the proof of the ``metalogical completeness'' of
Example~3 is found in Remark 9.6 and Theorem 9.7 of \cite{Megill}.\index{Megill,
Norman}

\subsection{Example~3---Metalogically Complete Predicate
Calculus with
Equality}

For simplicity we will assume there is one binary predicate $R$;
this system suffices for set theory, where the $R$ is of course the $\in$
predicate.  We label the axioms as they appear in \cite{Megill}.  This
system is logically equivalent to that of Example~3 (when the latter is
restricted to this single binary predicate) but is also metalogically
complete.\index{metalogical completeness}

Let
\begin{itemize}
  \item[] $\mbox{\em CN}=\{\mbox{wff}, \mbox{var}, \vdash, \to, \lnot, (,),\forall,=,R\}$.
  \item[] $\mbox{\em VR}=\{\varphi,\psi,\chi,\ldots\}\cup\{x,y,z,\ldots\}$.
  \item[] $T = \{\langle \mbox{wff\ } \varphi\rangle,
             \langle \mbox{wff\ } \psi\rangle,
             \langle \mbox{wff\ } \chi\rangle,\ldots\}\cup
       \{\langle \mbox{var\ } x\rangle, \langle \mbox{var\ } y\rangle, \langle
       \mbox{var\ }z\rangle,\ldots\}$.

\noindent Then
  $\Gamma$ consists of the following statements:
    \begin{itemize}
      \item[] $\langle\varnothing,T,\varnothing,
               \langle \mbox{wff\ }(\varphi\to\psi)\rangle\rangle$
      \item[] $\langle\varnothing,T,\varnothing,
               \langle \mbox{wff\ }\lnot\varphi\rangle\rangle$
      \item[] $\langle\varnothing,T,\varnothing,
               \langle \mbox{wff\ }\forall x\,\varphi\rangle\rangle$
      \item[] $\langle\varnothing,T,\varnothing,
               \langle \mbox{wff\ }x=y\rangle\rangle$
      \item[] $\langle\varnothing,T,\varnothing,
               \langle \mbox{wff\ }Rxy\rangle\rangle$
      \item[(C1$'$)] $\langle\varnothing,T,\varnothing,
               \langle \vdash(\varphi\to(\psi\to\varphi))
               \rangle\rangle$
      \item[(C2$'$)] $\langle\varnothing,T,
               \varnothing,
               \langle \vdash((\varphi\to(\psi\to\chi))\to
               ((\varphi\to\psi)\to(\varphi\to\chi)))
               \rangle\rangle$
      \item[(C3$'$)] $\langle\varnothing,T,
               \varnothing,
               \langle \vdash((\lnot\varphi\to\lnot\psi)\to
               (\psi\to\varphi))\rangle\rangle$
      \item[(C4$'$)] $\langle\varnothing,T,
               \varnothing,
               \langle \vdash(\forall x(\forall x\,\varphi\to\psi)\to
                 (\forall x\,\varphi\to\forall x\,\psi))\rangle\rangle$
      \item[(C5$'$)] $\langle\varnothing,T,
               \varnothing,
               \langle \vdash(\forall x\,\varphi\to\varphi)\rangle\rangle$
      \item[(C6$'$)] $\langle\varnothing,T,
               \varnothing,
               \langle \vdash(\forall x\forall y\,\varphi\to
                 \forall y\forall x\,\varphi)\rangle\rangle$
      \item[(C7$'$)] $\langle\varnothing,T,
               \varnothing,
               \langle \vdash(\lnot\varphi\to\forall x\lnot\forall x\,\varphi
                 )\rangle\rangle$
      \item[(C8$'$)] $\langle\varnothing,T,
               \varnothing,
               \langle \vdash(x=y\to(x=z\to y=z))\rangle\rangle$
      \item[(C9$'$)] $\langle\varnothing,T,
               \varnothing,
               \langle \vdash(\lnot\forall x\, x=y\to(\lnot\forall x\, x=z\to
                 (y=z\to\forall x\, y=z)))\rangle\rangle$
      \item[(C10$'$)] $\langle\varnothing,T,
               \varnothing,
               \langle \vdash(\forall x(x=y\to\forall x\,\varphi)\to
                 \varphi))\rangle\rangle$
      \item[(C11$'$)] $\langle\varnothing,T,
               \varnothing,
               \langle \vdash(\forall x\, x=y\to(\forall x\,\varphi
               \to\forall y\,\varphi))\rangle\rangle$
      \item[(C12$'$)] $\langle\varnothing,T,
               \varnothing,
               \langle \vdash(x=y\to(Rxz\to Ryz))\rangle\rangle$
      \item[(C13$'$)] $\langle\varnothing,T,
               \varnothing,
               \langle \vdash(x=y\to(Rzx\to Rzy))\rangle\rangle$
      \item[(C15$'$)] $\langle\varnothing,T,
               \varnothing,
               \langle \vdash(\lnot\forall x\, x=y\to(x=y\to(\varphi
                 \to\forall x(x=y\to\varphi))))\rangle\rangle$
      \item[(C16$'$)] $\langle\{\{x,y\}\},T,
               \varnothing,
               \langle \vdash(\forall x\, x=y\to(\varphi\to\forall x\,\varphi)
                 )\rangle\rangle$
      \item[(C5)] $\langle\{\{x,\varphi\}\},T,\varnothing,
               \langle \vdash(\varphi\to\forall x\,\varphi)
               \rangle\rangle$
      \item[(MP)] $\langle\varnothing,T,
               \{\langle\vdash(\varphi\to\psi)\rangle,
                 \langle\vdash\varphi\rangle\},
               \langle\vdash\psi\rangle\rangle$
      \item[(Gen)] $\langle\varnothing,T,
               \{\langle\vdash\varphi\rangle\},
               \langle\vdash\forall x\,\varphi\rangle\rangle$
    \end{itemize}
\end{itemize}

While it is known that these axioms are ``metalogically complete,'' it is
not known whether they are independent (i.e.\ none is
redundant) in the metalogical sense; specifically, whether any axiom (possibly
with additional non-mandatory distinct-variable restrictions, for use with any
dummy variables in its proof) is provable from the others.  Note that
metalogical independence is a stronger requirement than independence in the
usual logical sense.  Not all of the above axioms are logically independent:
for example, C9$'$ can be proved as a metatheorem from the others, outside the
formal system, by combining the possible cases of distinct variables.

\subsection{Example~4---Adding Definitions}\index{definition}
There are several ways to add definitions to a formal system.  Probably the
most proper way is to consider definitions not as part of the formal system at
all but rather as abbreviations that are part of the expository metalogic
outside the formal system.  For convenience, though, we may use the formal
system itself to incorporate definitions, adding them as axiomatic extensions
to the system.  This could be done by adding a constant representing the
concept ``is defined as'' along with axioms for it. But there is a nicer way,
at least in this writer's opinion, that introduces definitions as direct
extensions to the language rather than as extralogical primitive notions.  We
introduce additional logical connectives and provide axioms for them.  For
systems of logic such as Examples 1 through 3, the additional axioms must be
conservative in the sense that no wff of the original system that was not a
theorem (when the initial term ``wff'' is replaced by ``$\vdash$'' of course)
becomes a theorem of the extended system.  In this example we extend Example~3
(or 2) with standard abbreviations of logic.

We extend $\mbox{\em CN}$ of Example~3 with new constants $\{\leftrightarrow,
\wedge,\vee,\exists\}$, corresponding to logical equivalence,\index{logical
equivalence ($\leftrightarrow$)}\index{biconditional ($\leftrightarrow$)}
conjunction,\index{conjunction ($\wedge$)} disjunction,\index{disjunction
($\vee$)} and the existential quantifier.\index{existential quantifier
($\exists$)}  We extend $\Gamma$ with the axiomatic statements:
\begin{list}{}{\itemsep 0.0pt}
      \item[] $\langle\varnothing,T,\varnothing,
               \langle \mbox{wff\ }(\varphi\leftrightarrow\psi)\rangle\rangle$
      \item[] $\langle\varnothing,T,\varnothing,
               \langle \mbox{wff\ }(\varphi\vee\psi)\rangle\rangle$
      \item[] $\langle\varnothing,T,\varnothing,
               \langle \mbox{wff\ }(\varphi\wedge\psi)\rangle\rangle$
      \item[] $\langle\varnothing,T,\varnothing,
               \langle \mbox{wff\ }\exists x\, \varphi\rangle\rangle$
  \item[] $\langle\varnothing,T,\varnothing,
     \langle\vdash ( ( \varphi \leftrightarrow \psi ) \to
     ( \varphi \to \psi ) )\rangle\rangle$
  \item[] $\langle\varnothing,T,\varnothing,
     \langle\vdash ((\varphi\leftrightarrow\psi)\to
    (\psi\to\varphi))\rangle\rangle$
  \item[] $\langle\varnothing,T,\varnothing,
     \langle\vdash ((\varphi\to\psi)\to(
     (\psi\to\varphi)\to(\varphi
     \leftrightarrow\psi)))\rangle\rangle$
  \item[] $\langle\varnothing,T,\varnothing,
     \langle\vdash (( \varphi \wedge \psi ) \leftrightarrow\neg ( \varphi
     \to \neg \psi )) \rangle\rangle$
  \item[] $\langle\varnothing,T,\varnothing,
     \langle\vdash (( \varphi \vee \psi ) \leftrightarrow (\neg \varphi
     \to \psi )) \rangle\rangle$
  \item[] $\langle\varnothing,T,\varnothing,
     \langle\vdash (\exists x \,\varphi\leftrightarrow
     \lnot \forall x \lnot \varphi)\rangle\rangle$
\end{list}
The first three logical axioms (statements containing ``$\vdash$'') introduce
and effectively define logical equivalence, ``$\leftrightarrow$''.  The last
three use ``$\leftrightarrow$'' to effectively mean ``is defined as.''

\subsection{Example~5---ZFC Set Theory}\index{ZFC set theory}

Here we add to the system of Example~4 the axioms of Zermelo-Fraenkel set
theory with Choice.  For convenience we make use of the
definitions in Example~4.

In the $\mbox{\em CN}$ of Example~4 (which extends Example~3), we replace the symbol $R$
with the symbol $\in$.  We remove from $\Gamma$ of Example~4 the three
axiomatic statements containing $R$ and replace them with the following:
\begin{list}{}{\itemsep 0.0pt}
      \item[] $\langle\varnothing,T,\varnothing,
               \langle \mbox{wff\ }x\in y\rangle\rangle$
      \item[] $\langle\varnothing,T,
               \varnothing,
               \langle \vdash(x=y\to(x\in z\to y\in z))\rangle\rangle$
      \item[] $\langle\varnothing,T,
               \varnothing,
               \langle \vdash(x=y\to(z\in x\to z\in y))\rangle\rangle$
\end{list}
Letting $D=\{\{\alpha,\beta\}\in \mbox{\em DV}\,|\alpha,\beta\in \mbox{\em
Vr}\}$ (in other words all individual variables must be distinct), we extend
$\Gamma$ with the ZFC axioms, called
\index{Axiom of Extensionality}
\index{Axiom of Replacement}
\index{Axiom of Union}
\index{Axiom of Power Sets}
\index{Axiom of Regularity}
\index{Axiom of Infinity}
\index{Axiom of Choice}
Extensionality, Replacement, Union, Power
Set, Regularity, Infinity, and Choice:
\begin{list}{}{\itemsep 0.0pt}
      \item[Ext] $\langle D,T,
               \varnothing,
               \langle\vdash (\forall x(x\in y\leftrightarrow x \in z)\to y
               =z) \rangle\rangle$
      \item[Rep] $\langle D,T,
               \varnothing,
               \langle\vdash\exists x ( \exists y \forall z (\varphi \to z = y
                        ) \to
                        \forall z ( z \in x \leftrightarrow \exists x ( x \in
                        y \wedge \forall y\,\varphi ) ) )\rangle\rangle$
      \item[Un] $\langle D,T,
               \varnothing,
               \langle\vdash \exists x \forall y ( \exists x ( y \in x \wedge
               x \in z ) \to y \in x ) \rangle\rangle$
      \item[Pow] $\langle D,T,
               \varnothing,
               \langle\vdash \exists x \forall y ( \forall x ( x \in y \to x
               \in z ) \to y \in x ) \rangle\rangle$
      \item[Reg] $\langle D,T,
               \varnothing,
               \langle\vdash (  x \in y \to
                 \exists x ( x \in y \wedge \forall z ( z \in x \to \lnot z
                \in y ) ) ) \rangle\rangle$
      \item[Inf] $\langle D,T,
               \varnothing,
               \langle\vdash \exists x(y\in x\wedge\forall y(y\in
               x\to
               \exists z(y \in z\wedge z\in x))) \rangle\rangle$
      \item[AC] $\langle D,T,
               \varnothing,
               \langle\vdash \exists x \forall y \forall z ( ( y \in z
               \wedge z \in w ) \to \exists w \forall y ( \exists w
              ( ( y \in z \wedge z \in w ) \wedge ( y \in w \wedge w \in x
              ) ) \leftrightarrow y = w ) ) \rangle\rangle$
\end{list}

\subsection{Example~6---Class Notation in Set Theory}\label{class}

A powerful device that makes set theory easier (and that we have
been using all along in our informal expository language) is {\em class
abstraction notation}.\index{class abstraction}\index{abstraction class}  The
definitions we introduce are rigorously justified
as conservative by Takeuti and Zaring \cite{Takeuti}\index{Takeuti, Gaisi} or
Quine \cite{Quine}\index{Quine, Willard Van Orman}.  The key idea is to
introduce the notation $\{x|\mbox{---}\}$ which means ``the class of all $x$
such that ---'' for abstraction classes and introduce (meta)variables that
range over them.  An abstraction class may or may not be a set, depending on
whether it exists (as a set).  A class that does not exist is
called a {\em proper class}.\index{proper class}\index{class!proper}

To illustrate the use of abstraction classes we will provide some examples
of definitions that make use of them:  the empty set, class union, and
unordered pair.  Many other such definitions can be found in the
Metamath set theory database, {\tt set.mm}.

We extend $\mbox{\em CN}$ of Example~5 with new symbols $\{\mbox{class}, \{,
|, \}, \varnothing, \cup, , \}$ where the inner braces and last comma are
constant symbols. (As before,
our dual use of some mathematical symbols for both our expository
language and as primitives of the formal system should be clear from context.)

We extend $\mbox{\em VR}$ of Example~5 with a set of {\em class
variables}\index{class variable}
$\{A,B,C,\ldots\}$. We extend the $T$ of Example~5 with $\{\langle
\mbox{class\ } A\rangle, \langle \mbox{class\ }B\rangle, \langle \mbox{class\ }
C\rangle,\ldots\}$.

We add to $\Gamma$ of Example~5 the following axiomatic statements to
introduce our definitions:
\begin{list}{}{\itemsep 0.0pt}
      \item[] $\langle\varnothing,T,\varnothing,
               \langle \mbox{class\ }x\rangle\rangle$
      \item[] $\langle\varnothing,T,\varnothing,
               \langle \mbox{class\ }\{x|\varphi\}\rangle\rangle$
      \item[] $\langle\varnothing,T,\varnothing,
               \langle \mbox{wff\ }A=B\rangle\rangle$
      \item[] $\langle\varnothing,T,\varnothing,
               \langle \mbox{wff\ }A\in B\rangle\rangle$
      \item[Ab] $\langle\varnothing,T,\varnothing,
               \langle \vdash ( y \in \{ x |\varphi\} \leftrightarrow
                  ( ( x = y \to\varphi) \wedge \exists x ( x = y
                  \wedge\varphi) ))
               \rangle\rangle$
      \item[Eq] $\langle\{\{x,A\},\{x,B\}\},T,\varnothing,
               \langle \vdash ( A = B \leftrightarrow
               \forall x ( x \in A \leftrightarrow x \in B ) )
               \rangle\rangle$
      \item[El] $\langle\{\{x,A\},\{x,B\}\},T,\varnothing,
               \langle \vdash ( A \in B \leftrightarrow \exists x
               ( x = A \wedge x \in B ) )
               \rangle\rangle$
\end{list}
Here we say that an individual variable is a class; $\{x|\varphi\}$ is a
class; and we extend the definition of a wff to include class equality and
membership.  Axiom Ab defines membership of a variable in a class abstraction;
the right-hand side can be read as ``the wff that results from proper
substitution of $y$ for $x$ in $\varphi$.''\footnote{Note that this definition
makes unnecessary the introduction of a separate notation similar to
$\varphi(x|y)$ for proper substitution, although we may choose to do so to be
conventional.  Incidentally, $\varphi(x|y)$ as it stands would be ambiguous in
the formal systems of our examples, since we wouldn't know whether
$\lnot\varphi(x|y)$ meant $\lnot(\varphi(x|y))$ or $(\lnot\varphi)(x|y)$.
Instead, we would have to use an unambiguous variant such as $(\varphi\,
x|y)$.}  Axioms Eq and El extend the meaning of the existing equality and
membership connectives.  This is potentially dangerous and requires careful
justification.  For example, from Eq we can derive the Axiom of Extensionality
with predicate logic alone; thus in principle we should include the Axiom of
Extensionality as a logical hypothesis.  However we do not bother to do this
since we have already presupposed that axiom earlier. The distinct variable
restrictions should be read ``where $x$ does not occur in $A$ or $B$.''  We
typically do this when the right-hand side of a definition involves an
individual variable not in the expression being defined; it is done so that
the right-hand side remains independent of the particular ``dummy'' variable
we use.

We continue to add to $\Gamma$ the following definitions for empty
set,\index{empty set} class union,\index{union} and unordered
pair.\index{unordered pair}  They should be self-explanatory.  Analogous to our
use of ``$\leftrightarrow$'' to define new wffs in Example~4, we use ``$=$''
to define new abstraction terms, and both may be read informally as ``is
defined as'' in this context.
\begin{list}{}{\itemsep 0.0pt}
      \item[] $\langle\varnothing,T,\varnothing,
               \langle \mbox{class\ }\varnothing\rangle\rangle$
      \item[] $\langle\varnothing,T,\varnothing,
               \langle \vdash \varnothing = \{ x | \lnot x = x \}
               \rangle\rangle$
      \item[] $\langle\varnothing,T,\varnothing,
               \langle \mbox{class\ }(A\cup B)\rangle\rangle$
      \item[] $\langle\{\{x,A\},\{x,B\}\},T,\varnothing,
               \langle \vdash ( A \cup B ) = \{ x | ( x \in A \vee x \in B ) \}
               \rangle\rangle$
      \item[] $\langle\varnothing,T,\varnothing,
               \langle \mbox{class\ }\{A,B\}\rangle\rangle$
      \item[] $\langle\{\{x,A\},\{x,B\}\},T,\varnothing,
               \langle \vdash \{ A , B \} = \{ x | ( x = A \vee x = B ) \}
               \rangle\rangle$
\end{list}

\section{Metamath as a Formal System}\label{theorymm}

This section presupposes a familiarity with the Metamath computer language.

Our theory describes formal systems and their universes.  The Metamath
language provides a way of representing these set-theoretical objects to a
computer.  A Metamath database, being a finite set of
{\sc ascii} characters, can usually describe only a subset of a formal system
and its universe, which are typically infinite.  However the database
can contain as large a finite subset of the formal system and its
universe as we wish.  (Of course a Metamath set theory database can
indirectly describe an entire infinite formal system by formalizing
the expository language in this Appendix.)

For purpose of our discussion, we assume the Metamath database
is in the simple form described on p.~\pageref{framelist},
consisting of all constant and variable declarations at the beginning,
followed by a sequence of extended frames each
delimited by {\tt \$\char`\{} and {\tt \$\char`\}}.  Any Metamath database can
be converted to this form, as described on p.~\pageref{frameconvert}.

The math symbol tokens of a Metamath source file, which are declared with {\tt
\$c} and {\tt \$v} statements, are names we assign to representatives of
$\mbox{\em CN}$ and $\mbox{\em VR}$.  For definiteness we could assume that
the first math symbol declared as a variable corresponds to $v_0$, the second
to $v_1$, etc., although the exact correspondence we choose is not important.

In the Metamath language, each {\tt \$d}, {\tt \$f}, and {\tt \$e} source
statement in an extended frame (Section~\ref{frames})
corresponds respectively to a member of the
collections $D$, $T$, and $H$ in a formal system statement $\langle
D,T,H,A\rangle$.  The math symbol strings following these Metamath keywords
correspond to a variable pair (in the case of {\tt \$d}) or an expression (for
the other two keywords). The math symbol string following a {\tt \$a} source
statement corresponds to expression $A$ in an axiomatic statement of the
formal system; the one following a {\tt \$p} source statement corresponds to
$A$ in a provable statement that is not axiomatic.  In other words, each
extended frame in the Metamath database corresponds to
a statement of the formal system.  (Don't confuse the two meanings of
``statement'' here.  A statement of the formal system corresponds to the
several statements of the Metamath database that may constitute an extended
frame.)

In order for the computer to verify that a formal system statement is
provable, each {\tt \$p} source statement is accompanied by a proof.  However,
the proof does not correspond to anything in the formal system but is simply a
way of communicating to the computer the information needed for its
verification. The proof tells the computer {\em how to construct} specific
members of the formal system statement's closure, resulting in a member
matching the extended frame for the {\tt \$p} statement; the formal system is
just concerned about the {\em existence} of members of the closure.

As mentioned on p.~\pageref{exampleref},
Examples 1 and 3--6 in the previous Section parallel the development of logic
and set theory in the Metamath database {\tt set.mm}.  You may find it
instructive to compare them.


\chapter{The MIU System}
\label{MIU}
\index{formal system}
\index{MIU-system}

The following is a listing of the file {\tt miu.mm}.  It is self-explanatory.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{verbatim}
$( The MIU-system:  A simple formal system $)

$(
Hofstadter's MIU-system is a simple example of a formal
system that illustrates some concepts of Metamath.  See
Douglas R. Hofstadter, "G\"{o}del, Escher, Bach:  An Eternal
Golden Braid" (Vintage Books, New York, 1979), pp. 33ff. for
a description of the MIU-system.

The system has 3 constant symbols, M, I, and U.  The sole
axiom of the system is MI. There are 4 rules:
     Rule I:  If you possess a string whose last letter is I,
     you can add on a U at the end.
     Rule II:  Suppose you have Mx.  Then you may add Mxx to
     your collection.
     Rule III:  If III occurs in one of the strings in your
     collection, you may make a new string with U in place
     of III.
     Rule IV:  If UU occurs inside one of your strings, you
     can drop it.
Unfortunately, Rules III and IV do not have unique results:
strings could have more than one occurrence of III or UU.
This requires that we introduce the concept of an "MIU
well-formed formula" or wff, which allows us to construct
unique symbol sequences to which Rules III and IV can be
applied.
$)

$( First, we declare the constant symbols of the language.
Note that we need two symbols to distinguish the assertion
that a sequence is a wff from the assertion that it is a
theorem; we have arbitrarily chosen "wff" and "|-". $)
      $c M I U |- wff $. $( Declare constants $)

$( Next, we declare some variables. $)
     $v x y $.

$( Throughout our theory, we shall assume that these
variables represent wffs. $)
 wx   $f wff x $.
 wy   $f wff y $.

$( Define MIU-wffs.  We allow the empty sequence to be a
wff. $)

$( The empty sequence is a wff. $)
 we   $a wff $.
$( "M" after any wff is a wff. $)
 wM   $a wff x M $.
$( "I" after any wff is a wff. $)
 wI   $a wff x I $.
$( "U" after any wff is a wff. $)
 wU   $a wff x U $.

$( Assert the axiom. $)
 ax   $a |- M I $.

$( Assert the rules. $)
 ${
   Ia   $e |- x I $.
$( Given any theorem ending with "I", it remains a theorem
if "U" is added after it. $)
   I    $a |- x I U $.
 $}
 ${
IIa  $e |- M x $.
$( Given any theorem starting with "M", it remains a theorem
if the part after the "M" is added again after it. $)
   II   $a |- M x x $.
 $}
 ${
   IIIa $e |- x I I I y $.
$( Given any theorem with "III" in the middle, it remains a
theorem if the "III" is replace with "U". $)
   III  $a |- x U y $.
 $}
 ${
   IVa  $e |- x U U y $.
$( Given any theorem with "UU" in the middle, it remains a
theorem if the "UU" is deleted. $)
   IV   $a |- x y $.
  $}

$( Now we prove the theorem MUIIU.  You may be interested in
comparing this proof with that of Hofstadter (pp. 35 - 36).
$)
 theorem1  $p |- M U I I U $=
      we wM wU wI we wI wU we wU wI wU we wM we wI wU we wM
      wI wI wI we wI wI we wI ax II II I III II IV $.
\end{verbatim}\index{well-formed formula (wff)}

The {\tt show proof /essential/lemmon/renumber} command
yields the following display.  It is very similar
to the one in \cite[pp.~35--36]{Hofstadter}.\index{Hofstadter, Douglas R.}

\begin{verbatim}
        1 ax             $a |- M I
        2 1 II           $a |- M I I
        3 2 II           $a |- M I I I I
        4 3 I            $a |- M I I I I U
        5 4 III          $a |- M U I U
        6 5 II           $a |- M U I U U I U
        7 6 IV           $a |- M U I I U
\end{verbatim}

We note that Hofstadter's ``MU-puzzle,'' which asks whether
MU is a theorem of the MIU-system, cannot be answered using
the system above because the MU-puzzle is a question {\em
about} the system.  To prove the answer to the MU-puzzle,
a much more elaborate system is needed, namely one that
models the MIU-system within set theory.  (Incidentally, the
answer to the MIU-puzzle is no.)


\chapter{Software Sources}\label{swsources}

\noindent \LaTeX\ \index{latex@{\LaTeX}} for the IBM PC is available from:
\begin{quote}
Personal \TeX\, Inc.\\
12 Madrona Avenue\\
Mill Valley, CA 94941\\
Phone:  415-388-8853
\end{quote}\index{latex@{\LaTeX}}

\noindent \LaTeX\ for the Macintosh is available from:
\begin{quote}
Blue Sky Research\\
534 Southwest Third Avenue\\
Portland, OR 97204\\
Phone:  800-622-8398 or 503-222-9571
\end{quote}

%??
%\noindent A public-domain \LaTeX\ for the Macintosh is available from:
%\begin{quote}
%???OzTex??? MacWorld letter, May?1993
%\end{quote}

\noindent AMSFonts are available from:\index{AMSFonts}
\begin{quote}
American Mathematical Society\\
P.O. Box 6248\\
Providence, RI 02940\\
Phone:  800-321-4AMS or 401-455-4080\\
These fonts are also available on the Internet via anonymous ftp to
{\tt e-MATH.AMS.COM} in the directory {\tt /ams}.
\end{quote}

\noindent For current information on the Metamath software see
\begin{quote}
{\tt ftp://ftp.shore.net/members/ndm/Read.me}
\end{quote}
or contact
%\noindent The Metamath software is available on the Internet via anonymous ftp
%to {\tt ftp.shore.net} in the directory {\tt members/ndm}.  This directory
%contains the Metamath source code and requires that you have a 32-bit ANSII C
%compiler to run it on a specific computer.
%  Compiled, ready-to-run versions
%are also available for MS-DOS and Macintosh.  The MS-DOS version requires DOS
%version 5.0 or higher, a 80386 or 80486 PC, and 8 megabytes of memory.  The
%Macintosh version requires version 6.0.7 or higher and 8 megabytes of memory.
%The software is provided on 3.5" high-density floppy diskettes.
%For current information contact:
\begin{quote}
%Metamath for MS-DOS:  \$15\\
%Metamath for Macintosh:  \$15\\
%{\em Metamath} book: \$18\\
%Add \$4 for postage and handling for any U.S. order.
%(These prices are valid as of October, 1994 and are subject to change without
%notice.  If you are dissatisfied, the software or book may be returned within
%30 days for a refund, minus postage and handling.)\\
%Make check or money order
%payable to:\\
Norman D. Megill\\
19 Locke Lane, Lexington, MA 02173\\
E-mail:  {\tt nm@alum.mit.edu}
\end{quote}



\chapter{Disclaimer and Trademarks}

Information in this document is subject to change without notice and does not
represent a commitment on the part of Norman D. Megill.
\vspace{2ex}

\noindent Norman D. Megill makes no warranties, either express or implied,
regarding the Metamath computer software package.

\vspace{2ex}

\noindent Microsoft is a registered trademark of Microsoft Corporation.\\
IBM PC is a registered trademark of International Business Machines, Inc.\\
Personal \TeX\ and PC\TeX\ are registered trademarks of Personal \TeX , Inc.\\
{\em Textures} is a trademark of Blue Sky Research.\\
Macintosh is a trademark licensed to Apple Computer, Inc.\\
\TeX\ is a trademark of the American Mathematical Society.\\
Metamath is a trademark of Norman D. Megill.

\bibliography{metamath}
%\input{metamath.bbl}

\raggedright
\input{metamath.ind}

\end{document}

